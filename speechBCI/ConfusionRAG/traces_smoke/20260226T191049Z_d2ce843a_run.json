{
  "run_id": "d2ce843a-f4e1-4c8a-8d17-89af0ddd8f0c",
  "timestamp": "2026-02-26T19:10:22.096944+00:00",
  "config": {
    "min_nbest": 2,
    "gate_metric": "entropy",
    "gate_threshold": 0.5,
    "retrieval_top_k": 5,
    "retrieval_context_window": 5,
    "session_memory_size": 10,
    "llm_mode": "nbest_rescore",
    "llm_alpha": 0.5,
    "acoustic_scale": 0.5,
    "llm_length_penalty": 0.0,
    "blank_penalty": 1.9459,
    "trace_enabled": true,
    "trace_dir": "/home/vincentyip/neuro/speechBCI/ConfusionRAG/traces_smoke"
  },
  "summary": {
    "total_sentences": 40,
    "sentences_with_uncertain_spans": 17,
    "sentences_using_span_choice": 0,
    "sentences_using_nbest_rescore": 17,
    "sentences_kept_top1": 23,
    "total_spans_evaluated": 90,
    "total_spans_gated_uncertain": 42,
    "total_retrievals": 42,
    "total_llm_changes": 5,
    "llm_change_accuracy": 0.4
  },
  "sentences": [
    {
      "sentence_idx": 0,
      "ground_truth": "it's really hard to find something that works",
      "top1_hypothesis": "it's really hard to find something that works",
      "final_decoded": "it's really hard to find something that works",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.7292089999282325
    },
    {
      "sentence_idx": 1,
      "ground_truth": "and i loved ths shining",
      "top1_hypothesis": "and i love the line",
      "final_decoded": "and i love the line",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 2,
      "spans": [
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "love",
          "confusion_candidates": [
            {
              "word": "love",
              "weight": 0.9967648100120085
            },
            {
              "word": "loved",
              "weight": 0.003235189986991343
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0217794551926493,
            "margin": 0.9935296200250171,
            "disagreement_mass": 0.003235189987991549
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "the",
          "confusion_candidates": [
            {
              "word": "the",
              "weight": 0.7243902947900349
            },
            {
              "word": "this",
              "weight": 0.27560970520896505
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5887588940847867,
            "margin": 0.44878058958106987,
            "disagreement_mass": 0.2756097052099651
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "and i love (the OR this) line",
            "retrieved_docs": [
              "I love this country too much.",
              "The child's love and security.",
              "You like food and I just love the smell.",
              "I would love to.",
              "I love Chinese food.",
              "it's really hard to find something that works"
            ],
            "scores": [
              10.983964016423965,
              10.67223848133441,
              9.421209276503596,
              8.889183021287025,
              8.889183021287025,
              0.0
            ],
            "retrieval_time_ms": 9.63498900000559
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "line",
          "confusion_candidates": [
            {
              "word": "line",
              "weight": 0.0530805100763046
            },
            {
              "word": "guy",
              "weight": 0.0007996918460929091
            },
            {
              "word": "show",
              "weight": 0.0008863127380678521
            },
            {
              "word": "signing",
              "weight": 0.5793997465691308
            },
            {
              "word": "time",
              "weight": 0.0010381052660611957
            },
            {
              "word": "u",
              "weight": 0.00011659677944997915
            },
            {
              "word": "shining",
              "weight": 0.14938713720485688
            },
            {
              "word": "sign",
              "weight": 0.01908581264223113
            },
            {
              "word": "no",
              "weight": 0.0003399177851855708
            },
            {
              "word": "high",
              "weight": 0.005689056332493873
            },
            {
              "word": "timing",
              "weight": 0.016976971587743393
            },
            {
              "word": "lying",
              "weight": 0.09818549925537716
            },
            {
              "word": "lighting",
              "weight": 0.0007836199279346971
            },
            {
              "word": "shine",
              "weight": 0.003890687317054156
            },
            {
              "word": "i",
              "weight": 0.0005872335360803079
            },
            {
              "word": "lie",
              "weight": 0.0010297655842872548
            },
            {
              "word": "dying",
              "weight": 0.0038850515210011177
            },
            {
              "word": "tone",
              "weight": 0.0004000942676502274
            },
            {
              "word": "tiny",
              "weight": 0.0018151862219850537
            },
            {
              "word": "lion",
              "weight": 0.0007468146061482217
            },
            {
              "word": "nine",
              "weight": 0.0028455756815754193
            },
            {
              "word": "eye",
              "weight": 0.0003155295484563624
            },
            {
              "word": "tie",
              "weight": 0.0023531505318108536
            },
            {
              "word": "song",
              "weight": 7.7014816630105e-06
            },
            {
              "word": "lining",
              "weight": 0.014301639203184153
            },
            {
              "word": "joy",
              "weight": 0.0003454973275036083
            },
            {
              "word": "toy",
              "weight": 0.00019289088214872102
            },
            {
              "word": "shiny",
              "weight": 0.0002791227859833332
            },
            {
              "word": "june",
              "weight": 8.88206313538363e-05
            },
            {
              "word": "site",
              "weight": 5.655044059946601e-06
            },
            {
              "word": "too",
              "weight": 7.520397779535993e-06
            },
            {
              "word": "new",
              "weight": 6.884303335518901e-06
            },
            {
              "word": "mining",
              "weight": 0.00048241340653051737
            },
            {
              "word": "size",
              "weight": 2.1243200101548758e-05
            },
            {
              "word": "way",
              "weight": 1.1436689237654822e-07
            },
            {
              "word": "two",
              "weight": 1.141207785387313e-05
            },
            {
              "word": "tying",
              "weight": 0.029303668773628673
            },
            {
              "word": "china",
              "weight": 0.00010889777085969164
            },
            {
              "word": "thai",
              "weight": 0.0006568537584212534
            },
            {
              "word": "town",
              "weight": 5.477389535253788e-07
            },
            {
              "word": "night",
              "weight": 1.9986984616159393e-06
            },
            {
              "word": "hire",
              "weight": 5.4833923544305535e-06
            },
            {
              "word": "wine",
              "weight": 7.388090016411286e-06
            },
            {
              "word": "ai",
              "weight": 4.167236799105663e-05
            },
            {
              "word": "sighing",
              "weight": 0.0076399750113611276
            },
            {
              "word": "tune",
              "weight": 5.0547761638916135e-06
            },
            {
              "word": "journey",
              "weight": 1.6421978148182517e-06
            },
            {
              "word": "low",
              "weight": 4.564746123204102e-06
            },
            {
              "word": "light",
              "weight": 9.072468689674999e-07
            },
            {
              "word": "sun",
              "weight": 1.0068045241334417e-06
            },
            {
              "word": "fine",
              "weight": 7.294471361206829e-06
            },
            {
              "word": "chain",
              "weight": 6.193760997604931e-06
            },
            {
              "word": "in",
              "weight": 0.0014248628534279464
            },
            {
              "word": "mine",
              "weight": 1.0813520896253677e-05
            },
            {
              "word": "hiring",
              "weight": 0.00011890161309483409
            },
            {
              "word": "jain",
              "weight": 0.000893997370636957
            },
            {
              "word": "sein",
              "weight": 0.00025107794064789117
            },
            {
              "word": "j",
              "weight": 5.825584764214356e-06
            },
            {
              "word": "loan",
              "weight": 6.6169340274412305e-06
            },
            {
              "word": "guys",
              "weight": 1.2838568834759342e-07
            },
            {
              "word": "writing",
              "weight": 1.672167945322317e-06
            },
            {
              "word": "saying",
              "weight": 5.9304567345284366e-05
            },
            {
              "word": "toys",
              "weight": 8.684761515672589e-07
            },
            {
              "word": "eyes",
              "weight": 9.81166111442091e-07
            },
            {
              "word": "rising",
              "weight": 6.778890807029707e-06
            },
            {
              "word": "sighting",
              "weight": 3.603898618472039e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.5347676656853444,
            "margin": 0.430012609364274,
            "disagreement_mass": 0.42060025343086915
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "and i love the (line OR guy OR show OR signing OR time OR u OR shining OR sign OR no OR high OR timing OR lying OR lighting OR shine OR i OR lie OR dying OR tone OR tiny OR lion OR nine OR eye OR tie OR song OR lining OR joy OR toy OR shiny OR june OR site OR too OR new OR mining OR size OR way OR two OR tying OR china OR thai OR town OR night OR hire OR wine OR ai OR sighing OR tune OR journey OR low OR light OR sun OR fine OR chain OR in OR mine OR hiring OR jain OR sein OR j OR loan OR guys OR writing OR saying OR toys OR eyes OR rising OR sighting)",
            "retrieved_docs": [
              "The decisions I made were mine and mine alone.",
              "I love this country too much.",
              "Wine glass heels are to be found in both high and semi-heights.",
              "Well that's the way mine is.",
              "I mean it's dying now.",
              "it's really hard to find something that works"
            ],
            "scores": [
              14.663940380424792,
              14.116119601834363,
              13.736936554864686,
              13.577196045466138,
              12.051187844358724,
              0.0
            ],
            "retrieval_time_ms": 80.23334100005286
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 5,
          "top1_word": "and i love the line",
          "confusion_candidates": [
            {
              "word": "and i love the line",
              "weight": -127.06734848022461
            },
            {
              "word": "and i love the guy",
              "weight": -127.9814453125
            },
            {
              "word": "and i love the show",
              "weight": -128.22474479675293
            },
            {
              "word": "and i love this signing",
              "weight": -129.76157188415527
            },
            {
              "word": "and i love the signing",
              "weight": -127.92214775085449
            },
            {
              "word": "and i love the time",
              "weight": -128.2492504119873
            },
            {
              "word": "and i love the u",
              "weight": -129.47341918945312
            },
            {
              "word": "and i love the shining",
              "weight": -128.2594165802002
            },
            {
              "word": "and i love the sign",
              "weight": -128.19124221801758
            },
            {
              "word": "and i love this guy",
              "weight": -129.28478813171387
            },
            {
              "word": "and i love this show",
              "weight": -129.91308975219727
            },
            {
              "word": "and i love the no",
              "weight": -129.98275756835938
            },
            {
              "word": "and i love the high",
              "weight": -127.64986228942871
            },
            {
              "word": "and i love the timing",
              "weight": -128.0253200531006
            },
            {
              "word": "and i love this line",
              "weight": -129.8021068572998
            },
            {
              "word": "and i love the lying",
              "weight": -128.72844696044922
            },
            {
              "word": "and i love this time",
              "weight": -129.80756950378418
            },
            {
              "word": "and i love the lighting",
              "weight": -129.10810089111328
            },
            {
              "word": "and i love the shine",
              "weight": -129.0959014892578
            },
            {
              "word": "and i love the i",
              "weight": -129.16218757629395
            },
            {
              "word": "and i love the lie",
              "weight": -130.4242401123047
            },
            {
              "word": "and i love the dying",
              "weight": -130.30003356933594
            },
            {
              "word": "and i love the tone",
              "weight": -129.80252647399902
            },
            {
              "word": "and i love the tiny",
              "weight": -129.0179786682129
            },
            {
              "word": "and i love the lion",
              "weight": -130.4470729827881
            },
            {
              "word": "and i love the nine",
              "weight": -129.93450164794922
            },
            {
              "word": "and i love the eye",
              "weight": -130.30008125305176
            },
            {
              "word": "and i loved the show",
              "weight": -132.84477996826172
            },
            {
              "word": "and i love the tie",
              "weight": -129.667142868042
            },
            {
              "word": "and i loved the line",
              "weight": -131.81724548339844
            },
            {
              "word": "and i love the song",
              "weight": -130.46484375
            },
            {
              "word": "and i love the lining",
              "weight": -129.3250274658203
            },
            {
              "word": "and i love the joy",
              "weight": -129.15206146240234
            },
            {
              "word": "and i love this song",
              "weight": -131.80736351013184
            },
            {
              "word": "and i love the toy",
              "weight": -130.13256645202637
            },
            {
              "word": "and i love the shiny",
              "weight": -130.43537139892578
            },
            {
              "word": "and i love the june",
              "weight": -132.72216987609863
            },
            {
              "word": "and i love this site",
              "weight": -131.70397758483887
            },
            {
              "word": "and i love this too",
              "weight": -131.07923316955566
            },
            {
              "word": "and i love the new",
              "weight": -129.8953628540039
            },
            {
              "word": "and i loved the guy",
              "weight": -132.84673309326172
            },
            {
              "word": "and i love the mining",
              "weight": -131.00205993652344
            },
            {
              "word": "and i love the size",
              "weight": -130.46977615356445
            },
            {
              "word": "and i love the way",
              "weight": -131.33156204223633
            },
            {
              "word": "and i loved the signing",
              "weight": -132.42706298828125
            },
            {
              "word": "and i loved the time",
              "weight": -132.81790924072266
            },
            {
              "word": "and i love the two",
              "weight": -130.3238468170166
            },
            {
              "word": "and i love this lying",
              "weight": -131.59183502197266
            },
            {
              "word": "and i love this sign",
              "weight": -131.4982795715332
            },
            {
              "word": "and i loved the u",
              "weight": -134.0653781890869
            },
            {
              "word": "and i loved the shining",
              "weight": -132.89493942260742
            },
            {
              "word": "and i love the tying",
              "weight": -129.68517684936523
            },
            {
              "word": "and i love this i",
              "weight": -131.3614902496338
            },
            {
              "word": "and i love the site",
              "weight": -131.78022003173828
            },
            {
              "word": "and i love this toy",
              "weight": -132.07085800170898
            },
            {
              "word": "and i love the china",
              "weight": -130.4444065093994
            },
            {
              "word": "and i love this thai",
              "weight": -132.41123008728027
            },
            {
              "word": "and i love this high",
              "weight": -131.3840675354004
            },
            {
              "word": "and i loved this line",
              "weight": -133.57609176635742
            },
            {
              "word": "and i love this town",
              "weight": -131.7947826385498
            },
            {
              "word": "and i love the thai",
              "weight": -129.99647331237793
            },
            {
              "word": "and i love the night",
              "weight": -131.14683151245117
            },
            {
              "word": "and i love the hire",
              "weight": -133.53912162780762
            },
            {
              "word": "and i love this timing",
              "weight": -132.57521629333496
            },
            {
              "word": "and i love the wine",
              "weight": -129.9394187927246
            },
            {
              "word": "and i loved this show",
              "weight": -134.2920036315918
            },
            {
              "word": "and i love the ai",
              "weight": -131.9560947418213
            },
            {
              "word": "and i love the sighing",
              "weight": -131.42281913757324
            },
            {
              "word": "and i love this tune",
              "weight": -134.14613914489746
            },
            {
              "word": "and i love the journey",
              "weight": -132.4055461883545
            },
            {
              "word": "and i love the low",
              "weight": -131.43945693969727
            },
            {
              "word": "and i love the light",
              "weight": -131.65167427062988
            },
            {
              "word": "and i loved the timing",
              "weight": -132.43475341796875
            },
            {
              "word": "and i loved the lying",
              "weight": -133.28837776184082
            },
            {
              "word": "and i loved the high",
              "weight": -132.53856658935547
            },
            {
              "word": "and i love the sun",
              "weight": -131.2041358947754
            },
            {
              "word": "and i love the fine",
              "weight": -130.994966506958
            },
            {
              "word": "and i love the chain",
              "weight": -131.70215797424316
            },
            {
              "word": "and i love this tie",
              "weight": -132.4442653656006
            },
            {
              "word": "and i love the high in",
              "weight": -131.7026596069336
            },
            {
              "word": "and i love the mine",
              "weight": -132.3769989013672
            },
            {
              "word": "and i love the hiring",
              "weight": -131.98691940307617
            },
            {
              "word": "and i love the jain",
              "weight": -131.9771785736084
            },
            {
              "word": "and i love the sein",
              "weight": -131.95595932006836
            },
            {
              "word": "and i love the j",
              "weight": -130.73384475708008
            },
            {
              "word": "and i love the loan",
              "weight": -133.22049713134766
            },
            {
              "word": "and i loved the sign",
              "weight": -133.14637565612793
            },
            {
              "word": "and i love the guys",
              "weight": -132.73712730407715
            },
            {
              "word": "and i love the sign in",
              "weight": -131.31178092956543
            },
            {
              "word": "and i love the time in",
              "weight": -131.99933624267578
            },
            {
              "word": "and i love the show in",
              "weight": -132.95238494873047
            },
            {
              "word": "and i love the writing",
              "weight": -132.08951950073242
            },
            {
              "word": "and i love the saying",
              "weight": -130.83750915527344
            },
            {
              "word": "and i love this june",
              "weight": -135.972900390625
            },
            {
              "word": "and i love the toys",
              "weight": -132.16965866088867
            },
            {
              "word": "and i love the eyes",
              "weight": -133.38460540771484
            },
            {
              "word": "and i love this lie",
              "weight": -133.36786651611328
            },
            {
              "word": "and i loved the tone",
              "weight": -134.30831146240234
            },
            {
              "word": "and i love the rising",
              "weight": -132.50605964660645
            },
            {
              "word": "and i love the sighting",
              "weight": -133.86325454711914
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "I love this country too much.",
              "The child's love and security.",
              "You like food and I just love the smell.",
              "I would love to.",
              "I love Chinese food.",
              "it's really hard to find something that works",
              "The decisions I made were mine and mine alone.",
              "Wine glass heels are to be found in both high and semi-heights.",
              "Well that's the way mine is.",
              "I mean it's dying now."
            ],
            "retrieval_time_ms": 89.86833000005845
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "and i love the line",
                "llm_score": -178.46884155273438,
                "old_lm_score": -25.642578125,
                "acoustic_score": -50.023277282714844,
                "combined_score": -127.06734848022461
              },
              {
                "candidate": "and i love the guy",
                "llm_score": -176.01795959472656,
                "old_lm_score": -22.3701171875,
                "acoustic_score": -57.57481384277344,
                "combined_score": -127.9814453125
              },
              {
                "candidate": "and i love the show",
                "llm_score": -176.608154296875,
                "old_lm_score": -22.482421875,
                "acoustic_score": -57.35891342163086,
                "combined_score": -128.22474479675293
              },
              {
                "candidate": "and i love this signing",
                "llm_score": -185.52120971679688,
                "old_lm_score": -28.5068359375,
                "acoustic_score": -45.49509811401367,
                "combined_score": -129.76157188415527
              },
              {
                "candidate": "and i love the signing",
                "llm_score": -181.98402404785156,
                "old_lm_score": -30.0927734375,
                "acoustic_score": -43.76749801635742,
                "combined_score": -127.92214775085449
              },
              {
                "candidate": "and i love the time",
                "llm_score": -176.80259704589844,
                "old_lm_score": -24.431640625,
                "acoustic_score": -55.26426315307617,
                "combined_score": -128.2492504119873
              },
              {
                "candidate": "and i love the u",
                "llm_score": -177.19793701171875,
                "old_lm_score": -22.576171875,
                "acoustic_score": -59.1727294921875,
                "combined_score": -129.47341918945312
              },
              {
                "candidate": "and i love the shining",
                "llm_score": -181.92550659179688,
                "old_lm_score": -29.7451171875,
                "acoustic_score": -44.848209381103516,
                "combined_score": -128.2594165802002
              },
              {
                "candidate": "and i love the sign",
                "llm_score": -179.71737670898438,
                "old_lm_score": -27.9248046875,
                "acoustic_score": -48.74030303955078,
                "combined_score": -128.19124221801758
              },
              {
                "candidate": "and i love this guy",
                "llm_score": -176.6040802001953,
                "old_lm_score": -22.6630859375,
                "acoustic_score": -59.30241012573242,
                "combined_score": -129.28478813171387
              },
              {
                "candidate": "and i love this show",
                "llm_score": -177.9203338623047,
                "old_lm_score": -22.8193359375,
                "acoustic_score": -59.086509704589844,
                "combined_score": -129.91308975219727
              },
              {
                "candidate": "and i love the no",
                "llm_score": -179.2918243408203,
                "old_lm_score": -24.2744140625,
                "acoustic_score": -56.39927673339844,
                "combined_score": -129.98275756835938
              },
              {
                "candidate": "and i love the high",
                "llm_score": -177.4229736328125,
                "old_lm_score": -27.359375,
                "acoustic_score": -50.51737594604492,
                "combined_score": -127.64986228942871
              },
              {
                "candidate": "and i love the timing",
                "llm_score": -179.26443481445312,
                "old_lm_score": -29.115234375,
                "acoustic_score": -47.67097091674805,
                "combined_score": -128.0253200531006
              },
              {
                "candidate": "and i love this line",
                "llm_score": -180.72540283203125,
                "old_lm_score": -27.1279296875,
                "acoustic_score": -51.75088119506836,
                "combined_score": -129.8021068572998
              },
              {
                "candidate": "and i love the lying",
                "llm_score": -182.4066162109375,
                "old_lm_score": -30.9619140625,
                "acoustic_score": -44.08836364746094,
                "combined_score": -128.72844696044922
              },
              {
                "candidate": "and i love this time",
                "llm_score": -177.97776794433594,
                "old_lm_score": -24.6455078125,
                "acoustic_score": -56.99186325073242,
                "combined_score": -129.80756950378418
              },
              {
                "candidate": "and i love the lighting",
                "llm_score": -178.3777313232422,
                "old_lm_score": -26.6650390625,
                "acoustic_score": -53.173431396484375,
                "combined_score": -129.10810089111328
              },
              {
                "candidate": "and i love the shine",
                "llm_score": -179.95574951171875,
                "old_lm_score": -28.4150390625,
                "acoustic_score": -49.821014404296875,
                "combined_score": -129.0959014892578
              },
              {
                "candidate": "and i love the i",
                "llm_score": -178.14654541015625,
                "old_lm_score": -26.9228515625,
                "acoustic_score": -53.25497817993164,
                "combined_score": -129.16218757629395
              },
              {
                "candidate": "and i love the lie",
                "llm_score": -181.2654571533203,
                "old_lm_score": -27.9013671875,
                "acoustic_score": -51.68165588378906,
                "combined_score": -130.4242401123047
              },
              {
                "candidate": "and i love the dying",
                "llm_score": -182.36256408691406,
                "old_lm_score": -29.3486328125,
                "acoustic_score": -48.88887023925781,
                "combined_score": -130.30003356933594
              },
              {
                "candidate": "and i love the tone",
                "llm_score": -179.0873565673828,
                "old_lm_score": -27.3046875,
                "acoustic_score": -53.213008880615234,
                "combined_score": -129.80252647399902
              },
              {
                "candidate": "and i love the tiny",
                "llm_score": -179.03750610351562,
                "old_lm_score": -29.03515625,
                "acoustic_score": -49.963294982910156,
                "combined_score": -129.0179786682129
              },
              {
                "candidate": "and i love the lion",
                "llm_score": -181.007568359375,
                "old_lm_score": -28.2197265625,
                "acoustic_score": -51.66685104370117,
                "combined_score": -130.4470729827881
              },
              {
                "candidate": "and i love the nine",
                "llm_score": -181.32012939453125,
                "old_lm_score": -29.6875,
                "acoustic_score": -48.86137390136719,
                "combined_score": -129.93450164794922
              },
              {
                "candidate": "and i love the eye",
                "llm_score": -179.85202026367188,
                "old_lm_score": -27.4931640625,
                "acoustic_score": -53.25497817993164,
                "combined_score": -130.30008125305176
              },
              {
                "candidate": "and i loved the show",
                "llm_score": -180.88626098632812,
                "old_lm_score": -23.5302734375,
                "acoustic_score": -61.27302551269531,
                "combined_score": -132.84477996826172
              },
              {
                "candidate": "and i love the tie",
                "llm_score": -180.55043029785156,
                "old_lm_score": -29.7919921875,
                "acoustic_score": -48.99186325073242,
                "combined_score": -129.667142868042
              },
              {
                "candidate": "and i loved the line",
                "llm_score": -182.2879180908203,
                "old_lm_score": -27.4091796875,
                "acoustic_score": -53.93739318847656,
                "combined_score": -131.81724548339844
              },
              {
                "candidate": "and i love the song",
                "llm_score": -176.15963745117188,
                "old_lm_score": -24.01953125,
                "acoustic_score": -60.750518798828125,
                "combined_score": -130.46484375
              },
              {
                "candidate": "and i love the lining",
                "llm_score": -181.71578979492188,
                "old_lm_score": -31.8837890625,
                "acoustic_score": -45.05047607421875,
                "combined_score": -129.3250274658203
              },
              {
                "candidate": "and i love the joy",
                "llm_score": -177.64671325683594,
                "old_lm_score": -28.2412109375,
                "acoustic_score": -52.41619873046875,
                "combined_score": -129.15206146240234
              },
              {
                "candidate": "and i love this song",
                "llm_score": -177.82899475097656,
                "old_lm_score": -23.3076171875,
                "acoustic_score": -62.47811508178711,
                "combined_score": -131.80736351013184
              },
              {
                "candidate": "and i love the toy",
                "llm_score": -178.88717651367188,
                "old_lm_score": -27.83203125,
                "acoustic_score": -53.54592514038086,
                "combined_score": -130.13256645202637
              },
              {
                "candidate": "and i love the shiny",
                "llm_score": -180.0,
                "old_lm_score": -28.419921875,
                "acoustic_score": -52.45082092285156,
                "combined_score": -130.43537139892578
              },
              {
                "candidate": "and i love the june",
                "llm_score": -183.3776092529297,
                "old_lm_score": -27.4853515625,
                "acoustic_score": -54.58137893676758,
                "combined_score": -132.72216987609863
              },
              {
                "candidate": "and i love this site",
                "llm_score": -177.8684844970703,
                "old_lm_score": -24.328125,
                "acoustic_score": -61.21134567260742,
                "combined_score": -131.70397758483887
              },
              {
                "candidate": "and i love this too",
                "llm_score": -177.67369079589844,
                "old_lm_score": -25.3876953125,
                "acoustic_score": -59.09708023071289,
                "combined_score": -131.07923316955566
              },
              {
                "candidate": "and i love the new",
                "llm_score": -175.2175750732422,
                "old_lm_score": -25.67578125,
                "acoustic_score": -58.897369384765625,
                "combined_score": -129.8953628540039
              },
              {
                "candidate": "and i loved the guy",
                "llm_score": -179.7836456298828,
                "old_lm_score": -24.4208984375,
                "acoustic_score": -61.488922119140625,
                "combined_score": -132.84673309326172
              },
              {
                "candidate": "and i love the mining",
                "llm_score": -181.68052673339844,
                "old_lm_score": -30.1533203125,
                "acoustic_score": -50.17027282714844,
                "combined_score": -131.00205993652344
              },
              {
                "candidate": "and i love the size",
                "llm_score": -177.49319458007812,
                "old_lm_score": -27.0546875,
                "acoustic_score": -56.39167022705078,
                "combined_score": -130.46977615356445
              },
              {
                "candidate": "and i love the way",
                "llm_score": -173.9923858642578,
                "old_lm_score": -21.8583984375,
                "acoustic_score": -66.81233978271484,
                "combined_score": -131.33156204223633
              },
              {
                "candidate": "and i loved the signing",
                "llm_score": -185.74282836914062,
                "old_lm_score": -31.4296875,
                "acoustic_score": -47.681610107421875,
                "combined_score": -132.42706298828125
              },
              {
                "candidate": "and i loved the time",
                "llm_score": -180.6888885498047,
                "old_lm_score": -25.7685546875,
                "acoustic_score": -59.178375244140625,
                "combined_score": -132.81790924072266
              },
              {
                "candidate": "and i love the two",
                "llm_score": -176.57997131347656,
                "old_lm_score": -26.6982421875,
                "acoustic_score": -57.36948013305664,
                "combined_score": -130.3238468170166
              },
              {
                "candidate": "and i love this lying",
                "llm_score": -184.86770629882812,
                "old_lm_score": -32.5,
                "acoustic_score": -45.81596374511719,
                "combined_score": -131.59183502197266
              },
              {
                "candidate": "and i love this sign",
                "llm_score": -182.31185913085938,
                "old_lm_score": -30.216796875,
                "acoustic_score": -50.46790313720703,
                "combined_score": -131.4982795715332
              },
              {
                "candidate": "and i loved the u",
                "llm_score": -181.13082885742188,
                "old_lm_score": -23.9130859375,
                "acoustic_score": -63.08684158325195,
                "combined_score": -134.0653781890869
              },
              {
                "candidate": "and i loved the shining",
                "llm_score": -185.94552612304688,
                "old_lm_score": -31.08203125,
                "acoustic_score": -48.76232147216797,
                "combined_score": -132.89493942260742
              },
              {
                "candidate": "and i love the tying",
                "llm_score": -183.15342712402344,
                "old_lm_score": -34.818359375,
                "acoustic_score": -41.39856719970703,
                "combined_score": -129.68517684936523
              },
              {
                "candidate": "and i love this i",
                "llm_score": -179.5919647216797,
                "old_lm_score": -28.1484375,
                "acoustic_score": -54.98257827758789,
                "combined_score": -131.3614902496338
              },
              {
                "candidate": "and i love the site",
                "llm_score": -178.16848754882812,
                "old_lm_score": -25.908203125,
                "acoustic_score": -59.48374938964844,
                "combined_score": -131.78022003173828
              },
              {
                "candidate": "and i love this toy",
                "llm_score": -180.85061645507812,
                "old_lm_score": -28.017578125,
                "acoustic_score": -55.273521423339844,
                "combined_score": -132.07085800170898
              },
              {
                "candidate": "and i love the china",
                "llm_score": -179.0768280029297,
                "old_lm_score": -29.546875,
                "acoustic_score": -52.26511001586914,
                "combined_score": -130.4444065093994
              },
              {
                "candidate": "and i love this thai",
                "llm_score": -183.77780151367188,
                "old_lm_score": -30.3251953125,
                "acoustic_score": -50.71946334838867,
                "combined_score": -132.41123008728027
              },
              {
                "candidate": "and i love this high",
                "llm_score": -180.84933471679688,
                "old_lm_score": -29.673828125,
                "acoustic_score": -52.244972229003906,
                "combined_score": -131.3840675354004
              },
              {
                "candidate": "and i loved this line",
                "llm_score": -183.42762756347656,
                "old_lm_score": -28.0595703125,
                "acoustic_score": -55.66498565673828,
                "combined_score": -133.57609176635742
              },
              {
                "candidate": "and i love this town",
                "llm_score": -176.48521423339844,
                "old_lm_score": -24.6943359375,
                "acoustic_score": -62.41001510620117,
                "combined_score": -131.7947826385498
              },
              {
                "candidate": "and i love the thai",
                "llm_score": -179.53623962402344,
                "old_lm_score": -31.46484375,
                "acoustic_score": -48.99186325073242,
                "combined_score": -129.99647331237793
              },
              {
                "candidate": "and i love the night",
                "llm_score": -176.4837646484375,
                "old_lm_score": -26.205078125,
                "acoustic_score": -59.604820251464844,
                "combined_score": -131.14683151245117
              },
              {
                "candidate": "and i love the hire",
                "llm_score": -182.27757263183594,
                "old_lm_score": -27.345703125,
                "acoustic_score": -57.4549674987793,
                "combined_score": -133.53912162780762
              },
              {
                "candidate": "and i love this timing",
                "llm_score": -184.37197875976562,
                "old_lm_score": -31.3798828125,
                "acoustic_score": -49.3985710144043,
                "combined_score": -132.57521629333496
              },
              {
                "candidate": "and i love the wine",
                "llm_score": -175.37631225585938,
                "old_lm_score": -27.724609375,
                "acoustic_score": -56.777915954589844,
                "combined_score": -129.9394187927246
              },
              {
                "candidate": "and i loved this show",
                "llm_score": -180.95448303222656,
                "old_lm_score": -24.62890625,
                "acoustic_score": -63.00061798095703,
                "combined_score": -134.2920036315918
              },
              {
                "candidate": "and i love the ai",
                "llm_score": -181.13963317871094,
                "old_lm_score": -29.517578125,
                "acoustic_score": -53.25497817993164,
                "combined_score": -131.9560947418213
              },
              {
                "candidate": "and i love the sighing",
                "llm_score": -185.28439331054688,
                "old_lm_score": -34.755859375,
                "acoustic_score": -42.80538558959961,
                "combined_score": -131.42281913757324
              },
              {
                "candidate": "and i love this tune",
                "llm_score": -183.41021728515625,
                "old_lm_score": -27.443359375,
                "acoustic_score": -57.43870162963867,
                "combined_score": -134.14613914489746
              },
              {
                "candidate": "and i love the journey",
                "llm_score": -178.8047332763672,
                "old_lm_score": -26.328125,
                "acoustic_score": -59.6782341003418,
                "combined_score": -132.4055461883545
              },
              {
                "candidate": "and i love the low",
                "llm_score": -177.89488220214844,
                "old_lm_score": -27.4228515625,
                "acoustic_score": -57.561180114746094,
                "combined_score": -131.43945693969727
              },
              {
                "candidate": "and i love the light",
                "llm_score": -176.70361328125,
                "old_lm_score": -25.8330078125,
                "acoustic_score": -60.766727447509766,
                "combined_score": -131.65167427062988
              },
              {
                "candidate": "and i loved the timing",
                "llm_score": -182.832275390625,
                "old_lm_score": -30.4521484375,
                "acoustic_score": -51.5850830078125,
                "combined_score": -132.43475341796875
              },
              {
                "candidate": "and i loved the lying",
                "llm_score": -186.27545166015625,
                "old_lm_score": -32.298828125,
                "acoustic_score": -48.00247573852539,
                "combined_score": -133.28837776184082
              },
              {
                "candidate": "and i loved the high",
                "llm_score": -181.48939514160156,
                "old_lm_score": -29.15625,
                "acoustic_score": -54.431488037109375,
                "combined_score": -132.53856658935547
              },
              {
                "candidate": "and i love the sun",
                "llm_score": -175.91265869140625,
                "old_lm_score": -26.259765625,
                "acoustic_score": -60.23584747314453,
                "combined_score": -131.2041358947754
              },
              {
                "candidate": "and i love the fine",
                "llm_score": -177.4746551513672,
                "old_lm_score": -28.447265625,
                "acoustic_score": -56.06801223754883,
                "combined_score": -130.994966506958
              },
              {
                "candidate": "and i love the chain",
                "llm_score": -178.7254638671875,
                "old_lm_score": -28.3017578125,
                "acoustic_score": -56.37709426879883,
                "combined_score": -131.70215797424316
              },
              {
                "candidate": "and i love this tie",
                "llm_score": -183.0255126953125,
                "old_lm_score": -31.1435546875,
                "acoustic_score": -50.71946334838867,
                "combined_score": -132.4442653656006
              },
              {
                "candidate": "and i love the high in",
                "llm_score": -182.8641815185547,
                "old_lm_score": -32.5341796875,
                "acoustic_score": -48.0069580078125,
                "combined_score": -131.7026596069336
              },
              {
                "candidate": "and i love the mine",
                "llm_score": -180.6324005126953,
                "old_lm_score": -28.978515625,
                "acoustic_score": -55.14308166503906,
                "combined_score": -132.3769989013672
              },
              {
                "candidate": "and i love the hiring",
                "llm_score": -182.24974060058594,
                "old_lm_score": -31.3828125,
                "acoustic_score": -50.341285705566406,
                "combined_score": -131.98691940307617
              },
              {
                "candidate": "and i love the jain",
                "llm_score": -184.24766540527344,
                "old_lm_score": -33.5029296875,
                "acoustic_score": -46.20376205444336,
                "combined_score": -131.9771785736084
              },
              {
                "candidate": "and i love the sein",
                "llm_score": -182.93528747558594,
                "old_lm_score": -32.236328125,
                "acoustic_score": -48.74030303955078,
                "combined_score": -131.95595932006836
              },
              {
                "candidate": "and i love the j",
                "llm_score": -176.72755432128906,
                "old_lm_score": -28.501953125,
                "acoustic_score": -56.238182067871094,
                "combined_score": -130.73384475708008
              },
              {
                "candidate": "and i love the loan",
                "llm_score": -181.82823181152344,
                "old_lm_score": -28.7099609375,
                "acoustic_score": -55.902801513671875,
                "combined_score": -133.22049713134766
              },
              {
                "candidate": "and i loved the sign",
                "llm_score": -183.21646118164062,
                "old_lm_score": -30.421875,
                "acoustic_score": -52.654415130615234,
                "combined_score": -133.14637565612793
              },
              {
                "candidate": "and i love the guys",
                "llm_score": -176.9191436767578,
                "old_lm_score": -24.9873046875,
                "acoustic_score": -63.567806243896484,
                "combined_score": -132.73712730407715
              },
              {
                "candidate": "and i love the sign in",
                "llm_score": -183.02798461914062,
                "old_lm_score": -33.9814453125,
                "acoustic_score": -45.614131927490234,
                "combined_score": -131.31178092956543
              },
              {
                "candidate": "and i love the time in",
                "llm_score": -180.8258819580078,
                "old_lm_score": -30.4189453125,
                "acoustic_score": -52.75384521484375,
                "combined_score": -131.99933624267578
              },
              {
                "candidate": "and i love the show in",
                "llm_score": -181.6822509765625,
                "old_lm_score": -29.3740234375,
                "acoustic_score": -54.84849548339844,
                "combined_score": -132.95238494873047
              },
              {
                "candidate": "and i love the writing",
                "llm_score": -178.19076538085938,
                "old_lm_score": -27.638671875,
                "acoustic_score": -58.34960174560547,
                "combined_score": -132.08951950073242
              },
              {
                "candidate": "and i love the saying",
                "llm_score": -179.25531005859375,
                "old_lm_score": -31.23828125,
                "acoustic_score": -51.181427001953125,
                "combined_score": -130.83750915527344
              },
              {
                "candidate": "and i love this june",
                "llm_score": -186.92784118652344,
                "old_lm_score": -28.708984375,
                "acoustic_score": -56.30897521972656,
                "combined_score": -135.972900390625
              },
              {
                "candidate": "and i love the toys",
                "llm_score": -177.69590759277344,
                "old_lm_score": -27.1044921875,
                "acoustic_score": -59.538917541503906,
                "combined_score": -132.16965866088867
              },
              {
                "candidate": "and i love the eyes",
                "llm_score": -180.247802734375,
                "old_lm_score": -27.2734375,
                "acoustic_score": -59.24797058105469,
                "combined_score": -133.38460540771484
              },
              {
                "candidate": "and i love this lie",
                "llm_score": -183.12823486328125,
                "old_lm_score": -30.1982421875,
                "acoustic_score": -53.40925598144531,
                "combined_score": -133.36786651611328
              },
              {
                "candidate": "and i loved the tone",
                "llm_score": -183.140869140625,
                "old_lm_score": -28.3486328125,
                "acoustic_score": -57.12712097167969,
                "combined_score": -134.30831146240234
              },
              {
                "candidate": "and i love the rising",
                "llm_score": -180.4235382080078,
                "old_lm_score": -29.3310546875,
                "acoustic_score": -55.25752639770508,
                "combined_score": -132.50605964660645
              },
              {
                "candidate": "and i love the sighting",
                "llm_score": -184.8087158203125,
                "old_lm_score": -31.02734375,
                "acoustic_score": -51.89044952392578,
                "combined_score": -133.86325454711914
              }
            ],
            "selected": "and i love the line",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 2183.238394
        }
      ],
      "total_time_ms": 2277.336951999928
    },
    {
      "sentence_idx": 2,
      "ground_truth": "i do have a friend that ran",
      "top1_hypothesis": "i do have a friend that one",
      "final_decoded": "i do have a friend that one",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 2.363760000093862
    },
    {
      "sentence_idx": 3,
      "ground_truth": "just way in the back",
      "top1_hypothesis": "this way in the back",
      "final_decoded": "this way in the back",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.9990159999233583
    },
    {
      "sentence_idx": 4,
      "ground_truth": "actually it makes sense to a certain extent",
      "top1_hypothesis": "actually it makes sense to a certain extend",
      "final_decoded": "actually it makes sense to a certain extent",
      "was_changed": true,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "actually",
          "confusion_candidates": [
            {
              "word": "actually",
              "weight": 0.035292013634349924
            },
            {
              "word": "actual",
              "weight": 0.041302946309175026
            },
            {
              "word": "naturally",
              "weight": 7.636723716822996e-09
            },
            {
              "word": "see",
              "weight": 0.009268990082754846
            },
            {
              "word": "e",
              "weight": 0.9141360423359964
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.3751014862176656,
            "margin": 0.8728330960268214,
            "disagreement_mass": 0.08586395766400357
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "makes",
          "confusion_candidates": [
            {
              "word": "makes",
              "weight": 0.2641151163345973
            },
            {
              "word": "make",
              "weight": 0.7358848836644025
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5773173408607624,
            "margin": 0.47176976732980525,
            "disagreement_mass": 0.2641151163355975
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "actually it (makes OR make) sense to a certain extend",
            "retrieved_docs": [
              "That makes sense too.",
              "They're actually going to extend it.",
              "That diagram makes sense only after much study.",
              "It makes it convenient.",
              "A certain percentage.",
              "it's really hard to find something that works",
              "and i love the line",
              "i do have a friend that one",
              "this way in the back"
            ],
            "scores": [
              16.355107922999995,
              15.652354473053984,
              12.196316717889584,
              10.837823381453479,
              10.670065924974619,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 12.734152999996695
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 6,
          "span_end": 7,
          "top1_word": "certain",
          "confusion_candidates": [
            {
              "word": "certain",
              "weight": 0.9999026394137425
            },
            {
              "word": "student",
              "weight": 9.736058525756309e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0009966842452222944,
            "margin": 0.9998052788284849,
            "disagreement_mass": 9.73605862575333e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 7,
          "span_end": 8,
          "top1_word": "extend",
          "confusion_candidates": [
            {
              "word": "extend",
              "weight": 0.8390234556836593
            },
            {
              "word": "extent",
              "weight": 0.0029896147803616605
            },
            {
              "word": "action",
              "weight": 4.1036953492050734e-05
            },
            {
              "word": "kind",
              "weight": 8.776287935547474e-06
            },
            {
              "word": "and",
              "weight": 0.1573167733195892
            },
            {
              "word": "actions",
              "weight": 1.0890758703042348e-05
            },
            {
              "word": "second",
              "weight": 0.000604541667282024
            },
            {
              "word": "background",
              "weight": 4.910547977012443e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.46077789523223256,
            "margin": 0.6817066823640701,
            "disagreement_mass": 0.16097654431634068
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 8,
          "top1_word": "actually it makes sense to a certain extend",
          "confusion_candidates": [
            {
              "word": "actually it makes sense to a certain extend",
              "weight": -158.15604400634766
            },
            {
              "word": "actually it makes sense to a certain extent",
              "weight": -157.25814056396484
            },
            {
              "word": "actually it make sense to a certain extend",
              "weight": -160.47320556640625
            },
            {
              "word": "actually it make sense to a certain extent",
              "weight": -159.5717315673828
            },
            {
              "word": "actual it makes sense to a certain extend",
              "weight": -160.79251098632812
            },
            {
              "word": "actual it make sense to a certain extend",
              "weight": -162.16973876953125
            },
            {
              "word": "actual it makes sense to a certain extent",
              "weight": -159.8646469116211
            },
            {
              "word": "actual it make sense to a certain extent",
              "weight": -161.25872802734375
            },
            {
              "word": "actually it makes sense to a certain action",
              "weight": -162.83260345458984
            },
            {
              "word": "actually it makes sense to a certain kind",
              "weight": -161.28022003173828
            },
            {
              "word": "actually it makes sense to a certain act and",
              "weight": -160.75598907470703
            },
            {
              "word": "actually it makes sense to a certain actions",
              "weight": -164.81677627563477
            },
            {
              "word": "actually it makes sense to a certain second",
              "weight": -160.3991241455078
            },
            {
              "word": "naturally it makes sense to a certain extend",
              "weight": -167.99195098876953
            },
            {
              "word": "naturally it makes sense to a certain extent",
              "weight": -167.1556167602539
            },
            {
              "word": "actually it makes sense to a certain background",
              "weight": -163.37741088867188
            },
            {
              "word": "actually it make sense to a certain action",
              "weight": -165.10762786865234
            },
            {
              "word": "actual see it make sense to a certain extend",
              "weight": -165.85590362548828
            },
            {
              "word": "actual e it makes sense to a certain extend",
              "weight": -164.86898231506348
            },
            {
              "word": "actually it makes sense to a student second",
              "weight": -165.61305618286133
            },
            {
              "word": "actual e it make sense to a certain extend",
              "weight": -165.87410736083984
            },
            {
              "word": "actual see it make sense to a certain extent",
              "weight": -164.85259246826172
            },
            {
              "word": "actual e it makes sense to a certain extent",
              "weight": -164.21459197998047
            },
            {
              "word": "actual e it make sense to a certain extent",
              "weight": -165.21250534057617
            },
            {
              "word": "actually it make sense to a certain kind",
              "weight": -163.55075073242188
            },
            {
              "word": "actual it makes sense to a certain action",
              "weight": -165.51536560058594
            },
            {
              "word": "actually it make sense to a certain act and",
              "weight": -163.0519790649414
            },
            {
              "word": "actual it make sense to a certain action",
              "weight": -166.84485626220703
            },
            {
              "word": "actually it make sense to a certain actions",
              "weight": -167.11144638061523
            },
            {
              "word": "actually it make sense to a certain second",
              "weight": -162.73196411132812
            },
            {
              "word": "actual it makes sense to a certain kind",
              "weight": -163.9859619140625
            },
            {
              "word": "actual it makes sense to a certain act and",
              "weight": -163.44249725341797
            },
            {
              "word": "actual it make sense to a certain kind",
              "weight": -165.33800506591797
            },
            {
              "word": "actual it make sense to a certain act and",
              "weight": -164.8285369873047
            },
            {
              "word": "actual it makes sense to a certain actions",
              "weight": -167.4078254699707
            },
            {
              "word": "actually it make sense to a certain background",
              "weight": -165.6927947998047
            },
            {
              "word": "actual it makes sense to a certain second",
              "weight": -163.218017578125
            },
            {
              "word": "actually it make sense to a student second",
              "weight": -167.9120750427246
            },
            {
              "word": "actual it make sense to a certain actions",
              "weight": -168.7513313293457
            },
            {
              "word": "actual it make sense to a certain second",
              "weight": -164.63945770263672
            },
            {
              "word": "actual it makes sense to a certain background",
              "weight": -166.1470184326172
            },
            {
              "word": "actual it makes sense to a student second",
              "weight": -168.37218856811523
            },
            {
              "word": "actual it make sense to a certain background",
              "weight": -167.52860260009766
            },
            {
              "word": "actual it make sense to a student second",
              "weight": -169.79388809204102
            },
            {
              "word": "naturally it makes sense to a certain action",
              "weight": -172.6266860961914
            },
            {
              "word": "actual see it make sense to a certain action",
              "weight": -170.6650161743164
            },
            {
              "word": "actual e it makes sense to a certain action",
              "weight": -169.5644760131836
            },
            {
              "word": "naturally it makes sense to a certain kind",
              "weight": -171.14157104492188
            },
            {
              "word": "actual e it make sense to a certain action",
              "weight": -170.5466537475586
            },
            {
              "word": "naturally it makes sense to a certain act and",
              "weight": -170.50949096679688
            },
            {
              "word": "naturally it makes sense to a certain actions",
              "weight": -174.61763381958008
            },
            {
              "word": "actual see it make sense to a certain kind",
              "weight": -169.1577377319336
            },
            {
              "word": "actual e it makes sense to a certain kind",
              "weight": -168.05613708496094
            },
            {
              "word": "naturally it makes sense to a certain second",
              "weight": -170.40811157226562
            },
            {
              "word": "actual see it make sense to a certain act and",
              "weight": -168.55779266357422
            },
            {
              "word": "actual e it makes sense to a certain act and",
              "weight": -167.54212951660156
            },
            {
              "word": "actual e it make sense to a certain kind",
              "weight": -169.04439544677734
            },
            {
              "word": "actual e it make sense to a certain act and",
              "weight": -168.54557609558105
            },
            {
              "word": "actual see it make sense to a certain actions",
              "weight": -172.5663185119629
            },
            {
              "word": "actual e it makes sense to a certain actions",
              "weight": -171.51189041137695
            },
            {
              "word": "actual see it make sense to a certain second",
              "weight": -168.36973571777344
            },
            {
              "word": "naturally it makes sense to a certain background",
              "weight": -173.22161865234375
            },
            {
              "word": "actual e it makes sense to a certain second",
              "weight": -167.32221031188965
            },
            {
              "word": "actual e it make sense to a certain actions",
              "weight": -172.48516273498535
            },
            {
              "word": "naturally it makes sense to a student second",
              "weight": -175.67290115356445
            },
            {
              "word": "actual e it make sense to a certain second",
              "weight": -168.38530349731445
            },
            {
              "word": "actual see it make sense to a certain background",
              "weight": -171.20301055908203
            },
            {
              "word": "actual e it makes sense to a certain background",
              "weight": -170.22415161132812
            },
            {
              "word": "actual see it make sense to a student second",
              "weight": -173.55092239379883
            },
            {
              "word": "actual e it makes sense to a student second",
              "weight": -172.11907386779785
            },
            {
              "word": "actual e it make sense to a certain background",
              "weight": -171.25087356567383
            },
            {
              "word": "actual e it make sense to a student second",
              "weight": -173.15606117248535
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "That makes sense too.",
              "They're actually going to extend it.",
              "That diagram makes sense only after much study.",
              "It makes it convenient.",
              "A certain percentage.",
              "it's really hard to find something that works",
              "and i love the line",
              "i do have a friend that one",
              "this way in the back"
            ],
            "retrieval_time_ms": 12.734152999996695
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "actually it makes sense to a certain extend",
                "llm_score": -199.08560180664062,
                "old_lm_score": -39.412109375,
                "acoustic_score": -77.81437683105469,
                "combined_score": -158.15604400634766
              },
              {
                "candidate": "actually it makes sense to a certain extent",
                "llm_score": -191.65269470214844,
                "old_lm_score": -34.64453125,
                "acoustic_score": -88.21905517578125,
                "combined_score": -157.25814056396484
              },
              {
                "candidate": "actually it make sense to a certain extend",
                "llm_score": -202.8899383544922,
                "old_lm_score": -42.89453125,
                "acoustic_score": -75.16194152832031,
                "combined_score": -160.47320556640625
              },
              {
                "candidate": "actually it make sense to a certain extent",
                "llm_score": -195.44989013671875,
                "old_lm_score": -38.126953125,
                "acoustic_score": -85.56661987304688,
                "combined_score": -159.5717315673828
              },
              {
                "candidate": "actual it makes sense to a certain extend",
                "llm_score": -203.4942626953125,
                "old_lm_score": -44.501953125,
                "acoustic_score": -73.58880615234375,
                "combined_score": -160.79251098632812
              },
              {
                "candidate": "actual it make sense to a certain extend",
                "llm_score": -207.34353637695312,
                "old_lm_score": -46.0595703125,
                "acoustic_score": -70.93637084960938,
                "combined_score": -162.16973876953125
              },
              {
                "candidate": "actual it makes sense to a certain extent",
                "llm_score": -196.00143432617188,
                "old_lm_score": -39.734375,
                "acoustic_score": -83.99348449707031,
                "combined_score": -159.8646469116211
              },
              {
                "candidate": "actual it make sense to a certain extent",
                "llm_score": -199.88441467285156,
                "old_lm_score": -41.2919921875,
                "acoustic_score": -81.34104919433594,
                "combined_score": -161.25872802734375
              },
              {
                "candidate": "actually it makes sense to a certain action",
                "llm_score": -198.51319885253906,
                "old_lm_score": -40.73046875,
                "acoustic_score": -86.42153930664062,
                "combined_score": -162.83260345458984
              },
              {
                "candidate": "actually it makes sense to a certain kind",
                "llm_score": -193.8660125732422,
                "old_lm_score": -40.693359375,
                "acoustic_score": -88.00106811523438,
                "combined_score": -161.28022003173828
              },
              {
                "candidate": "actually it makes sense to a certain act and",
                "llm_score": -202.61151123046875,
                "old_lm_score": -50.896484375,
                "acoustic_score": -68.00398254394531,
                "combined_score": -160.75598907470703
              },
              {
                "candidate": "actually it makes sense to a certain actions",
                "llm_score": -201.1549835205078,
                "old_lm_score": -41.8876953125,
                "acoustic_score": -86.59087371826172,
                "combined_score": -164.81677627563477
              },
              {
                "candidate": "actually it makes sense to a certain second",
                "llm_score": -196.16062927246094,
                "old_lm_score": -46.11328125,
                "acoustic_score": -78.52433776855469,
                "combined_score": -160.3991241455078
              },
              {
                "candidate": "naturally it makes sense to a certain extend",
                "llm_score": -203.7731170654297,
                "old_lm_score": -38.8017578125,
                "acoustic_score": -93.40902709960938,
                "combined_score": -167.99195098876953
              },
              {
                "candidate": "naturally it makes sense to a certain extent",
                "llm_score": -196.46334838867188,
                "old_lm_score": -34.0341796875,
                "acoustic_score": -103.81370544433594,
                "combined_score": -167.1556167602539
              },
              {
                "candidate": "actually it makes sense to a certain background",
                "llm_score": -197.47972106933594,
                "old_lm_score": -42.7333984375,
                "acoustic_score": -86.54170227050781,
                "combined_score": -163.37741088867188
              },
              {
                "candidate": "actually it make sense to a certain action",
                "llm_score": -202.23326110839844,
                "old_lm_score": -44.212890625,
                "acoustic_score": -83.76910400390625,
                "combined_score": -165.10762786865234
              },
              {
                "candidate": "actual see it make sense to a certain extend",
                "llm_score": -213.51023864746094,
                "old_lm_score": -54.0615234375,
                "acoustic_score": -64.14004516601562,
                "combined_score": -165.85590362548828
              },
              {
                "candidate": "actual e it makes sense to a certain extend",
                "llm_score": -214.74424743652344,
                "old_lm_score": -57.3125,
                "acoustic_score": -57.681217193603516,
                "combined_score": -164.86898231506348
              },
              {
                "candidate": "actually it makes sense to a student second",
                "llm_score": -204.93804931640625,
                "old_lm_score": -46.1142578125,
                "acoustic_score": -80.1738052368164,
                "combined_score": -165.61305618286133
              },
              {
                "candidate": "actual e it make sense to a certain extend",
                "llm_score": -217.8493194580078,
                "old_lm_score": -58.8701171875,
                "acoustic_score": -55.028778076171875,
                "combined_score": -165.87410736083984
              },
              {
                "candidate": "actual see it make sense to a certain extent",
                "llm_score": -205.86651611328125,
                "old_lm_score": -49.2939453125,
                "acoustic_score": -74.54472351074219,
                "combined_score": -164.85259246826172
              },
              {
                "candidate": "actual e it makes sense to a certain extent",
                "llm_score": -207.79837036132812,
                "old_lm_score": -52.544921875,
                "acoustic_score": -68.08589172363281,
                "combined_score": -164.21459197998047
              },
              {
                "candidate": "actual e it make sense to a certain extent",
                "llm_score": -210.88902282714844,
                "old_lm_score": -54.1025390625,
                "acoustic_score": -65.4334487915039,
                "combined_score": -165.21250534057617
              },
              {
                "candidate": "actually it make sense to a certain kind",
                "llm_score": -197.57708740234375,
                "old_lm_score": -44.17578125,
                "acoustic_score": -85.3486328125,
                "combined_score": -163.55075073242188
              },
              {
                "candidate": "actual it makes sense to a certain action",
                "llm_score": -203.0144500732422,
                "old_lm_score": -45.8203125,
                "acoustic_score": -82.19596862792969,
                "combined_score": -165.51536560058594
              },
              {
                "candidate": "actually it make sense to a certain act and",
                "llm_score": -206.37350463867188,
                "old_lm_score": -54.37890625,
                "acoustic_score": -65.35154724121094,
                "combined_score": -163.0519790649414
              },
              {
                "candidate": "actual it make sense to a certain action",
                "llm_score": -206.76824951171875,
                "old_lm_score": -47.3779296875,
                "acoustic_score": -79.54353332519531,
                "combined_score": -166.84485626220703
              },
              {
                "candidate": "actually it make sense to a certain actions",
                "llm_score": -204.91433715820312,
                "old_lm_score": -45.3701171875,
                "acoustic_score": -83.93843841552734,
                "combined_score": -167.11144638061523
              },
              {
                "candidate": "actually it make sense to a certain second",
                "llm_score": -199.99632263183594,
                "old_lm_score": -49.595703125,
                "acoustic_score": -75.87190246582031,
                "combined_score": -162.73196411132812
              },
              {
                "candidate": "actual it makes sense to a certain kind",
                "llm_score": -198.41322326660156,
                "old_lm_score": -45.783203125,
                "acoustic_score": -83.77549743652344,
                "combined_score": -163.9859619140625
              },
              {
                "candidate": "actual it makes sense to a certain act and",
                "llm_score": -207.12025451660156,
                "old_lm_score": -55.986328125,
                "acoustic_score": -63.778411865234375,
                "combined_score": -163.44249725341797
              },
              {
                "candidate": "actual it make sense to a certain kind",
                "llm_score": -202.21212768554688,
                "old_lm_score": -47.3408203125,
                "acoustic_score": -81.12306213378906,
                "combined_score": -165.33800506591797
              },
              {
                "candidate": "actual it make sense to a certain act and",
                "llm_score": -210.98715209960938,
                "old_lm_score": -57.5439453125,
                "acoustic_score": -61.1259765625,
                "combined_score": -164.8285369873047
              },
              {
                "candidate": "actual it makes sense to a certain actions",
                "llm_score": -205.47280883789062,
                "old_lm_score": -46.9775390625,
                "acoustic_score": -82.36530303955078,
                "combined_score": -167.4078254699707
              },
              {
                "candidate": "actually it make sense to a certain background",
                "llm_score": -201.28050231933594,
                "old_lm_score": -46.2158203125,
                "acoustic_score": -83.88926696777344,
                "combined_score": -165.6927947998047
              },
              {
                "candidate": "actual it makes sense to a certain second",
                "llm_score": -200.93414306640625,
                "old_lm_score": -51.203125,
                "acoustic_score": -74.29876708984375,
                "combined_score": -163.218017578125
              },
              {
                "candidate": "actually it make sense to a student second",
                "llm_score": -208.7061004638672,
                "old_lm_score": -49.5966796875,
                "acoustic_score": -77.52136993408203,
                "combined_score": -167.9120750427246
              },
              {
                "candidate": "actual it make sense to a certain actions",
                "llm_score": -209.254638671875,
                "old_lm_score": -48.53515625,
                "acoustic_score": -79.7128677368164,
                "combined_score": -168.7513313293457
              },
              {
                "candidate": "actual it make sense to a certain second",
                "llm_score": -204.87184143066406,
                "old_lm_score": -52.7607421875,
                "acoustic_score": -71.64633178710938,
                "combined_score": -164.63945770263672
              },
              {
                "candidate": "actual it makes sense to a certain background",
                "llm_score": -202.1546630859375,
                "old_lm_score": -47.8232421875,
                "acoustic_score": -82.31613159179688,
                "combined_score": -166.1470184326172
              },
              {
                "candidate": "actual it makes sense to a student second",
                "llm_score": -209.592041015625,
                "old_lm_score": -51.2041015625,
                "acoustic_score": -75.94823455810547,
                "combined_score": -168.37218856811523
              },
              {
                "candidate": "actual it make sense to a certain background",
                "llm_score": -206.0126495361328,
                "old_lm_score": -49.380859375,
                "acoustic_score": -79.6636962890625,
                "combined_score": -167.52860260009766
              },
              {
                "candidate": "actual it make sense to a student second",
                "llm_score": -213.53025817871094,
                "old_lm_score": -52.76171875,
                "acoustic_score": -73.2957992553711,
                "combined_score": -169.79388809204102
              },
              {
                "candidate": "naturally it makes sense to a certain action",
                "llm_score": -203.1170654296875,
                "old_lm_score": -40.1201171875,
                "acoustic_score": -102.01618957519531,
                "combined_score": -172.6266860961914
              },
              {
                "candidate": "actual see it make sense to a certain action",
                "llm_score": -213.20294189453125,
                "old_lm_score": -55.3798828125,
                "acoustic_score": -72.74720764160156,
                "combined_score": -170.6650161743164
              },
              {
                "candidate": "actual e it makes sense to a certain action",
                "llm_score": -214.209716796875,
                "old_lm_score": -58.630859375,
                "acoustic_score": -66.28837585449219,
                "combined_score": -169.5644760131836
              },
              {
                "candidate": "naturally it makes sense to a certain kind",
                "llm_score": -198.6044158935547,
                "old_lm_score": -40.0830078125,
                "acoustic_score": -103.59571838378906,
                "combined_score": -171.14157104492188
              },
              {
                "candidate": "actual e it make sense to a certain action",
                "llm_score": -217.26889038085938,
                "old_lm_score": -60.1884765625,
                "acoustic_score": -63.63594055175781,
                "combined_score": -170.5466537475586
              },
              {
                "candidate": "naturally it makes sense to a certain act and",
                "llm_score": -207.13421630859375,
                "old_lm_score": -50.2861328125,
                "acoustic_score": -83.5986328125,
                "combined_score": -170.50949096679688
              },
              {
                "candidate": "naturally it makes sense to a certain actions",
                "llm_score": -205.77239990234375,
                "old_lm_score": -41.27734375,
                "acoustic_score": -102.1855239868164,
                "combined_score": -174.61763381958008
              },
              {
                "candidate": "actual see it make sense to a certain kind",
                "llm_score": -208.64596557617188,
                "old_lm_score": -55.3427734375,
                "acoustic_score": -74.32673645019531,
                "combined_score": -169.1577377319336
              },
              {
                "candidate": "actual e it makes sense to a certain kind",
                "llm_score": -209.65061950683594,
                "old_lm_score": -58.59375,
                "acoustic_score": -67.86790466308594,
                "combined_score": -168.05613708496094
              },
              {
                "candidate": "naturally it makes sense to a certain second",
                "llm_score": -201.19430541992188,
                "old_lm_score": -45.5029296875,
                "acoustic_score": -94.11898803710938,
                "combined_score": -170.40811157226562
              },
              {
                "candidate": "actual see it make sense to a certain act and",
                "llm_score": -217.2400360107422,
                "old_lm_score": -65.5458984375,
                "acoustic_score": -54.32965087890625,
                "combined_score": -168.55779266357422
              },
              {
                "candidate": "actual e it makes sense to a certain act and",
                "llm_score": -218.41656494140625,
                "old_lm_score": -68.796875,
                "acoustic_score": -47.870819091796875,
                "combined_score": -167.54212951660156
              },
              {
                "candidate": "actual e it make sense to a certain kind",
                "llm_score": -212.72195434570312,
                "old_lm_score": -60.1513671875,
                "acoustic_score": -65.21546936035156,
                "combined_score": -169.04439544677734
              },
              {
                "candidate": "actual e it make sense to a certain act and",
                "llm_score": -221.51828002929688,
                "old_lm_score": -70.3544921875,
                "acoustic_score": -45.218379974365234,
                "combined_score": -168.54557609558105
              },
              {
                "candidate": "actual see it make sense to a certain actions",
                "llm_score": -215.67898559570312,
                "old_lm_score": -56.537109375,
                "acoustic_score": -72.91654205322266,
                "combined_score": -172.5663185119629
              },
              {
                "candidate": "actual e it makes sense to a certain actions",
                "llm_score": -216.77798461914062,
                "old_lm_score": -59.7880859375,
                "acoustic_score": -66.45771026611328,
                "combined_score": -171.51189041137695
              },
              {
                "candidate": "actual see it make sense to a certain second",
                "llm_score": -211.12677001953125,
                "old_lm_score": -60.7626953125,
                "acoustic_score": -64.85000610351562,
                "combined_score": -168.36973571777344
              },
              {
                "candidate": "naturally it makes sense to a certain background",
                "llm_score": -202.183837890625,
                "old_lm_score": -42.123046875,
                "acoustic_score": -102.1363525390625,
                "combined_score": -173.22161865234375
              },
              {
                "candidate": "actual e it makes sense to a certain second",
                "llm_score": -212.2395782470703,
                "old_lm_score": -64.013671875,
                "acoustic_score": -58.391170501708984,
                "combined_score": -167.32221031188965
              },
              {
                "candidate": "actual e it make sense to a certain actions",
                "llm_score": -219.81935119628906,
                "old_lm_score": -61.345703125,
                "acoustic_score": -63.80527114868164,
                "combined_score": -172.48516273498535
              },
              {
                "candidate": "naturally it makes sense to a student second",
                "llm_score": -210.0734405517578,
                "old_lm_score": -45.50390625,
                "acoustic_score": -95.7684555053711,
                "combined_score": -175.67290115356445
              },
              {
                "candidate": "actual e it make sense to a certain second",
                "llm_score": -215.46058654785156,
                "old_lm_score": -65.5712890625,
                "acoustic_score": -55.738731384277344,
                "combined_score": -168.38530349731445
              },
              {
                "candidate": "actual see it make sense to a certain background",
                "llm_score": -212.1558380126953,
                "old_lm_score": -57.3828125,
                "acoustic_score": -72.86737060546875,
                "combined_score": -171.20301055908203
              },
              {
                "candidate": "actual e it makes sense to a certain background",
                "llm_score": -213.40597534179688,
                "old_lm_score": -60.6337890625,
                "acoustic_score": -66.40853881835938,
                "combined_score": -170.22415161132812
              },
              {
                "candidate": "actual see it make sense to a student second",
                "llm_score": -219.8386993408203,
                "old_lm_score": -60.763671875,
                "acoustic_score": -66.49947357177734,
                "combined_score": -173.55092239379883
              },
              {
                "candidate": "actual e it makes sense to a student second",
                "llm_score": -220.182861328125,
                "old_lm_score": -64.0146484375,
                "acoustic_score": -60.0406379699707,
                "combined_score": -172.11907386779785
              },
              {
                "candidate": "actual e it make sense to a certain background",
                "llm_score": -216.5542449951172,
                "old_lm_score": -62.19140625,
                "acoustic_score": -63.75609588623047,
                "combined_score": -171.25087356567383
              },
              {
                "candidate": "actual e it make sense to a student second",
                "llm_score": -223.35165405273438,
                "old_lm_score": -65.572265625,
                "acoustic_score": -57.38820266723633,
                "combined_score": -173.15606117248535
              }
            ],
            "selected": "actually it makes sense to a certain extent",
            "selected_index": 1,
            "changed_from_top1": true,
            "change_was_correct": true
          },
          "time_ms": 1402.7570220000598
        }
      ],
      "total_time_ms": 1420.9693490000745
    },
    {
      "sentence_idx": 5,
      "ground_truth": "assure the government that he was employed",
      "top1_hypothesis": "just the government that he was employed",
      "final_decoded": "just the government that he was employed",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "just",
          "confusion_candidates": [
            {
              "word": "just",
              "weight": 0.6765994374431107
            },
            {
              "word": "so",
              "weight": 0.029350278614040354
            },
            {
              "word": "thus",
              "weight": 0.06895355490627533
            },
            {
              "word": "to",
              "weight": 0.16123841582439957
            },
            {
              "word": "also",
              "weight": 0.0005173251988477461
            },
            {
              "word": "us",
              "weight": 0.04372567326414023
            },
            {
              "word": "what",
              "weight": 0.0003261160166007761
            },
            {
              "word": "but",
              "weight": 3.680715192132127e-06
            },
            {
              "word": "it's",
              "weight": 8.93928031337463e-07
            },
            {
              "word": "the",
              "weight": 4.233472361710495e-06
            },
            {
              "word": "see",
              "weight": 2.8757067269051802e-05
            },
            {
              "word": "this",
              "weight": 5.931546117961823e-06
            },
            {
              "word": "dust",
              "weight": 0.0010306828912487079
            },
            {
              "word": "whilst",
              "weight": 5.3358593322509685e-06
            },
            {
              "word": "a",
              "weight": 3.986811610574925e-06
            },
            {
              "word": "stir",
              "weight": 1.9305833085742005e-05
            },
            {
              "word": "and",
              "weight": 6.581012531574031e-08
            },
            {
              "word": "use",
              "weight": 3.44598348526456e-06
            },
            {
              "word": "at",
              "weight": 2.954089361732064e-07
            },
            {
              "word": "must",
              "weight": 3.35655498603573e-05
            },
            {
              "word": "au",
              "weight": 0.01133682596208604
            },
            {
              "word": "once",
              "weight": 2.1331470844668852e-07
            },
            {
              "word": "while",
              "weight": 2.1131170623282438e-08
            },
            {
              "word": "slow",
              "weight": 0.005631460996463128
            },
            {
              "word": "ulster",
              "weight": 0.0010180913533199805
            },
            {
              "word": "assert",
              "weight": 0.0001561329392919772
            },
            {
              "word": "that",
              "weight": 3.4713083525692885e-08
            },
            {
              "word": "'s",
              "weight": 1.5276867975417304e-06
            },
            {
              "word": "sew",
              "weight": 4.101923911348401e-06
            },
            {
              "word": "c",
              "weight": 1.5291027980937393e-07
            },
            {
              "word": "trust",
              "weight": 4.54923816379134e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.0866324078551617,
            "margin": 0.5153610216187111,
            "disagreement_mass": 0.3234005625568893
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(just OR so OR thus OR to OR also OR us OR what OR but OR it's OR the OR see OR this OR dust OR whilst OR a OR stir OR and OR use OR at OR must OR au OR once OR while OR slow OR ulster OR assert OR that OR 's OR sew OR c OR trust) the government that he was",
            "retrieved_docs": [
              "But it's slow burning.",
              "But also while I was growing up.",
              "Once that was accomplished.",
              "That is true, but it also misses the point.",
              "So that was upsetting.",
              "it's really hard to find something that works",
              "and i love the line",
              "i do have a friend that one",
              "this way in the back",
              "actually it makes sense to a certain extent"
            ],
            "scores": [
              17.837434234574683,
              17.456501171720966,
              16.413183441906604,
              14.178940474229272,
              14.172903537086807,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 43.76038999998855
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "the",
          "confusion_candidates": [
            {
              "word": "the",
              "weight": 0.9999988917536374
            },
            {
              "word": "a",
              "weight": 1.1082453624412189e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.630531600110226e-05,
            "margin": 0.999997783508275,
            "disagreement_mass": 1.1082463625688987e-06
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "government",
          "confusion_candidates": [
            {
              "word": "government",
              "weight": 0.9999888094227664
            },
            {
              "word": "goverment",
              "weight": 1.1190576233590276e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.00013876798921461718,
            "margin": 0.9999776188465328,
            "disagreement_mass": 1.1190577233644028e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "he",
          "confusion_candidates": [
            {
              "word": "he",
              "weight": 0.9999390180549923
            },
            {
              "word": "she",
              "weight": 5.527720933280322e-05
            },
            {
              "word": "i",
              "weight": 5.704734674884452e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0006717510373761751,
            "margin": 0.9998837408456595,
            "disagreement_mass": 6.098194500769871e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 6,
          "span_end": 7,
          "top1_word": "employed",
          "confusion_candidates": [
            {
              "word": "employed",
              "weight": 0.9999672937604459
            },
            {
              "word": "implied",
              "weight": 3.2706238553926025e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0003704939263783865,
            "margin": 0.999934587521892,
            "disagreement_mass": 3.270623955409224e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 7,
          "top1_word": "just the government that he was employed",
          "confusion_candidates": [
            {
              "word": "just the government that he was employed",
              "weight": -156.11106872558594
            },
            {
              "word": "so the government that he was employed",
              "weight": -157.35237884521484
            },
            {
              "word": "thus the government that he was employed",
              "weight": -158.35945892333984
            },
            {
              "word": "the government that he was employed",
              "weight": -160.15856170654297
            },
            {
              "word": "us to the government that he was employed",
              "weight": -159.65557861328125
            },
            {
              "word": "also the government that he was employed",
              "weight": -159.0837059020996
            },
            {
              "word": "us the government that he was employed",
              "weight": -159.69794082641602
            },
            {
              "word": "what the government that he was employed",
              "weight": -159.77399826049805
            },
            {
              "word": "but the government that he was employed",
              "weight": -160.78632736206055
            },
            {
              "word": "it's the government that he was employed",
              "weight": -163.2311248779297
            },
            {
              "word": "the the government that he was employed",
              "weight": -162.94996643066406
            },
            {
              "word": "the to the government that he was employed",
              "weight": -163.44012832641602
            },
            {
              "word": "just the government that she was employed",
              "weight": -161.59116744995117
            },
            {
              "word": "see the government that he was employed",
              "weight": -164.60988235473633
            },
            {
              "word": "the so the government that he was employed",
              "weight": -161.94091796875
            },
            {
              "word": "so the government that she was employed",
              "weight": -162.66167068481445
            },
            {
              "word": "to the government that he was employed",
              "weight": -162.31068801879883
            },
            {
              "word": "this the government that he was employed",
              "weight": -163.2824363708496
            },
            {
              "word": "dust the government that he was employed",
              "weight": -163.04547882080078
            },
            {
              "word": "thus to the government that he was employed",
              "weight": -161.59440231323242
            },
            {
              "word": "whilst the government that he was employed",
              "weight": -164.06084060668945
            },
            {
              "word": "a the government that he was employed",
              "weight": -163.49568557739258
            },
            {
              "word": "stir the government that he was employed",
              "weight": -165.94143676757812
            },
            {
              "word": "and the government that he was employed",
              "weight": -162.3322639465332
            },
            {
              "word": "use the government that he was employed",
              "weight": -164.0112419128418
            },
            {
              "word": "this to the government that he was employed",
              "weight": -164.38197708129883
            },
            {
              "word": "a to the government that he was employed",
              "weight": -163.9016876220703
            },
            {
              "word": "at the government that he was employed",
              "weight": -162.65199661254883
            },
            {
              "word": "just the government that he was implied",
              "weight": -163.71178436279297
            },
            {
              "word": "must the government that he was employed",
              "weight": -164.24751663208008
            },
            {
              "word": "us au the government that he was employed",
              "weight": -166.3907585144043
            },
            {
              "word": "just the government that i was employed",
              "weight": -162.9045524597168
            },
            {
              "word": "thus the government that she was employed",
              "weight": -163.650634765625
            },
            {
              "word": "once the government that he was employed",
              "weight": -164.35807418823242
            },
            {
              "word": "just to the government that he was employed",
              "weight": -162.31982803344727
            },
            {
              "word": "while the government that he was employed",
              "weight": -165.01900482177734
            },
            {
              "word": "just a government that he was employed",
              "weight": -163.52409744262695
            },
            {
              "word": "i see the government that he was employed",
              "weight": -164.44001007080078
            },
            {
              "word": "a so the government that he was employed",
              "weight": -162.0627784729004
            },
            {
              "word": "a slow the government that he was employed",
              "weight": -166.01448440551758
            },
            {
              "word": "ulster the government that he was employed",
              "weight": -166.00142288208008
            },
            {
              "word": "assert the government that he was employed",
              "weight": -163.97967529296875
            },
            {
              "word": "that the government that he was employed",
              "weight": -162.46121978759766
            },
            {
              "word": "so the government that he was implied",
              "weight": -165.18668365478516
            },
            {
              "word": "so the goverment that he was employed",
              "weight": -163.4209213256836
            },
            {
              "word": "'s the government that he was employed",
              "weight": -163.27954864501953
            },
            {
              "word": "so the government that i was employed",
              "weight": -163.90176010131836
            },
            {
              "word": "sew the government that he was employed",
              "weight": -166.76610565185547
            },
            {
              "word": "c the government that he was employed",
              "weight": -165.58639907836914
            },
            {
              "word": "the government that she was employed",
              "weight": -165.5687713623047
            },
            {
              "word": "the slow the government that he was employed",
              "weight": -164.50277709960938
            },
            {
              "word": "trust the government that he was employed",
              "weight": -164.4135513305664
            },
            {
              "word": "thus the government that he was implied",
              "weight": -166.10316467285156
            },
            {
              "word": "us to the government that she was employed",
              "weight": -165.04352951049805
            },
            {
              "word": "thus the government that i was employed",
              "weight": -164.8388786315918
            },
            {
              "word": "us the government that she was employed",
              "weight": -165.2940444946289
            },
            {
              "word": "also the government that she was employed",
              "weight": -164.53450775146484
            },
            {
              "word": "what the government that she was employed",
              "weight": -165.1570816040039
            },
            {
              "word": "the government that he was implied",
              "weight": -168.13148498535156
            },
            {
              "word": "the government that i was employed",
              "weight": -166.80941009521484
            },
            {
              "word": "but the government that she was employed",
              "weight": -166.02223205566406
            },
            {
              "word": "us to the government that he was implied",
              "weight": -167.01217651367188
            },
            {
              "word": "us to the government that i was employed",
              "weight": -165.93873596191406
            },
            {
              "word": "also the government that he was implied",
              "weight": -167.0320053100586
            },
            {
              "word": "us the government that he was implied",
              "weight": -167.4471092224121
            },
            {
              "word": "it's the government that she was employed",
              "weight": -168.42353057861328
            },
            {
              "word": "us the government that i was employed",
              "weight": -166.33763122558594
            },
            {
              "word": "what the government that he was implied",
              "weight": -167.81936645507812
            },
            {
              "word": "also the government that i was employed",
              "weight": -165.8525390625
            },
            {
              "word": "what the government that i was employed",
              "weight": -166.4925537109375
            },
            {
              "word": "the the government that she was employed",
              "weight": -168.41609573364258
            },
            {
              "word": "the to the government that she was employed",
              "weight": -168.84437561035156
            },
            {
              "word": "see the government that she was employed",
              "weight": -169.84578704833984
            },
            {
              "word": "the so the government that she was employed",
              "weight": -167.3773307800293
            },
            {
              "word": "but the government that he was implied",
              "weight": -168.9632568359375
            },
            {
              "word": "but the government that i was employed",
              "weight": -167.4526252746582
            },
            {
              "word": "to the government that she was employed",
              "weight": -167.52072143554688
            },
            {
              "word": "this the government that she was employed",
              "weight": -168.7742156982422
            },
            {
              "word": "dust the government that she was employed",
              "weight": -168.6315040588379
            },
            {
              "word": "it's the government that he was implied",
              "weight": -170.00969696044922
            },
            {
              "word": "thus to the government that she was employed",
              "weight": -166.93669891357422
            },
            {
              "word": "it's the government that i was employed",
              "weight": -169.4460906982422
            },
            {
              "word": "whilst the government that she was employed",
              "weight": -169.3723373413086
            },
            {
              "word": "a the government that she was employed",
              "weight": -168.77259826660156
            },
            {
              "word": "stir the government that she was employed",
              "weight": -171.2859764099121
            },
            {
              "word": "and the government that she was employed",
              "weight": -167.6580047607422
            },
            {
              "word": "use the government that she was employed",
              "weight": -169.28810119628906
            },
            {
              "word": "the the government that he was implied",
              "weight": -170.67584991455078
            },
            {
              "word": "the the government that i was employed",
              "weight": -169.32841873168945
            },
            {
              "word": "at the government that she was employed",
              "weight": -167.86856842041016
            },
            {
              "word": "this to the government that she was employed",
              "weight": -169.77722930908203
            },
            {
              "word": "the to the government that he was implied",
              "weight": -170.61712646484375
            },
            {
              "word": "a to the government that she was employed",
              "weight": -169.1549530029297
            },
            {
              "word": "must the government that she was employed",
              "weight": -169.4181137084961
            },
            {
              "word": "us au the government that she was employed",
              "weight": -171.81456756591797
            },
            {
              "word": "the to the government that i was employed",
              "weight": -169.4861602783203
            },
            {
              "word": "once the government that she was employed",
              "weight": -169.6602325439453
            },
            {
              "word": "see the government that he was implied",
              "weight": -172.2669906616211
            },
            {
              "word": "see the government that i was employed",
              "weight": -171.39685440063477
            },
            {
              "word": "while the government that she was employed",
              "weight": -170.32283782958984
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "But it's slow burning.",
              "But also while I was growing up.",
              "Once that was accomplished.",
              "That is true, but it also misses the point.",
              "So that was upsetting.",
              "it's really hard to find something that works",
              "and i love the line",
              "i do have a friend that one",
              "this way in the back",
              "actually it makes sense to a certain extent"
            ],
            "retrieval_time_ms": 43.76038999998855
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "just the government that he was employed",
                "llm_score": -205.98707580566406,
                "old_lm_score": -39.62890625,
                "acoustic_score": -66.60615539550781,
                "combined_score": -156.11106872558594
              },
              {
                "candidate": "so the government that he was employed",
                "llm_score": -203.5306854248047,
                "old_lm_score": -36.2392578125,
                "acoustic_score": -74.934814453125,
                "combined_score": -157.35237884521484
              },
              {
                "candidate": "thus the government that he was employed",
                "llm_score": -208.20025634765625,
                "old_lm_score": -40.7392578125,
                "acoustic_score": -67.77940368652344,
                "combined_score": -158.35945892333984
              },
              {
                "candidate": "the government that he was employed",
                "llm_score": -199.80612182617188,
                "old_lm_score": -30.2685546875,
                "acoustic_score": -90.24244689941406,
                "combined_score": -160.15856170654297
              },
              {
                "candidate": "us to the government that he was employed",
                "llm_score": -211.63299560546875,
                "old_lm_score": -44.521484375,
                "acoustic_score": -63.15667724609375,
                "combined_score": -159.65557861328125
              },
              {
                "candidate": "also the government that he was employed",
                "llm_score": -204.75624084472656,
                "old_lm_score": -39.4384765625,
                "acoustic_score": -73.97269439697266,
                "combined_score": -159.0837059020996
              },
              {
                "candidate": "us the government that he was employed",
                "llm_score": -210.42172241210938,
                "old_lm_score": -44.0078125,
                "acoustic_score": -64.96634674072266,
                "combined_score": -159.69794082641602
              },
              {
                "candidate": "what the government that he was employed",
                "llm_score": -205.67539978027344,
                "old_lm_score": -39.2216796875,
                "acoustic_score": -74.65091705322266,
                "combined_score": -159.77399826049805
              },
              {
                "candidate": "but the government that he was employed",
                "llm_score": -203.21591186523438,
                "old_lm_score": -36.5478515625,
                "acoustic_score": -81.80889129638672,
                "combined_score": -160.78632736206055
              },
              {
                "candidate": "it's the government that he was employed",
                "llm_score": -206.69027709960938,
                "old_lm_score": -36.1337890625,
                "acoustic_score": -83.63818359375,
                "combined_score": -163.2311248779297
              },
              {
                "candidate": "the the government that he was employed",
                "llm_score": -207.68310546875,
                "old_lm_score": -38.2216796875,
                "acoustic_score": -79.99514770507812,
                "combined_score": -162.94996643066406
              },
              {
                "candidate": "the to the government that he was employed",
                "llm_score": -210.77037048339844,
                "old_lm_score": -40.7431640625,
                "acoustic_score": -75.3667221069336,
                "combined_score": -163.44012832641602
              },
              {
                "candidate": "just the government that she was employed",
                "llm_score": -207.14584350585938,
                "old_lm_score": -41.0048828125,
                "acoustic_score": -75.03160858154297,
                "combined_score": -161.59116744995117
              },
              {
                "candidate": "see the government that he was employed",
                "llm_score": -209.91551208496094,
                "old_lm_score": -37.923828125,
                "acoustic_score": -81.38042449951172,
                "combined_score": -164.60988235473633
              },
              {
                "candidate": "the so the government that he was employed",
                "llm_score": -213.6646270751953,
                "old_lm_score": -47.689453125,
                "acoustic_score": -62.52775573730469,
                "combined_score": -161.94091796875
              },
              {
                "candidate": "so the government that she was employed",
                "llm_score": -204.46112060546875,
                "old_lm_score": -37.501953125,
                "acoustic_score": -83.36026763916016,
                "combined_score": -162.66167068481445
              },
              {
                "candidate": "to the government that he was employed",
                "llm_score": -202.91192626953125,
                "old_lm_score": -36.6826171875,
                "acoustic_score": -85.0268325805664,
                "combined_score": -162.31068801879883
              },
              {
                "candidate": "this the government that he was employed",
                "llm_score": -208.6853485107422,
                "old_lm_score": -40.75,
                "acoustic_score": -77.12952423095703,
                "combined_score": -163.2824363708496
              },
              {
                "candidate": "dust the government that he was employed",
                "llm_score": -213.36912536621094,
                "old_lm_score": -46.033203125,
                "acoustic_score": -66.68862915039062,
                "combined_score": -163.04547882080078
              },
              {
                "candidate": "thus to the government that he was employed",
                "llm_score": -210.7454376220703,
                "old_lm_score": -46.4736328125,
                "acoustic_score": -65.96973419189453,
                "combined_score": -161.59440231323242
              },
              {
                "candidate": "whilst the government that he was employed",
                "llm_score": -210.13632202148438,
                "old_lm_score": -41.3330078125,
                "acoustic_score": -76.65235137939453,
                "combined_score": -164.06084060668945
              },
              {
                "candidate": "a the government that he was employed",
                "llm_score": -208.7145538330078,
                "old_lm_score": -41.0947265625,
                "acoustic_score": -77.18209075927734,
                "combined_score": -163.49568557739258
              },
              {
                "candidate": "stir the government that he was employed",
                "llm_score": -215.1834716796875,
                "old_lm_score": -42.6728515625,
                "acoustic_score": -74.02655029296875,
                "combined_score": -165.94143676757812
              },
              {
                "candidate": "and the government that he was employed",
                "llm_score": -202.2837371826172,
                "old_lm_score": -37.0537109375,
                "acoustic_score": -85.32707977294922,
                "combined_score": -162.3322639465332
              },
              {
                "candidate": "use the government that he was employed",
                "llm_score": -209.59988403320312,
                "old_lm_score": -41.05078125,
                "acoustic_score": -77.37181854248047,
                "combined_score": -164.0112419128418
              },
              {
                "candidate": "this to the government that he was employed",
                "llm_score": -211.259521484375,
                "old_lm_score": -42.1845703125,
                "acoustic_score": -75.31986236572266,
                "combined_score": -164.38197708129883
              },
              {
                "candidate": "a to the government that he was employed",
                "llm_score": -211.6334991455078,
                "old_lm_score": -43.6162109375,
                "acoustic_score": -72.55366516113281,
                "combined_score": -163.9016876220703
              },
              {
                "candidate": "at the government that he was employed",
                "llm_score": -204.42478942871094,
                "old_lm_score": -39.0126953125,
                "acoustic_score": -81.86650848388672,
                "combined_score": -162.65199661254883
              },
              {
                "candidate": "just the government that he was implied",
                "llm_score": -210.9069366455078,
                "old_lm_score": -43.4013671875,
                "acoustic_score": -73.11526489257812,
                "combined_score": -163.71178436279297
              },
              {
                "candidate": "must the government that he was employed",
                "llm_score": -212.34872436523438,
                "old_lm_score": -43.962890625,
                "acoustic_score": -72.18341827392578,
                "combined_score": -164.24751663208008
              },
              {
                "candidate": "us au the government that he was employed",
                "llm_score": -222.45751953125,
                "old_lm_score": -49.802734375,
                "acoustic_score": -60.521263122558594,
                "combined_score": -166.3907585144043
              },
              {
                "candidate": "just the government that i was employed",
                "llm_score": -207.53269958496094,
                "old_lm_score": -41.9296875,
                "acoustic_score": -76.34671783447266,
                "combined_score": -162.9045524597168
              },
              {
                "candidate": "thus the government that she was employed",
                "llm_score": -209.09446716308594,
                "old_lm_score": -42.001953125,
                "acoustic_score": -76.20484924316406,
                "combined_score": -163.650634765625
              },
              {
                "candidate": "once the government that he was employed",
                "llm_score": -207.5113525390625,
                "old_lm_score": -39.068359375,
                "acoustic_score": -82.13643646240234,
                "combined_score": -164.35807418823242
              },
              {
                "candidate": "just to the government that he was employed",
                "llm_score": -208.5416717529297,
                "old_lm_score": -44.5732421875,
                "acoustic_score": -71.52474212646484,
                "combined_score": -162.31982803344727
              },
              {
                "candidate": "while the government that he was employed",
                "llm_score": -206.5211944580078,
                "old_lm_score": -37.2421875,
                "acoustic_score": -86.27462768554688,
                "combined_score": -165.01900482177734
              },
              {
                "candidate": "just a government that he was employed",
                "llm_score": -207.49122619628906,
                "old_lm_score": -41.203125,
                "acoustic_score": -78.35384368896484,
                "combined_score": -163.52409744262695
              },
              {
                "candidate": "i see the government that he was employed",
                "llm_score": -212.52825927734375,
                "old_lm_score": -44.453125,
                "acoustic_score": -71.89863586425781,
                "combined_score": -164.44001007080078
              },
              {
                "candidate": "a so the government that he was employed",
                "llm_score": -213.84835815429688,
                "old_lm_score": -50.5625,
                "acoustic_score": -59.714698791503906,
                "combined_score": -162.0627784729004
              },
              {
                "candidate": "a slow the government that he was employed",
                "llm_score": -220.84678649902344,
                "old_lm_score": -49.86328125,
                "acoustic_score": -61.31890106201172,
                "combined_score": -166.01448440551758
              },
              {
                "candidate": "ulster the government that he was employed",
                "llm_score": -219.26878356933594,
                "old_lm_score": -48.3427734375,
                "acoustic_score": -64.39128875732422,
                "combined_score": -166.00142288208008
              },
              {
                "candidate": "assert the government that he was employed",
                "llm_score": -213.35031127929688,
                "old_lm_score": -46.6318359375,
                "acoustic_score": -67.97720336914062,
                "combined_score": -163.97967529296875
              },
              {
                "candidate": "that the government that he was employed",
                "llm_score": -201.9020538330078,
                "old_lm_score": -38.3408203125,
                "acoustic_score": -84.6795654296875,
                "combined_score": -162.46121978759766
              },
              {
                "candidate": "so the government that he was implied",
                "llm_score": -208.917724609375,
                "old_lm_score": -40.01171875,
                "acoustic_score": -81.44392395019531,
                "combined_score": -165.18668365478516
              },
              {
                "candidate": "so the goverment that he was employed",
                "llm_score": -209.59716796875,
                "old_lm_score": -44.2861328125,
                "acoustic_score": -72.95854187011719,
                "combined_score": -163.4209213256836
              },
              {
                "candidate": "'s the government that he was employed",
                "llm_score": -207.32310485839844,
                "old_lm_score": -42.3095703125,
                "acoustic_score": -76.92642211914062,
                "combined_score": -163.27954864501953
              },
              {
                "candidate": "so the government that i was employed",
                "llm_score": -204.69259643554688,
                "old_lm_score": -38.435546875,
                "acoustic_score": -84.67537689208984,
                "combined_score": -163.90176010131836
              },
              {
                "candidate": "sew the government that he was employed",
                "llm_score": -215.28392028808594,
                "old_lm_score": -43.3134765625,
                "acoustic_score": -74.934814453125,
                "combined_score": -166.76610565185547
              },
              {
                "candidate": "c the government that he was employed",
                "llm_score": -209.63514709472656,
                "old_lm_score": -40.1572265625,
                "acoustic_score": -81.38042449951172,
                "combined_score": -165.58639907836914
              },
              {
                "candidate": "the government that she was employed",
                "llm_score": -200.93838500976562,
                "old_lm_score": -31.53125,
                "acoustic_score": -98.66790771484375,
                "combined_score": -165.5687713623047
              },
              {
                "candidate": "the slow the government that he was employed",
                "llm_score": -216.06207275390625,
                "old_lm_score": -48.8115234375,
                "acoustic_score": -64.1319580078125,
                "combined_score": -164.50277709960938
              },
              {
                "candidate": "trust the government that he was employed",
                "llm_score": -208.37973022460938,
                "old_lm_score": -41.4052734375,
                "acoustic_score": -79.04209899902344,
                "combined_score": -164.4135513305664
              },
              {
                "candidate": "thus the government that he was implied",
                "llm_score": -213.40609741210938,
                "old_lm_score": -44.51171875,
                "acoustic_score": -74.28851318359375,
                "combined_score": -166.10316467285156
              },
              {
                "candidate": "us to the government that she was employed",
                "llm_score": -212.6074676513672,
                "old_lm_score": -45.8974609375,
                "acoustic_score": -71.5821304321289,
                "combined_score": -165.04352951049805
              },
              {
                "candidate": "thus the government that i was employed",
                "llm_score": -209.2222442626953,
                "old_lm_score": -42.935546875,
                "acoustic_score": -77.51996612548828,
                "combined_score": -164.8388786315918
              },
              {
                "candidate": "us the government that she was employed",
                "llm_score": -211.92578125,
                "old_lm_score": -45.2705078125,
                "acoustic_score": -73.39179992675781,
                "combined_score": -165.2940444946289
              },
              {
                "candidate": "also the government that she was employed",
                "llm_score": -205.85641479492188,
                "old_lm_score": -40.814453125,
                "acoustic_score": -82.39814758300781,
                "combined_score": -164.53450775146484
              },
              {
                "candidate": "what the government that she was employed",
                "llm_score": -206.75341796875,
                "old_lm_score": -40.484375,
                "acoustic_score": -83.07637023925781,
                "combined_score": -165.1570816040039
              },
              {
                "candidate": "the government that he was implied",
                "llm_score": -205.47039794921875,
                "old_lm_score": -34.041015625,
                "acoustic_score": -96.75155639648438,
                "combined_score": -168.13148498535156
              },
              {
                "candidate": "the government that i was employed",
                "llm_score": -201.17095947265625,
                "old_lm_score": -32.46484375,
                "acoustic_score": -99.98301696777344,
                "combined_score": -166.80941009521484
              },
              {
                "candidate": "but the government that she was employed",
                "llm_score": -203.99957275390625,
                "old_lm_score": -37.810546875,
                "acoustic_score": -90.23434448242188,
                "combined_score": -166.02223205566406
              },
              {
                "candidate": "us to the government that he was implied",
                "llm_score": -216.0646209716797,
                "old_lm_score": -48.2939453125,
                "acoustic_score": -69.66578674316406,
                "combined_score": -167.01217651367188
              },
              {
                "candidate": "us to the government that i was employed",
                "llm_score": -212.157958984375,
                "old_lm_score": -46.822265625,
                "acoustic_score": -72.89724731445312,
                "combined_score": -165.93873596191406
              },
              {
                "candidate": "also the government that he was implied",
                "llm_score": -210.3712615966797,
                "old_lm_score": -43.2109375,
                "acoustic_score": -80.4818115234375,
                "combined_score": -167.0320053100586
              },
              {
                "candidate": "us the government that he was implied",
                "llm_score": -215.63848876953125,
                "old_lm_score": -47.7802734375,
                "acoustic_score": -71.47545623779297,
                "combined_score": -167.4471092224121
              },
              {
                "candidate": "it's the government that she was employed",
                "llm_score": -207.27365112304688,
                "old_lm_score": -37.509765625,
                "acoustic_score": -92.06364440917969,
                "combined_score": -168.42353057861328
              },
              {
                "candidate": "us the government that i was employed",
                "llm_score": -211.76425170898438,
                "old_lm_score": -46.2041015625,
                "acoustic_score": -74.7069091796875,
                "combined_score": -166.33763122558594
              },
              {
                "candidate": "what the government that he was implied",
                "llm_score": -211.48455810546875,
                "old_lm_score": -42.994140625,
                "acoustic_score": -81.1600341796875,
                "combined_score": -167.81936645507812
              },
              {
                "candidate": "also the government that i was employed",
                "llm_score": -206.2525634765625,
                "old_lm_score": -41.7392578125,
                "acoustic_score": -83.7132568359375,
                "combined_score": -165.8525390625
              },
              {
                "candidate": "what the government that i was employed",
                "llm_score": -207.1756591796875,
                "old_lm_score": -41.41796875,
                "acoustic_score": -84.3914794921875,
                "combined_score": -166.4925537109375
              },
              {
                "candidate": "the the government that she was employed",
                "llm_score": -208.92721557617188,
                "old_lm_score": -39.484375,
                "acoustic_score": -88.42060089111328,
                "combined_score": -168.41609573364258
              },
              {
                "candidate": "the to the government that she was employed",
                "llm_score": -211.77743530273438,
                "old_lm_score": -42.119140625,
                "acoustic_score": -83.79217529296875,
                "combined_score": -168.84437561035156
              },
              {
                "candidate": "see the government that she was employed",
                "llm_score": -210.6991729736328,
                "old_lm_score": -39.1865234375,
                "acoustic_score": -89.80587768554688,
                "combined_score": -169.84578704833984
              },
              {
                "candidate": "the so the government that she was employed",
                "llm_score": -214.84930419921875,
                "old_lm_score": -48.9521484375,
                "acoustic_score": -70.95320892333984,
                "combined_score": -167.3773307800293
              },
              {
                "candidate": "but the government that he was implied",
                "llm_score": -209.28819274902344,
                "old_lm_score": -40.3203125,
                "acoustic_score": -88.31800842285156,
                "combined_score": -168.9632568359375
              },
              {
                "candidate": "but the government that i was employed",
                "llm_score": -204.6116485595703,
                "old_lm_score": -38.744140625,
                "acoustic_score": -91.5494613647461,
                "combined_score": -167.4526252746582
              },
              {
                "candidate": "to the government that she was employed",
                "llm_score": -203.5305633544922,
                "old_lm_score": -38.05859375,
                "acoustic_score": -93.45228576660156,
                "combined_score": -167.52072143554688
              },
              {
                "candidate": "this the government that she was employed",
                "llm_score": -209.9807586669922,
                "old_lm_score": -42.0126953125,
                "acoustic_score": -85.55497741699219,
                "combined_score": -168.7742156982422
              },
              {
                "candidate": "dust the government that she was employed",
                "llm_score": -214.85302734375,
                "old_lm_score": -47.2958984375,
                "acoustic_score": -75.11408233642578,
                "combined_score": -168.6315040588379
              },
              {
                "candidate": "it's the government that he was implied",
                "llm_score": -209.96585083007812,
                "old_lm_score": -39.90625,
                "acoustic_score": -90.14729309082031,
                "combined_score": -170.00969696044922
              },
              {
                "candidate": "thus to the government that she was employed",
                "llm_score": -211.62860107421875,
                "old_lm_score": -47.849609375,
                "acoustic_score": -74.39518737792969,
                "combined_score": -166.93669891357422
              },
              {
                "candidate": "it's the government that i was employed",
                "llm_score": -207.078857421875,
                "old_lm_score": -38.4345703125,
                "acoustic_score": -93.37875366210938,
                "combined_score": -169.4460906982422
              },
              {
                "candidate": "whilst the government that she was employed",
                "llm_score": -211.0711669921875,
                "old_lm_score": -42.595703125,
                "acoustic_score": -85.07780456542969,
                "combined_score": -169.3723373413086
              },
              {
                "candidate": "a the government that she was employed",
                "llm_score": -209.58023071289062,
                "old_lm_score": -42.357421875,
                "acoustic_score": -85.6075439453125,
                "combined_score": -168.77259826660156
              },
              {
                "candidate": "stir the government that she was employed",
                "llm_score": -216.1844024658203,
                "old_lm_score": -43.935546875,
                "acoustic_score": -82.4520034790039,
                "combined_score": -171.2859764099121
              },
              {
                "candidate": "and the government that she was employed",
                "llm_score": -203.2470703125,
                "old_lm_score": -38.31640625,
                "acoustic_score": -93.75253295898438,
                "combined_score": -167.6580047607422
              },
              {
                "candidate": "use the government that she was employed",
                "llm_score": -210.4654541015625,
                "old_lm_score": -42.3134765625,
                "acoustic_score": -85.79727172851562,
                "combined_score": -169.28810119628906
              },
              {
                "candidate": "the the government that he was implied",
                "llm_score": -212.85330200195312,
                "old_lm_score": -41.994140625,
                "acoustic_score": -86.50425720214844,
                "combined_score": -170.67584991455078
              },
              {
                "candidate": "the the government that i was employed",
                "llm_score": -208.50315856933594,
                "old_lm_score": -40.41796875,
                "acoustic_score": -89.73571014404297,
                "combined_score": -169.32841873168945
              },
              {
                "candidate": "at the government that she was employed",
                "llm_score": -205.16978454589844,
                "old_lm_score": -40.275390625,
                "acoustic_score": -90.29196166992188,
                "combined_score": -167.86856842041016
              },
              {
                "candidate": "this to the government that she was employed",
                "llm_score": -212.24859619140625,
                "old_lm_score": -43.560546875,
                "acoustic_score": -83.74531555175781,
                "combined_score": -169.77722930908203
              },
              {
                "candidate": "the to the government that he was implied",
                "llm_score": -214.84278869628906,
                "old_lm_score": -44.515625,
                "acoustic_score": -81.87583923339844,
                "combined_score": -170.61712646484375
              },
              {
                "candidate": "a to the government that she was employed",
                "llm_score": -212.33860778808594,
                "old_lm_score": -44.9921875,
                "acoustic_score": -80.97911071777344,
                "combined_score": -169.1549530029297
              },
              {
                "candidate": "must the government that she was employed",
                "llm_score": -213.00177001953125,
                "old_lm_score": -45.2255859375,
                "acoustic_score": -80.60887145996094,
                "combined_score": -169.4181137084961
              },
              {
                "candidate": "us au the government that she was employed",
                "llm_score": -223.6169891357422,
                "old_lm_score": -51.0654296875,
                "acoustic_score": -68.94671630859375,
                "combined_score": -171.81456756591797
              },
              {
                "candidate": "the to the government that i was employed",
                "llm_score": -210.8210906982422,
                "old_lm_score": -43.0439453125,
                "acoustic_score": -85.10728454589844,
                "combined_score": -169.4861602783203
              },
              {
                "candidate": "once the government that she was employed",
                "llm_score": -208.42752075195312,
                "old_lm_score": -40.3310546875,
                "acoustic_score": -90.5618896484375,
                "combined_score": -169.6602325439453
              },
              {
                "candidate": "see the government that he was implied",
                "llm_score": -214.94815063476562,
                "old_lm_score": -41.6962890625,
                "acoustic_score": -87.88954162597656,
                "combined_score": -172.2669906616211
              },
              {
                "candidate": "see the government that i was employed",
                "llm_score": -211.55259704589844,
                "old_lm_score": -40.1201171875,
                "acoustic_score": -91.1209945678711,
                "combined_score": -171.39685440063477
              },
              {
                "candidate": "while the government that she was employed",
                "llm_score": -207.44070434570312,
                "old_lm_score": -38.5048828125,
                "acoustic_score": -94.70008850097656,
                "combined_score": -170.32283782958984
              }
            ],
            "selected": "just the government that he was employed",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 2145.5783769999925
        }
      ],
      "total_time_ms": 2195.164380000051
    },
    {
      "sentence_idx": 6,
      "ground_truth": "they feel good about what they're doing",
      "top1_hypothesis": "they feel good about what they're doing",
      "final_decoded": "they feel good about what they're doing",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.2376979999780815
    },
    {
      "sentence_idx": 7,
      "ground_truth": "besides its an invasion of personal privacy",
      "top1_hypothesis": "because it's an invasion of personal privacy",
      "final_decoded": "because it's an invasion of personal privacy",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.41569500001514825
    },
    {
      "sentence_idx": 8,
      "ground_truth": "so you travel a lot",
      "top1_hypothesis": "so you travel a lot",
      "final_decoded": "so you travel a lot",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.009800000043469481
    },
    {
      "sentence_idx": 9,
      "ground_truth": "so we're going to wait",
      "top1_hypothesis": "they were going to write",
      "final_decoded": "they were going to write",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "they",
          "confusion_candidates": [
            {
              "word": "they",
              "weight": 0.47018342423581344
            },
            {
              "word": "there",
              "weight": 0.05388037248329679
            },
            {
              "word": "so",
              "weight": 0.4705019636491737
            },
            {
              "word": "those",
              "weight": 0.0025195042949505753
            },
            {
              "word": "though",
              "weight": 0.002902416244817467
            },
            {
              "word": "the",
              "weight": 1.2319090948101689e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.8991087270967169,
            "margin": 0.0003185394133602415,
            "disagreement_mass": 0.5294980363508264
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(they OR there OR so OR those OR though OR the) were going to write",
            "retrieved_docs": [
              "They were so destitute.",
              "Some of those countries were so safe.",
              "There is just so much going on.",
              "Those were the general issues.",
              "I wish if they were going to do it.",
              "it's really hard to find something that works",
              "and i love the line",
              "i do have a friend that one",
              "this way in the back",
              "actually it makes sense to a certain extent",
              "just the government that he was employed",
              "they feel good about what they're doing",
              "because it's an invasion of personal privacy",
              "so you travel a lot"
            ],
            "scores": [
              13.039951261613009,
              12.272189820873969,
              11.749059680898995,
              11.1924580628935,
              10.732037130596925,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 13.940846999958012
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "were",
          "confusion_candidates": [
            {
              "word": "were",
              "weight": 0.9997031808797359
            },
            {
              "word": "we're",
              "weight": 0.00016623770597244943
            },
            {
              "word": "we",
              "weight": 0.00013058141329175206
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.002911247499826429,
            "margin": 0.9995369431737634,
            "disagreement_mass": 0.0002968191202641357
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "write",
          "confusion_candidates": [
            {
              "word": "write",
              "weight": 0.9437716804363553
            },
            {
              "word": "get",
              "weight": 0.0013287424508949867
            },
            {
              "word": "right",
              "weight": 0.04395489392053985
            },
            {
              "word": "wait",
              "weight": 0.0009502804152160989
            },
            {
              "word": "rate",
              "weight": 0.008975999333054142
            },
            {
              "word": "read",
              "weight": 0.00015799513127511144
            },
            {
              "word": "eat",
              "weight": 3.0003958290982703e-05
            },
            {
              "word": "ride",
              "weight": 2.8099546858177394e-05
            },
            {
              "word": "win",
              "weight": 1.098593619891988e-07
            },
            {
              "word": "it",
              "weight": 3.2624017434473714e-06
            },
            {
              "word": "rain",
              "weight": 5.946742550234211e-06
            },
            {
              "word": "raid",
              "weight": 9.423773548465213e-06
            },
            {
              "word": "run",
              "weight": 2.890844538252573e-07
            },
            {
              "word": "wright",
              "weight": 0.0007611768862773073
            },
            {
              "word": "fight",
              "weight": 4.1379907287847913e-07
            },
            {
              "word": "white",
              "weight": 1.883803207918968e-05
            },
            {
              "word": "red",
              "weight": 2.384085067797225e-06
            },
            {
              "word": "what",
              "weight": 4.601423602047266e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.25760966430487736,
            "margin": 0.8998167865158154,
            "disagreement_mass": 0.05622831956364471
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 5,
          "top1_word": "they were going to write",
          "confusion_candidates": [
            {
              "word": "they were going to write",
              "weight": -114.77135562896729
            },
            {
              "word": "they were going to get",
              "weight": -116.94894981384277
            },
            {
              "word": "there were going to write",
              "weight": -122.33851337432861
            },
            {
              "word": "they were going to right",
              "weight": -117.61242008209229
            },
            {
              "word": "they were going to wait",
              "weight": -118.54080200195312
            },
            {
              "word": "so were going to write",
              "weight": -120.08946418762207
            },
            {
              "word": "there were going to get",
              "weight": -122.88278388977051
            },
            {
              "word": "they were going to rate",
              "weight": -119.86325263977051
            },
            {
              "word": "they were going to read",
              "weight": -120.10472869873047
            },
            {
              "word": "so we're going to write",
              "weight": -122.20978355407715
            },
            {
              "word": "they were going to eat",
              "weight": -121.2734203338623
            },
            {
              "word": "so were going to get",
              "weight": -122.49618530273438
            },
            {
              "word": "those were going to write",
              "weight": -122.88269805908203
            },
            {
              "word": "they were going to ride",
              "weight": -121.43160820007324
            },
            {
              "word": "they were going to win",
              "weight": -122.21137619018555
            },
            {
              "word": "there were going to right",
              "weight": -124.04216480255127
            },
            {
              "word": "they were going to it",
              "weight": -121.52262687683105
            },
            {
              "word": "they were going to rain",
              "weight": -123.18130683898926
            },
            {
              "word": "they were going to raid",
              "weight": -121.83722686767578
            },
            {
              "word": "there were going to wait",
              "weight": -125.0722541809082
            },
            {
              "word": "they were going to run",
              "weight": -121.9590015411377
            },
            {
              "word": "they were going to wright",
              "weight": -124.33416843414307
            },
            {
              "word": "so we're going to get",
              "weight": -124.00473403930664
            },
            {
              "word": "they were going to fight",
              "weight": -121.66279602050781
            },
            {
              "word": "so we going to write",
              "weight": -124.4277458190918
            },
            {
              "word": "though were going to write",
              "weight": -122.75770473480225
            },
            {
              "word": "so were going to right",
              "weight": -122.77026557922363
            },
            {
              "word": "there were going to rate",
              "weight": -125.98676872253418
            },
            {
              "word": "those were going to get",
              "weight": -124.75418663024902
            },
            {
              "word": "there were going to read",
              "weight": -126.14503860473633
            },
            {
              "word": "they were going to white",
              "weight": -122.7662582397461
            },
            {
              "word": "so were going to wait",
              "weight": -124.14508247375488
            },
            {
              "word": "there were going to eat",
              "weight": -127.22830390930176
            },
            {
              "word": "so we're going to wait",
              "weight": -124.79605674743652
            },
            {
              "word": "the were going to write",
              "weight": -126.14812660217285
            },
            {
              "word": "so were going to rate",
              "weight": -124.72131633758545
            },
            {
              "word": "they were going to red",
              "weight": -122.47311401367188
            },
            {
              "word": "they were going to what",
              "weight": -123.3255386352539
            },
            {
              "word": "though were going to get",
              "weight": -125.24109268188477
            },
            {
              "word": "so were going to read",
              "weight": -125.26015567779541
            },
            {
              "word": "those were going to right",
              "weight": -125.42362213134766
            },
            {
              "word": "so were going to eat",
              "weight": -126.21626853942871
            },
            {
              "word": "those were going to wait",
              "weight": -126.50841522216797
            },
            {
              "word": "the were going to get",
              "weight": -128.65089416503906
            },
            {
              "word": "those were going to rate",
              "weight": -127.39775943756104
            },
            {
              "word": "though were going to right",
              "weight": -125.58911037445068
            },
            {
              "word": "those were going to read",
              "weight": -127.65736389160156
            },
            {
              "word": "though were going to wait",
              "weight": -126.41447257995605
            },
            {
              "word": "those were going to eat",
              "weight": -128.7353630065918
            },
            {
              "word": "though were going to rate",
              "weight": -127.6367416381836
            },
            {
              "word": "the were going to right",
              "weight": -129.12233924865723
            },
            {
              "word": "though were going to read",
              "weight": -127.93364524841309
            },
            {
              "word": "the were going to wait",
              "weight": -130.14527320861816
            },
            {
              "word": "though were going to eat",
              "weight": -129.1928825378418
            },
            {
              "word": "the were going to rate",
              "weight": -131.07404708862305
            },
            {
              "word": "the were going to read",
              "weight": -131.4818286895752
            },
            {
              "word": "the were going to eat",
              "weight": -132.49506378173828
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "They were so destitute.",
              "Some of those countries were so safe.",
              "There is just so much going on.",
              "Those were the general issues.",
              "I wish if they were going to do it.",
              "it's really hard to find something that works",
              "and i love the line",
              "i do have a friend that one",
              "this way in the back",
              "actually it makes sense to a certain extent",
              "just the government that he was employed",
              "they feel good about what they're doing",
              "because it's an invasion of personal privacy",
              "so you travel a lot"
            ],
            "retrieval_time_ms": 13.940846999958012
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "they were going to write",
                "llm_score": -175.32174682617188,
                "old_lm_score": -23.65234375,
                "acoustic_score": -30.568620681762695,
                "combined_score": -114.77135562896729
              },
              {
                "candidate": "they were going to get",
                "llm_score": -173.11146545410156,
                "old_lm_score": -19.9794921875,
                "acoustic_score": -40.806941986083984,
                "combined_score": -116.94894981384277
              },
              {
                "candidate": "there were going to write",
                "llm_score": -188.29147338867188,
                "old_lm_score": -26.6064453125,
                "acoustic_score": -29.77910804748535,
                "combined_score": -122.33851337432861
              },
              {
                "candidate": "they were going to right",
                "llm_score": -177.93746948242188,
                "old_lm_score": -26.71875,
                "acoustic_score": -30.568620681762695,
                "combined_score": -117.61242008209229
              },
              {
                "candidate": "they were going to wait",
                "llm_score": -175.9597625732422,
                "old_lm_score": -23.998046875,
                "acoustic_score": -37.12379455566406,
                "combined_score": -118.54080200195312
              },
              {
                "candidate": "so were going to write",
                "llm_score": -185.95977783203125,
                "old_lm_score": -30.9521484375,
                "acoustic_score": -23.26700210571289,
                "combined_score": -120.08946418762207
              },
              {
                "candidate": "there were going to get",
                "llm_score": -182.81454467773438,
                "old_lm_score": -22.93359375,
                "acoustic_score": -40.01742935180664,
                "combined_score": -122.88278388977051
              },
              {
                "candidate": "they were going to rate",
                "llm_score": -180.85052490234375,
                "old_lm_score": -27.39453125,
                "acoustic_score": -31.481449127197266,
                "combined_score": -119.86325263977051
              },
              {
                "candidate": "they were going to read",
                "llm_score": -177.29373168945312,
                "old_lm_score": -23.9150390625,
                "acoustic_score": -39.00068664550781,
                "combined_score": -120.10472869873047
              },
              {
                "candidate": "so we're going to write",
                "llm_score": -182.30712890625,
                "old_lm_score": -25.12890625,
                "acoustic_score": -36.9835319519043,
                "combined_score": -122.20978355407715
              },
              {
                "candidate": "they were going to eat",
                "llm_score": -177.96987915039062,
                "old_lm_score": -23.0673828125,
                "acoustic_score": -41.509578704833984,
                "combined_score": -121.2734203338623
              },
              {
                "candidate": "so were going to get",
                "llm_score": -184.20774841308594,
                "old_lm_score": -27.279296875,
                "acoustic_score": -33.50532531738281,
                "combined_score": -122.49618530273438
              },
              {
                "candidate": "those were going to write",
                "llm_score": -186.317138671875,
                "old_lm_score": -29.3046875,
                "acoustic_score": -30.143569946289062,
                "combined_score": -122.88269805908203
              },
              {
                "candidate": "they were going to ride",
                "llm_score": -178.9759521484375,
                "old_lm_score": -25.05859375,
                "acoustic_score": -38.828670501708984,
                "combined_score": -121.43160820007324
              },
              {
                "candidate": "they were going to win",
                "llm_score": -174.99118041992188,
                "old_lm_score": -19.6259765625,
                "acoustic_score": -49.80559539794922,
                "combined_score": -122.21137619018555
              },
              {
                "candidate": "there were going to right",
                "llm_score": -188.6323699951172,
                "old_lm_score": -29.6728515625,
                "acoustic_score": -29.77910804748535,
                "combined_score": -124.04216480255127
              },
              {
                "candidate": "they were going to it",
                "llm_score": -177.00469970703125,
                "old_lm_score": -23.15625,
                "acoustic_score": -42.88430404663086,
                "combined_score": -121.52262687683105
              },
              {
                "candidate": "they were going to rain",
                "llm_score": -180.9224395751953,
                "old_lm_score": -24.1513671875,
                "acoustic_score": -41.2888069152832,
                "combined_score": -123.18130683898926
              },
              {
                "candidate": "they were going to raid",
                "llm_score": -178.69467163085938,
                "old_lm_score": -25.23828125,
                "acoustic_score": -39.74150085449219,
                "combined_score": -121.83722686767578
              },
              {
                "candidate": "there were going to wait",
                "llm_score": -186.8580780029297,
                "old_lm_score": -26.9521484375,
                "acoustic_score": -36.33428192138672,
                "combined_score": -125.0722541809082
              },
              {
                "candidate": "they were going to run",
                "llm_score": -175.45394897460938,
                "old_lm_score": -22.1220703125,
                "acoustic_score": -46.341983795166016,
                "combined_score": -121.9590015411377
              },
              {
                "candidate": "they were going to wright",
                "llm_score": -188.08018493652344,
                "old_lm_score": -30.01953125,
                "acoustic_score": -30.568620681762695,
                "combined_score": -124.33416843414307
              },
              {
                "candidate": "so we're going to get",
                "llm_score": -179.05616760253906,
                "old_lm_score": -21.7314453125,
                "acoustic_score": -47.22185516357422,
                "combined_score": -124.00473403930664
              },
              {
                "candidate": "they were going to fight",
                "llm_score": -175.22019958496094,
                "old_lm_score": -22.7216796875,
                "acoustic_score": -45.38371276855469,
                "combined_score": -121.66279602050781
              },
              {
                "candidate": "so we going to write",
                "llm_score": -186.5044708251953,
                "old_lm_score": -28.66796875,
                "acoustic_score": -33.68305206298828,
                "combined_score": -124.4277458190918
              },
              {
                "candidate": "though were going to write",
                "llm_score": -186.20863342285156,
                "old_lm_score": -31.767578125,
                "acoustic_score": -27.53919792175293,
                "combined_score": -122.75770473480225
              },
              {
                "candidate": "so were going to right",
                "llm_score": -188.25497436523438,
                "old_lm_score": -34.0185546875,
                "acoustic_score": -23.26700210571289,
                "combined_score": -122.77026557922363
              },
              {
                "candidate": "there were going to rate",
                "llm_score": -190.93296813964844,
                "old_lm_score": -30.3486328125,
                "acoustic_score": -30.691936492919922,
                "combined_score": -125.98676872253418
              },
              {
                "candidate": "those were going to get",
                "llm_score": -183.49464416503906,
                "old_lm_score": -25.6318359375,
                "acoustic_score": -40.381893157958984,
                "combined_score": -124.75418663024902
              },
              {
                "candidate": "there were going to read",
                "llm_score": -187.2097625732422,
                "old_lm_score": -26.869140625,
                "acoustic_score": -38.21117401123047,
                "combined_score": -126.14503860473633
              },
              {
                "candidate": "they were going to white",
                "llm_score": -181.24537658691406,
                "old_lm_score": -28.076171875,
                "acoustic_score": -36.210968017578125,
                "combined_score": -122.7662582397461
              },
              {
                "candidate": "so were going to wait",
                "llm_score": -187.17013549804688,
                "old_lm_score": -31.2978515625,
                "acoustic_score": -29.82217788696289,
                "combined_score": -124.14508247375488
              },
              {
                "candidate": "there were going to eat",
                "llm_score": -187.71505737304688,
                "old_lm_score": -26.021484375,
                "acoustic_score": -40.72006607055664,
                "combined_score": -127.22830390930176
              },
              {
                "candidate": "so we're going to wait",
                "llm_score": -181.14520263671875,
                "old_lm_score": -24.908203125,
                "acoustic_score": -43.5387077331543,
                "combined_score": -124.79605674743652
              },
              {
                "candidate": "the were going to write",
                "llm_score": -187.52732849121094,
                "old_lm_score": -28.6083984375,
                "acoustic_score": -36.160526275634766,
                "combined_score": -126.14812660217285
              },
              {
                "candidate": "so were going to rate",
                "llm_score": -190.56846618652344,
                "old_lm_score": -34.6943359375,
                "acoustic_score": -24.17983055114746,
                "combined_score": -124.72131633758545
              },
              {
                "candidate": "they were going to red",
                "llm_score": -178.59202575683594,
                "old_lm_score": -27.353515625,
                "acoustic_score": -39.00068664550781,
                "combined_score": -122.47311401367188
              },
              {
                "candidate": "they were going to what",
                "llm_score": -178.65184020996094,
                "old_lm_score": -25.822265625,
                "acoustic_score": -42.176971435546875,
                "combined_score": -123.3255386352539
              },
              {
                "candidate": "though were going to get",
                "llm_score": -184.6099395751953,
                "old_lm_score": -28.0947265625,
                "acoustic_score": -37.77751922607422,
                "combined_score": -125.24109268188477
              },
              {
                "candidate": "so were going to read",
                "llm_score": -187.6063995361328,
                "old_lm_score": -31.21484375,
                "acoustic_score": -31.699068069458008,
                "combined_score": -125.26015567779541
              },
              {
                "candidate": "those were going to right",
                "llm_score": -188.33258056640625,
                "old_lm_score": -32.37109375,
                "acoustic_score": -30.143569946289062,
                "combined_score": -125.42362213134766
              },
              {
                "candidate": "so were going to eat",
                "llm_score": -187.85739135742188,
                "old_lm_score": -30.3671875,
                "acoustic_score": -34.20795822143555,
                "combined_score": -126.21626853942871
              },
              {
                "candidate": "those were going to wait",
                "llm_score": -186.66769409179688,
                "old_lm_score": -29.650390625,
                "acoustic_score": -36.69874572753906,
                "combined_score": -126.50841522216797
              },
              {
                "candidate": "the were going to get",
                "llm_score": -185.96739196777344,
                "old_lm_score": -24.935546875,
                "acoustic_score": -46.39884948730469,
                "combined_score": -128.65089416503906
              },
              {
                "candidate": "those were going to rate",
                "llm_score": -190.69224548339844,
                "old_lm_score": -33.046875,
                "acoustic_score": -31.056398391723633,
                "combined_score": -127.39775943756104
              },
              {
                "candidate": "though were going to right",
                "llm_score": -188.80503845214844,
                "old_lm_score": -34.833984375,
                "acoustic_score": -27.53919792175293,
                "combined_score": -125.58911037445068
              },
              {
                "candidate": "those were going to read",
                "llm_score": -187.1717071533203,
                "old_lm_score": -29.5673828125,
                "acoustic_score": -38.57563781738281,
                "combined_score": -127.65736389160156
              },
              {
                "candidate": "though were going to wait",
                "llm_score": -186.6212921142578,
                "old_lm_score": -32.11328125,
                "acoustic_score": -34.0943717956543,
                "combined_score": -126.41447257995605
              },
              {
                "candidate": "those were going to eat",
                "llm_score": -187.66647338867188,
                "old_lm_score": -28.7197265625,
                "acoustic_score": -41.08452606201172,
                "combined_score": -128.7353630065918
              },
              {
                "candidate": "though were going to rate",
                "llm_score": -191.3116912841797,
                "old_lm_score": -35.509765625,
                "acoustic_score": -28.4520263671875,
                "combined_score": -127.6367416381836
              },
              {
                "candidate": "the were going to right",
                "llm_score": -190.4093475341797,
                "old_lm_score": -31.6748046875,
                "acoustic_score": -36.160526275634766,
                "combined_score": -129.12233924865723
              },
              {
                "candidate": "though were going to read",
                "llm_score": -187.86575317382812,
                "old_lm_score": -32.0302734375,
                "acoustic_score": -35.97126388549805,
                "combined_score": -127.93364524841309
              },
              {
                "candidate": "the were going to wait",
                "llm_score": -188.62074279785156,
                "old_lm_score": -28.9541015625,
                "acoustic_score": -42.715702056884766,
                "combined_score": -130.14527320861816
              },
              {
                "candidate": "though were going to eat",
                "llm_score": -188.72299194335938,
                "old_lm_score": -31.1826171875,
                "acoustic_score": -38.48015594482422,
                "combined_score": -129.1928825378418
              },
              {
                "candidate": "the were going to rate",
                "llm_score": -192.72415161132812,
                "old_lm_score": -32.3505859375,
                "acoustic_score": -37.07335662841797,
                "combined_score": -131.07404708862305
              },
              {
                "candidate": "the were going to read",
                "llm_score": -189.49996948242188,
                "old_lm_score": -28.87109375,
                "acoustic_score": -44.592594146728516,
                "combined_score": -131.4818286895752
              },
              {
                "candidate": "the were going to eat",
                "llm_score": -189.86520385742188,
                "old_lm_score": -28.0234375,
                "acoustic_score": -47.10148620605469,
                "combined_score": -132.49506378173828
              }
            ],
            "selected": "they were going to write",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 1124.1474000000835
        }
      ],
      "total_time_ms": 1140.2962720000005
    },
    {
      "sentence_idx": 10,
      "ground_truth": "any kind of a good environment to live in",
      "top1_hypothesis": "any kind of a good environment to live in",
      "final_decoded": "any kind of a good environment to live in",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.9672740000041813
    },
    {
      "sentence_idx": 11,
      "ground_truth": "the best of android",
      "top1_hypothesis": "the best of android",
      "final_decoded": "the best of android",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.18767200003821927
    },
    {
      "sentence_idx": 12,
      "ground_truth": "i don't know what you think about the point",
      "top1_hypothesis": "i don't know what you think about the point",
      "final_decoded": "i don't know what you think about the point",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.3338529999155071
    },
    {
      "sentence_idx": 13,
      "ground_truth": "i believe it costs about ten dollars",
      "top1_hypothesis": "i believe it was about ten dollars",
      "final_decoded": "i believe it was about ten dollars",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.5218060000515834
    },
    {
      "sentence_idx": 14,
      "ground_truth": "what in the world drugs are you on to",
      "top1_hypothesis": "what in the world drugs are you on to",
      "final_decoded": "what in the world drugs are you on to",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 2,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "what",
          "confusion_candidates": [
            {
              "word": "what",
              "weight": 0.9997510324041164
            },
            {
              "word": "but",
              "weight": 0.00024896759488343933
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.002314916460074814,
            "margin": 0.999502064809233,
            "disagreement_mass": 0.00024896759588355355
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "world",
          "confusion_candidates": [
            {
              "word": "world",
              "weight": 0.998768250507277
            },
            {
              "word": "wild",
              "weight": 5.8956894233862004e-05
            },
            {
              "word": "word",
              "weight": 0.0007765010639301989
            },
            {
              "word": "world's",
              "weight": 1.9493135111848824e-05
            },
            {
              "word": "ward",
              "weight": 0.0003767983984468641
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.010547470324358071,
            "margin": 0.9979917494433468,
            "disagreement_mass": 0.0012317494927229777
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "drugs",
          "confusion_candidates": [
            {
              "word": "drugs",
              "weight": 0.6044661876321689
            },
            {
              "word": "dogs",
              "weight": 0.37796482637267703
            },
            {
              "word": "does",
              "weight": 0.0001905385123254402
            },
            {
              "word": "dog's",
              "weight": 0.01229778578782413
            },
            {
              "word": "doors",
              "weight": 6.981366206167213e-05
            },
            {
              "word": "logs",
              "weight": 6.665987653336565e-05
            },
            {
              "word": "dogs'",
              "weight": 0.004881527034541914
            },
            {
              "word": "stars",
              "weight": 7.326434733435758e-07
            },
            {
              "word": "stores",
              "weight": 2.234411915732362e-06
            },
            {
              "word": "tags",
              "weight": 1.8781438338672904e-05
            },
            {
              "word": "digs",
              "weight": 1.9273236975635417e-05
            },
            {
              "word": "was",
              "weight": 1.3991707725801124e-09
            },
            {
              "word": "wars",
              "weight": 3.886695027614027e-08
            },
            {
              "word": "dog",
              "weight": 1.9451555246485272e-05
            },
            {
              "word": "calls",
              "weight": 2.5338635033893967e-07
            },
            {
              "word": "draws",
              "weight": 1.8941824462346064e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.755741961939707,
            "margin": 0.22650136125949183,
            "disagreement_mass": 0.39553381236783114
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "what in the world (drugs OR dogs OR does OR dog's OR doors OR logs OR dogs' OR stars OR stores OR tags OR digs OR was OR wars OR dog OR calls OR draws) are you on to",
            "retrieved_docs": [
              "The stores that sell.",
              "What kind of dog do you have.",
              "What was going on there.",
              "About how many calls have you made on this system?",
              "Are you on the early retirement.",
              "actually it makes sense to a certain extent",
              "just the government that he was employed",
              "they feel good about what they're doing",
              "because it's an invasion of personal privacy",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars"
            ],
            "scores": [
              11.302093750982756,
              11.271515656428097,
              10.467545353986658,
              10.320122736688676,
              10.300964676356882,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 30.251583999984177
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "are",
          "confusion_candidates": [
            {
              "word": "are",
              "weight": 0.9999988384573422
            },
            {
              "word": "r",
              "weight": 1.1363417472268777e-06
            },
            {
              "word": "ar",
              "weight": 2.519991065812488e-08
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.715634823835311e-05,
            "margin": 0.9999977021155949,
            "disagreement_mass": 1.1615426578348576e-06
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 6,
          "span_end": 7,
          "top1_word": "you",
          "confusion_candidates": [
            {
              "word": "you",
              "weight": 0.9993507498346287
            },
            {
              "word": "u",
              "weight": 0.0006492501643713723
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.00541433588721262,
            "margin": 0.9987014996702573,
            "disagreement_mass": 0.0006492501653713179
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 7,
          "span_end": 8,
          "top1_word": "on",
          "confusion_candidates": [
            {
              "word": "on",
              "weight": 0.999999935515583
            },
            {
              "word": "r",
              "weight": 6.043471888324225e-12
            },
            {
              "word": "are",
              "weight": 6.447737357290374e-08
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.1321863500987187e-06,
            "margin": 0.9999998710382094,
            "disagreement_mass": 6.448441702833208e-08
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 8,
          "span_end": 9,
          "top1_word": "to",
          "confusion_candidates": [
            {
              "word": "to",
              "weight": 0.6951706630628764
            },
            {
              "word": "u",
              "weight": 0.03180594293306161
            },
            {
              "word": "you",
              "weight": 0.020384821399328
            },
            {
              "word": "two",
              "weight": 0.14165649935465865
            },
            {
              "word": "too",
              "weight": 0.09713421576776306
            },
            {
              "word": "tue",
              "weight": 0.012064487819107546
            },
            {
              "word": "no",
              "weight": 1.8250522423061947e-05
            },
            {
              "word": "new",
              "weight": 0.0003361258477430422
            },
            {
              "word": "now",
              "weight": 3.813640394154739e-07
            },
            {
              "word": "do",
              "weight": 0.00015826544581113753
            },
            {
              "word": "tu",
              "weight": 0.0012703464821878434
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.0111647892917588,
            "margin": 0.5535141637082178,
            "disagreement_mass": 0.30482933693712355
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "world drugs are you on (to OR u OR you OR two OR too OR tue OR no OR new OR now OR do OR tu)",
            "retrieved_docs": [
              "Doctors prescribe drugs too freely.",
              "Are you going to trade it in on this new one?",
              "Are you putting too many in?",
              "You are in New York right now.",
              "You rely too heavily on visual aids.",
              "actually it makes sense to a certain extent",
              "just the government that he was employed",
              "they feel good about what they're doing",
              "because it's an invasion of personal privacy",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars"
            ],
            "scores": [
              14.32940710749251,
              13.087135097764277,
              12.8197727937693,
              11.908838270661652,
              11.8855404033507,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 19.195474999946782
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 9,
          "top1_word": "what in the world drugs are you on to",
          "confusion_candidates": [
            {
              "word": "what in the world drugs are you on to",
              "weight": -163.61843490600586
            },
            {
              "word": "what in the world drugs are you on u",
              "weight": -166.72344970703125
            },
            {
              "word": "what in the world drugs are you on you",
              "weight": -165.3913803100586
            },
            {
              "word": "what in the world dogs are you on to",
              "weight": -163.67409896850586
            },
            {
              "word": "what in the world does are you on to",
              "weight": -165.66186904907227
            },
            {
              "word": "what in the world drugs are you on two",
              "weight": -166.29297256469727
            },
            {
              "word": "what in the world dogs are you on u",
              "weight": -166.49906158447266
            },
            {
              "word": "what in the world does are you on u",
              "weight": -168.7768669128418
            },
            {
              "word": "what in the world drugs are you on too",
              "weight": -165.85701370239258
            },
            {
              "word": "what in the world dogs are you on you",
              "weight": -165.39664459228516
            },
            {
              "word": "what in the world does are you on you",
              "weight": -167.4255485534668
            },
            {
              "word": "what in the world dogs are you on two",
              "weight": -166.00734329223633
            },
            {
              "word": "what in the world does are you on two",
              "weight": -167.92848587036133
            },
            {
              "word": "what in the world dogs are you on too",
              "weight": -165.98508071899414
            },
            {
              "word": "what in the world does are you on too",
              "weight": -168.06755447387695
            },
            {
              "word": "what in the world does r u on u",
              "weight": -171.89765167236328
            },
            {
              "word": "but in the world drugs are you on to",
              "weight": -174.1686019897461
            },
            {
              "word": "what in the world drugs are you on tue",
              "weight": -169.70808029174805
            },
            {
              "word": "what in the wild dogs are you on to",
              "weight": -166.3644256591797
            },
            {
              "word": "but in the world drugs are you on u",
              "weight": -178.06407165527344
            },
            {
              "word": "what in the world dogs are u on u",
              "weight": -170.16060638427734
            },
            {
              "word": "but in the world drugs are you on you",
              "weight": -176.1289291381836
            },
            {
              "word": "what in the world does are u on u",
              "weight": -171.92729568481445
            },
            {
              "word": "what in the wild dogs are you on u",
              "weight": -169.52769470214844
            },
            {
              "word": "but in the world dogs are you on to",
              "weight": -173.0768051147461
            },
            {
              "word": "what in the world drugs are you on no",
              "weight": -170.4369125366211
            },
            {
              "word": "what in the world dogs are you on tue",
              "weight": -169.6125831604004
            },
            {
              "word": "what in the world does are you on tue",
              "weight": -171.90761184692383
            },
            {
              "word": "what in the world drugs are you on new",
              "weight": -169.49467849731445
            },
            {
              "word": "what in the world drugs are you on now",
              "weight": -169.68133544921875
            },
            {
              "word": "what in the world drugs are you on do",
              "weight": -167.77088165283203
            },
            {
              "word": "what in the wild dogs are you on you",
              "weight": -168.13609313964844
            },
            {
              "word": "what in the word drugs are you on to",
              "weight": -169.7603874206543
            },
            {
              "word": "but in the world drugs are you on two",
              "weight": -175.94717407226562
            },
            {
              "word": "but in the world dogs are you on u",
              "weight": -177.03408813476562
            },
            {
              "word": "what in the world dog's are you on to",
              "weight": -168.00258255004883
            },
            {
              "word": "what in the world drugs are u on u",
              "weight": -171.57682037353516
            },
            {
              "word": "but in the world drugs are you on too",
              "weight": -175.7882537841797
            },
            {
              "word": "but in the world dogs are you on you",
              "weight": -174.83917999267578
            },
            {
              "word": "what in the wild dogs are you on two",
              "weight": -168.98776245117188
            },
            {
              "word": "what in the word drugs are you on u",
              "weight": -173.05485916137695
            },
            {
              "word": "what in the world doors are you on to",
              "weight": -167.7336883544922
            },
            {
              "word": "but in the wild dogs are you on to",
              "weight": -173.14799880981445
            },
            {
              "word": "what in the world dog's are you on u",
              "weight": -170.54672241210938
            },
            {
              "word": "what in the world dogs are you on no",
              "weight": -170.44540405273438
            },
            {
              "word": "what in the world does r u r u",
              "weight": -176.04009628295898
            },
            {
              "word": "what in the world does are you on no",
              "weight": -172.20860290527344
            },
            {
              "word": "what in the world logs are you on to",
              "weight": -166.64294815063477
            },
            {
              "word": "what in the wild dogs are you on too",
              "weight": -168.34711456298828
            },
            {
              "word": "what in the world drugs are you on tu",
              "weight": -171.0515251159668
            },
            {
              "word": "what in the world drugs are you on",
              "weight": -172.25966262817383
            },
            {
              "word": "what in the world dogs are you on new",
              "weight": -169.57421493530273
            },
            {
              "word": "what in the world dogs are you on now",
              "weight": -170.19039154052734
            },
            {
              "word": "what in the world dogs' are you on to",
              "weight": -171.30434799194336
            },
            {
              "word": "what in the world does are you on new",
              "weight": -171.43442153930664
            },
            {
              "word": "what in the world does are you on now",
              "weight": -172.0888557434082
            },
            {
              "word": "what in the word drugs are you on you",
              "weight": -171.60163497924805
            },
            {
              "word": "what in the world dogs are you on do",
              "weight": -168.0558624267578
            },
            {
              "word": "what in the world does are you on do",
              "weight": -169.9192237854004
            },
            {
              "word": "but in the word drugs are you on to",
              "weight": -177.58692932128906
            },
            {
              "word": "what in the word dogs are you on to",
              "weight": -170.1818084716797
            },
            {
              "word": "but in the world dogs are you on two",
              "weight": -174.52156829833984
            },
            {
              "word": "what in the world doors are you on u",
              "weight": -170.97190856933594
            },
            {
              "word": "what in the world dog's are you on you",
              "weight": -169.57550048828125
            },
            {
              "word": "but in the wild dogs are you on u",
              "weight": -177.3517951965332
            },
            {
              "word": "what in the world stars are you on to",
              "weight": -170.74147033691406
            },
            {
              "word": "what in the world stores are you on to",
              "weight": -167.65166854858398
            },
            {
              "word": "what in the world tags are you on to",
              "weight": -168.96435928344727
            },
            {
              "word": "what in the world digs are you on to",
              "weight": -171.08342361450195
            },
            {
              "word": "what in the world's drugs are you on to",
              "weight": -170.15283203125
            },
            {
              "word": "what in the world logs are you on u",
              "weight": -169.70929336547852
            },
            {
              "word": "what in the world dogs' are you on u",
              "weight": -174.10655975341797
            },
            {
              "word": "but in the world dogs are you on too",
              "weight": -174.4858627319336
            },
            {
              "word": "what in the world doors are you on you",
              "weight": -169.52803802490234
            },
            {
              "word": "what in the world was are you on to",
              "weight": -172.19733047485352
            },
            {
              "word": "what in the word drugs are you on two",
              "weight": -172.58127975463867
            },
            {
              "word": "but in the wild dogs are you on you",
              "weight": -175.00264358520508
            },
            {
              "word": "what in the world wars are you on to",
              "weight": -171.43410110473633
            },
            {
              "word": "but in the word drugs are you on u",
              "weight": -181.4200668334961
            },
            {
              "word": "what in the word dogs are you on u",
              "weight": -173.34719848632812
            },
            {
              "word": "what in the world dog are you on to",
              "weight": -166.9250259399414
            },
            {
              "word": "what in the world dogs are you are too",
              "weight": -175.33536529541016
            },
            {
              "word": "what in the world does are you are too",
              "weight": -177.32869338989258
            },
            {
              "word": "what in the world stars are you on u",
              "weight": -173.4791259765625
            },
            {
              "word": "what in the world does ar u on u",
              "weight": -176.17473220825195
            },
            {
              "word": "what in the world stores are you on u",
              "weight": -170.55131149291992
            },
            {
              "word": "what in the world dog's are you on two",
              "weight": -170.28863906860352
            },
            {
              "word": "what in the world calls are you on to",
              "weight": -168.82370376586914
            },
            {
              "word": "what in the world tags are you on u",
              "weight": -172.16420364379883
            },
            {
              "word": "what in the world logs are you on you",
              "weight": -168.70204544067383
            },
            {
              "word": "what in the ward drugs are you on to",
              "weight": -171.72235488891602
            },
            {
              "word": "what in the world dogs' are you on you",
              "weight": -173.0399398803711
            },
            {
              "word": "what in the world does r u on to",
              "weight": -172.19428253173828
            },
            {
              "word": "what in the world digs are you on u",
              "weight": -173.99003982543945
            },
            {
              "word": "what in the world's drugs are you on u",
              "weight": -173.22332763671875
            },
            {
              "word": "what in the word drugs are you on too",
              "weight": -171.96866989135742
            },
            {
              "word": "what in the world dogs are you on tu",
              "weight": -170.4797706604004
            },
            {
              "word": "what in the world draws are you on to",
              "weight": -171.20485305786133
            },
            {
              "word": "but in the word drugs are you on you",
              "weight": -179.6745147705078
            },
            {
              "word": "what in the world does are you on tu",
              "weight": -172.15354537963867
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "The stores that sell.",
              "What kind of dog do you have.",
              "What was going on there.",
              "About how many calls have you made on this system?",
              "Are you on the early retirement.",
              "actually it makes sense to a certain extent",
              "just the government that he was employed",
              "they feel good about what they're doing",
              "because it's an invasion of personal privacy",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "Doctors prescribe drugs too freely.",
              "Are you going to trade it in on this new one?",
              "Are you putting too many in?",
              "You are in New York right now.",
              "You rely too heavily on visual aids."
            ],
            "retrieval_time_ms": 49.44705899993096
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "what in the world drugs are you on to",
                "llm_score": -209.22750854492188,
                "old_lm_score": -53.51953125,
                "acoustic_score": -64.48983001708984,
                "combined_score": -163.61843490600586
              },
              {
                "candidate": "what in the world drugs are you on u",
                "llm_score": -212.33299255371094,
                "old_lm_score": -51.4814453125,
                "acoustic_score": -69.63246154785156,
                "combined_score": -166.72344970703125
              },
              {
                "candidate": "what in the world drugs are you on you",
                "llm_score": -209.24502563476562,
                "old_lm_score": -51.9052734375,
                "acoustic_score": -69.63246154785156,
                "combined_score": -165.3913803100586
              },
              {
                "candidate": "what in the world dogs are you on to",
                "llm_score": -208.86880493164062,
                "old_lm_score": -55.2978515625,
                "acoustic_score": -63.181541442871094,
                "combined_score": -163.67409896850586
              },
              {
                "candidate": "what in the world does are you on to",
                "llm_score": -205.24658203125,
                "old_lm_score": -47.7353515625,
                "acoustic_score": -78.34180450439453,
                "combined_score": -165.66186904907227
              },
              {
                "candidate": "what in the world drugs are you on two",
                "llm_score": -212.9935760498047,
                "old_lm_score": -55.1025390625,
                "acoustic_score": -64.48983001708984,
                "combined_score": -166.29297256469727
              },
              {
                "candidate": "what in the world dogs are you on u",
                "llm_score": -211.4141845703125,
                "old_lm_score": -53.259765625,
                "acoustic_score": -68.32417297363281,
                "combined_score": -166.49906158447266
              },
              {
                "candidate": "what in the world does are you on u",
                "llm_score": -208.3720245361328,
                "old_lm_score": -45.697265625,
                "acoustic_score": -83.48444366455078,
                "combined_score": -168.7768669128418
              },
              {
                "candidate": "what in the world drugs are you on too",
                "llm_score": -211.7583770751953,
                "old_lm_score": -55.4658203125,
                "acoustic_score": -64.48983001708984,
                "combined_score": -165.85701370239258
              },
              {
                "candidate": "what in the world dogs are you on you",
                "llm_score": -208.7855224609375,
                "old_lm_score": -53.68359375,
                "acoustic_score": -68.32417297363281,
                "combined_score": -165.39664459228516
              },
              {
                "candidate": "what in the world does are you on you",
                "llm_score": -205.2455596923828,
                "old_lm_score": -46.12109375,
                "acoustic_score": -83.48444366455078,
                "combined_score": -167.4255485534668
              },
              {
                "candidate": "what in the world dogs are you on two",
                "llm_score": -211.95228576660156,
                "old_lm_score": -56.880859375,
                "acoustic_score": -63.181541442871094,
                "combined_score": -166.00734329223633
              },
              {
                "candidate": "what in the world does are you on two",
                "llm_score": -208.19680786132812,
                "old_lm_score": -49.318359375,
                "acoustic_score": -78.34180450439453,
                "combined_score": -167.92848587036133
              },
              {
                "candidate": "what in the world dogs are you on too",
                "llm_score": -211.5444793701172,
                "old_lm_score": -57.244140625,
                "acoustic_score": -63.181541442871094,
                "combined_score": -165.98508071899414
              },
              {
                "candidate": "what in the world does are you on too",
                "llm_score": -208.11166381835938,
                "old_lm_score": -49.681640625,
                "acoustic_score": -78.34180450439453,
                "combined_score": -168.06755447387695
              },
              {
                "candidate": "what in the world does r u on u",
                "llm_score": -212.68780517578125,
                "old_lm_score": -47.623046875,
                "acoustic_score": -83.48445129394531,
                "combined_score": -171.89765167236328
              },
              {
                "candidate": "but in the world drugs are you on to",
                "llm_score": -222.0572052001953,
                "old_lm_score": -52.8447265625,
                "acoustic_score": -73.43527221679688,
                "combined_score": -174.1686019897461
              },
              {
                "candidate": "what in the world drugs are you on tue",
                "llm_score": -217.37554931640625,
                "old_lm_score": -57.55078125,
                "acoustic_score": -64.48983001708984,
                "combined_score": -169.70808029174805
              },
              {
                "candidate": "what in the wild dogs are you on to",
                "llm_score": -205.4988250732422,
                "old_lm_score": -52.9404296875,
                "acoustic_score": -74.28959655761719,
                "combined_score": -166.3644256591797
              },
              {
                "candidate": "but in the world drugs are you on u",
                "llm_score": -226.74359130859375,
                "old_lm_score": -50.806640625,
                "acoustic_score": -78.57791137695312,
                "combined_score": -178.06407165527344
              },
              {
                "candidate": "what in the world dogs are u on u",
                "llm_score": -215.64743041992188,
                "old_lm_score": -56.349609375,
                "acoustic_score": -68.32417297363281,
                "combined_score": -170.16060638427734
              },
              {
                "candidate": "but in the world drugs are you on you",
                "llm_score": -222.44947814941406,
                "old_lm_score": -51.23046875,
                "acoustic_score": -78.57791137695312,
                "combined_score": -176.1289291381836
              },
              {
                "candidate": "what in the world does are u on u",
                "llm_score": -211.58303833007812,
                "old_lm_score": -48.787109375,
                "acoustic_score": -83.48444366455078,
                "combined_score": -171.92729568481445
              },
              {
                "candidate": "what in the wild dogs are you on u",
                "llm_score": -208.72080993652344,
                "old_lm_score": -50.90234375,
                "acoustic_score": -79.43223571777344,
                "combined_score": -169.52769470214844
              },
              {
                "candidate": "but in the world dogs are you on to",
                "llm_score": -219.40357971191406,
                "old_lm_score": -54.623046875,
                "acoustic_score": -72.12698364257812,
                "combined_score": -173.0768051147461
              },
              {
                "candidate": "what in the world drugs are you on no",
                "llm_score": -212.33938598632812,
                "old_lm_score": -53.1171875,
                "acoustic_score": -75.41725158691406,
                "combined_score": -170.4369125366211
              },
              {
                "candidate": "what in the world dogs are you on tue",
                "llm_score": -216.7145233154297,
                "old_lm_score": -59.3291015625,
                "acoustic_score": -63.181541442871094,
                "combined_score": -169.6125831604004
              },
              {
                "candidate": "what in the world does are you on tue",
                "llm_score": -213.70681762695312,
                "old_lm_score": -51.7666015625,
                "acoustic_score": -78.34180450439453,
                "combined_score": -171.90761184692383
              },
              {
                "candidate": "what in the world drugs are you on new",
                "llm_score": -213.3682098388672,
                "old_lm_score": -56.27734375,
                "acoustic_score": -69.34380340576172,
                "combined_score": -169.49467849731445
              },
              {
                "candidate": "what in the world drugs are you on now",
                "llm_score": -206.9600372314453,
                "old_lm_score": -49.4970703125,
                "acoustic_score": -82.90556335449219,
                "combined_score": -169.68133544921875
              },
              {
                "candidate": "what in the world drugs are you on do",
                "llm_score": -209.1674041748047,
                "old_lm_score": -55.66015625,
                "acoustic_score": -70.71420288085938,
                "combined_score": -167.77088165283203
              },
              {
                "candidate": "what in the wild dogs are you on you",
                "llm_score": -205.51377868652344,
                "old_lm_score": -51.326171875,
                "acoustic_score": -79.43223571777344,
                "combined_score": -168.13609313964844
              },
              {
                "candidate": "what in the word drugs are you on to",
                "llm_score": -214.49050903320312,
                "old_lm_score": -57.240234375,
                "acoustic_score": -67.79003143310547,
                "combined_score": -169.7603874206543
              },
              {
                "candidate": "but in the world drugs are you on two",
                "llm_score": -224.03134155273438,
                "old_lm_score": -54.427734375,
                "acoustic_score": -73.43527221679688,
                "combined_score": -175.94717407226562
              },
              {
                "candidate": "but in the world dogs are you on u",
                "llm_score": -224.21359252929688,
                "old_lm_score": -52.5849609375,
                "acoustic_score": -77.26962280273438,
                "combined_score": -177.03408813476562
              },
              {
                "candidate": "what in the world dog's are you on to",
                "llm_score": -214.22288513183594,
                "old_lm_score": -60.8876953125,
                "acoustic_score": -60.89458465576172,
                "combined_score": -168.00258255004883
              },
              {
                "candidate": "what in the world drugs are u on u",
                "llm_score": -216.94110107421875,
                "old_lm_score": -56.580078125,
                "acoustic_score": -69.63246154785156,
                "combined_score": -171.57682037353516
              },
              {
                "candidate": "but in the world drugs are you on too",
                "llm_score": -223.3502197265625,
                "old_lm_score": -54.791015625,
                "acoustic_score": -73.43527221679688,
                "combined_score": -175.7882537841797
              },
              {
                "candidate": "but in the world dogs are you on you",
                "llm_score": -219.3999481201172,
                "old_lm_score": -53.0087890625,
                "acoustic_score": -77.26962280273438,
                "combined_score": -174.83917999267578
              },
              {
                "candidate": "what in the wild dogs are you on two",
                "llm_score": -209.16249084472656,
                "old_lm_score": -54.5234375,
                "acoustic_score": -74.28959655761719,
                "combined_score": -168.98776245117188
              },
              {
                "candidate": "what in the word drugs are you on u",
                "llm_score": -217.9748992919922,
                "old_lm_score": -55.2021484375,
                "acoustic_score": -72.93267059326172,
                "combined_score": -173.05485916137695
              },
              {
                "candidate": "what in the world doors are you on to",
                "llm_score": -208.68869018554688,
                "old_lm_score": -56.71484375,
                "acoustic_score": -70.0638427734375,
                "combined_score": -167.7336883544922
              },
              {
                "candidate": "but in the wild dogs are you on to",
                "llm_score": -212.8939666748047,
                "old_lm_score": -50.1669921875,
                "acoustic_score": -83.23503875732422,
                "combined_score": -173.14799880981445
              },
              {
                "candidate": "what in the world dog's are you on u",
                "llm_score": -216.2066192626953,
                "old_lm_score": -58.849609375,
                "acoustic_score": -66.03721618652344,
                "combined_score": -170.54672241210938
              },
              {
                "candidate": "what in the world dogs are you on no",
                "llm_score": -211.88633728027344,
                "old_lm_score": -54.8955078125,
                "acoustic_score": -74.10896301269531,
                "combined_score": -170.44540405273438
              },
              {
                "candidate": "what in the world does r u r u",
                "llm_score": -209.1107177734375,
                "old_lm_score": -40.96484375,
                "acoustic_score": -102.00463104248047,
                "combined_score": -176.04009628295898
              },
              {
                "candidate": "what in the world does are you on no",
                "llm_score": -207.81497192382812,
                "old_lm_score": -47.3330078125,
                "acoustic_score": -89.26922607421875,
                "combined_score": -172.20860290527344
              },
              {
                "candidate": "what in the world logs are you on to",
                "llm_score": -206.4609832763672,
                "old_lm_score": -57.181640625,
                "acoustic_score": -69.64327239990234,
                "combined_score": -166.64294815063477
              },
              {
                "candidate": "what in the wild dogs are you on too",
                "llm_score": -207.51791381835938,
                "old_lm_score": -54.88671875,
                "acoustic_score": -74.28959655761719,
                "combined_score": -168.34711456298828
              },
              {
                "candidate": "what in the world drugs are you on tu",
                "llm_score": -217.81146240234375,
                "old_lm_score": -59.8017578125,
                "acoustic_score": -64.48983001708984,
                "combined_score": -171.0515251159668
              },
              {
                "candidate": "what in the world drugs are you on",
                "llm_score": -203.64825439453125,
                "old_lm_score": -43.26171875,
                "acoustic_score": -97.6093521118164,
                "combined_score": -172.25966262817383
              },
              {
                "candidate": "what in the world dogs are you on new",
                "llm_score": -213.0572509765625,
                "old_lm_score": -58.0556640625,
                "acoustic_score": -68.03551483154297,
                "combined_score": -169.57421493530273
              },
              {
                "candidate": "what in the world dogs are you on now",
                "llm_score": -207.50811767578125,
                "old_lm_score": -51.275390625,
                "acoustic_score": -81.59727478027344,
                "combined_score": -170.19039154052734
              },
              {
                "candidate": "what in the world dogs' are you on to",
                "llm_score": -220.077392578125,
                "old_lm_score": -61.63671875,
                "acoustic_score": -60.89458465576172,
                "combined_score": -171.30434799194336
              },
              {
                "candidate": "what in the world does are you on new",
                "llm_score": -209.17990112304688,
                "old_lm_score": -50.4931640625,
                "acoustic_score": -83.1957778930664,
                "combined_score": -171.43442153930664
              },
              {
                "candidate": "what in the world does are you on now",
                "llm_score": -203.707275390625,
                "old_lm_score": -43.712890625,
                "acoustic_score": -96.7575454711914,
                "combined_score": -172.0888557434082
              },
              {
                "candidate": "what in the word drugs are you on you",
                "llm_score": -214.64462280273438,
                "old_lm_score": -55.6259765625,
                "acoustic_score": -72.93267059326172,
                "combined_score": -171.60163497924805
              },
              {
                "candidate": "what in the world dogs are you on do",
                "llm_score": -209.267333984375,
                "old_lm_score": -57.4384765625,
                "acoustic_score": -69.40591430664062,
                "combined_score": -168.0558624267578
              },
              {
                "candidate": "what in the world does are you on do",
                "llm_score": -205.3962860107422,
                "old_lm_score": -49.8759765625,
                "acoustic_score": -84.5661849975586,
                "combined_score": -169.9192237854004
              },
              {
                "candidate": "but in the word drugs are you on to",
                "llm_score": -224.57901000976562,
                "old_lm_score": -53.859375,
                "acoustic_score": -76.7354736328125,
                "combined_score": -177.58692932128906
              },
              {
                "candidate": "what in the word dogs are you on to",
                "llm_score": -214.8633270263672,
                "old_lm_score": -59.0185546875,
                "acoustic_score": -66.48173522949219,
                "combined_score": -170.1818084716797
              },
              {
                "candidate": "but in the world dogs are you on two",
                "llm_score": -220.71009826660156,
                "old_lm_score": -56.2060546875,
                "acoustic_score": -72.12698364257812,
                "combined_score": -174.52156829833984
              },
              {
                "candidate": "what in the world doors are you on u",
                "llm_score": -212.06057739257812,
                "old_lm_score": -54.6767578125,
                "acoustic_score": -75.20648193359375,
                "combined_score": -170.97190856933594
              },
              {
                "candidate": "what in the world dog's are you on you",
                "llm_score": -213.84034729003906,
                "old_lm_score": -59.2734375,
                "acoustic_score": -66.03721618652344,
                "combined_score": -169.57550048828125
              },
              {
                "candidate": "but in the wild dogs are you on u",
                "llm_score": -218.19700622558594,
                "old_lm_score": -48.12890625,
                "acoustic_score": -88.37767791748047,
                "combined_score": -177.3517951965332
              },
              {
                "candidate": "what in the world stars are you on to",
                "llm_score": -210.17503356933594,
                "old_lm_score": -53.3671875,
                "acoustic_score": -77.94071960449219,
                "combined_score": -170.74147033691406
              },
              {
                "candidate": "what in the world stores are you on to",
                "llm_score": -205.11050415039062,
                "old_lm_score": -54.5390625,
                "acoustic_score": -75.65377044677734,
                "combined_score": -167.65166854858398
              },
              {
                "candidate": "what in the world tags are you on to",
                "llm_score": -209.86477661132812,
                "old_lm_score": -56.7568359375,
                "acoustic_score": -71.3071060180664,
                "combined_score": -168.96435928344727
              },
              {
                "candidate": "what in the world digs are you on to",
                "llm_score": -214.12875366210938,
                "old_lm_score": -57.013671875,
                "acoustic_score": -71.02442169189453,
                "combined_score": -171.08342361450195
              },
              {
                "candidate": "what in the world's drugs are you on to",
                "llm_score": -212.27891540527344,
                "old_lm_score": -57.041015625,
                "acoustic_score": -70.98573303222656,
                "combined_score": -170.15283203125
              },
              {
                "candidate": "what in the world logs are you on u",
                "llm_score": -209.48912048339844,
                "old_lm_score": -55.1435546875,
                "acoustic_score": -74.7859115600586,
                "combined_score": -169.70929336547852
              },
              {
                "candidate": "what in the world dogs' are you on u",
                "llm_score": -222.5772705078125,
                "old_lm_score": -59.5986328125,
                "acoustic_score": -66.03721618652344,
                "combined_score": -174.10655975341797
              },
              {
                "candidate": "but in the world dogs are you on too",
                "llm_score": -220.27540588378906,
                "old_lm_score": -56.5693359375,
                "acoustic_score": -72.12698364257812,
                "combined_score": -174.4858627319336
              },
              {
                "candidate": "what in the world doors are you on you",
                "llm_score": -208.74900817871094,
                "old_lm_score": -55.1005859375,
                "acoustic_score": -75.20648193359375,
                "combined_score": -169.52803802490234
              },
              {
                "candidate": "what in the world was are you on to",
                "llm_score": -206.86984252929688,
                "old_lm_score": -47.8974609375,
                "acoustic_score": -89.62735748291016,
                "combined_score": -172.19733047485352
              },
              {
                "candidate": "what in the word drugs are you on two",
                "llm_score": -218.54928588867188,
                "old_lm_score": -58.8232421875,
                "acoustic_score": -67.79003143310547,
                "combined_score": -172.58127975463867
              },
              {
                "candidate": "but in the wild dogs are you on you",
                "llm_score": -213.0748748779297,
                "old_lm_score": -48.552734375,
                "acoustic_score": -88.37767791748047,
                "combined_score": -175.00264358520508
              },
              {
                "candidate": "what in the world wars are you on to",
                "llm_score": -208.6676483154297,
                "old_lm_score": -51.30078125,
                "acoustic_score": -82.89977264404297,
                "combined_score": -171.43410110473633
              },
              {
                "candidate": "but in the word drugs are you on u",
                "llm_score": -229.14073181152344,
                "old_lm_score": -51.8212890625,
                "acoustic_score": -81.87811279296875,
                "combined_score": -181.4200668334961
              },
              {
                "candidate": "what in the word dogs are you on u",
                "llm_score": -218.0895538330078,
                "old_lm_score": -56.98046875,
                "acoustic_score": -71.62437438964844,
                "combined_score": -173.34719848632812
              },
              {
                "candidate": "what in the world dog are you on to",
                "llm_score": -205.8650360107422,
                "old_lm_score": -57.6884765625,
                "acoustic_score": -70.29653930664062,
                "combined_score": -166.9250259399414
              },
              {
                "candidate": "what in the world dogs are you are too",
                "llm_score": -216.97584533691406,
                "old_lm_score": -51.9931640625,
                "acoustic_score": -81.70172119140625,
                "combined_score": -175.33536529541016
              },
              {
                "candidate": "what in the world does are you are too",
                "llm_score": -213.36473083496094,
                "old_lm_score": -44.4306640625,
                "acoustic_score": -96.86199188232422,
                "combined_score": -177.32869338989258
              },
              {
                "candidate": "what in the world stars are you on u",
                "llm_score": -212.54579162597656,
                "old_lm_score": -51.3291015625,
                "acoustic_score": -83.08335876464844,
                "combined_score": -173.4791259765625
              },
              {
                "candidate": "what in the world does ar u on u",
                "llm_score": -217.71560668945312,
                "old_lm_score": -51.1494140625,
                "acoustic_score": -83.48444366455078,
                "combined_score": -176.17473220825195
              },
              {
                "candidate": "what in the world stores are you on u",
                "llm_score": -207.80523681640625,
                "old_lm_score": -52.5009765625,
                "acoustic_score": -80.7964096069336,
                "combined_score": -170.55131149291992
              },
              {
                "candidate": "what in the world dog's are you on two",
                "llm_score": -217.2119903564453,
                "old_lm_score": -62.470703125,
                "acoustic_score": -60.89458465576172,
                "combined_score": -170.28863906860352
              },
              {
                "candidate": "what in the world calls are you on to",
                "llm_score": -205.32162475585938,
                "old_lm_score": -53.5478515625,
                "acoustic_score": -78.7779312133789,
                "combined_score": -168.82370376586914
              },
              {
                "candidate": "what in the world tags are you on u",
                "llm_score": -213.159912109375,
                "old_lm_score": -54.71875,
                "acoustic_score": -76.44974517822266,
                "combined_score": -172.16420364379883
              },
              {
                "candidate": "what in the world logs are you on you",
                "llm_score": -207.05079650878906,
                "old_lm_score": -55.5673828125,
                "acoustic_score": -74.7859115600586,
                "combined_score": -168.70204544067383
              },
              {
                "candidate": "what in the ward drugs are you on to",
                "llm_score": -218.42347717285156,
                "old_lm_score": -60.9072265625,
                "acoustic_score": -64.11400604248047,
                "combined_score": -171.72235488891602
              },
              {
                "candidate": "what in the world dogs' are you on you",
                "llm_score": -220.02020263671875,
                "old_lm_score": -60.0224609375,
                "acoustic_score": -66.03721618652344,
                "combined_score": -173.0399398803711
              },
              {
                "candidate": "what in the world does r u on to",
                "llm_score": -212.1610107421875,
                "old_lm_score": -53.8857421875,
                "acoustic_score": -78.34181213378906,
                "combined_score": -172.19428253173828
              },
              {
                "candidate": "what in the world digs are you on u",
                "llm_score": -216.83743286132812,
                "old_lm_score": -54.9755859375,
                "acoustic_score": -76.16706085205078,
                "combined_score": -173.99003982543945
              },
              {
                "candidate": "what in the world's drugs are you on u",
                "llm_score": -215.3153533935547,
                "old_lm_score": -55.0029296875,
                "acoustic_score": -76.12837219238281,
                "combined_score": -173.22332763671875
              },
              {
                "candidate": "what in the word drugs are you on too",
                "llm_score": -216.96078491210938,
                "old_lm_score": -59.1865234375,
                "acoustic_score": -67.79003143310547,
                "combined_score": -171.96866989135742
              },
              {
                "candidate": "what in the world dogs are you on tu",
                "llm_score": -216.1979217529297,
                "old_lm_score": -61.580078125,
                "acoustic_score": -63.181541442871094,
                "combined_score": -170.4797706604004
              },
              {
                "candidate": "what in the world draws are you on to",
                "llm_score": -212.09555053710938,
                "old_lm_score": -56.0517578125,
                "acoustic_score": -74.26239776611328,
                "combined_score": -171.20485305786133
              },
              {
                "candidate": "but in the word drugs are you on you",
                "llm_score": -225.22579956054688,
                "old_lm_score": -52.2451171875,
                "acoustic_score": -81.87811279296875,
                "combined_score": -179.6745147705078
              },
              {
                "candidate": "what in the world does are you on tu",
                "llm_score": -211.9477081298828,
                "old_lm_score": -54.017578125,
                "acoustic_score": -78.34180450439453,
                "combined_score": -172.15354537963867
              }
            ],
            "selected": "what in the world drugs are you on to",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 2253.4451969999054
        }
      ],
      "total_time_ms": 2311.4897990000145
    },
    {
      "sentence_idx": 15,
      "ground_truth": "android tv box",
      "top1_hypothesis": "android tv box",
      "final_decoded": "android tv box",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.02548400004798168
    },
    {
      "sentence_idx": 16,
      "ground_truth": "a couple of times",
      "top1_hypothesis": "a couple of times",
      "final_decoded": "a couple of times",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.29570399999556685
    },
    {
      "sentence_idx": 17,
      "ground_truth": "i had the brakes done on it",
      "top1_hypothesis": "i had the back down on it",
      "final_decoded": "i had the back down on it",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "the",
          "confusion_candidates": [
            {
              "word": "the",
              "weight": 0.9999819049401316
            },
            {
              "word": "a",
              "weight": 1.808438490194896e-05
            },
            {
              "word": "to",
              "weight": 1.0673966451915428e-08
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0002157806514696118,
            "margin": 0.9999638205552297,
            "disagreement_mass": 1.8095059868383778e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "back",
          "confusion_candidates": [
            {
              "word": "back",
              "weight": 0.9202824191442357
            },
            {
              "word": "break",
              "weight": 0.038488598661404666
            },
            {
              "word": "backs",
              "weight": 0.016143895275972063
            },
            {
              "word": "breaks",
              "weight": 0.0006729447816164003
            },
            {
              "word": "work",
              "weight": 4.840398680866902e-07
            },
            {
              "word": "book",
              "weight": 0.0026188858871628684
            },
            {
              "word": "bike",
              "weight": 0.0002809433433346004
            },
            {
              "word": "backed",
              "weight": 0.00019409922860510572
            },
            {
              "word": "black",
              "weight": 0.0006905281530339588
            },
            {
              "word": "pack",
              "weight": 0.001254539000603321
            },
            {
              "word": "bank",
              "weight": 0.001147597327987462
            },
            {
              "word": "brick",
              "weight": 0.005171897078010949
            },
            {
              "word": "brakes",
              "weight": 0.0026460716395770552
            },
            {
              "word": "brake",
              "weight": 0.005335278515006409
            },
            {
              "word": "mic",
              "weight": 0.00017415045947345123
            },
            {
              "word": "pic",
              "weight": 0.00030955384733191184
            },
            {
              "word": "pick",
              "weight": 0.0002948019967940916
            },
            {
              "word": "bank's",
              "weight": 0.00016361012929242276
            },
            {
              "word": "mac",
              "weight": 0.0003380669443636982
            },
            {
              "word": "banks",
              "weight": 0.00010952131082667608
            },
            {
              "word": "books",
              "weight": 4.026559386644403e-05
            },
            {
              "word": "crack",
              "weight": 2.840553536624299e-09
            },
            {
              "word": "pac",
              "weight": 0.0003627869819872398
            },
            {
              "word": "bic",
              "weight": 0.0027790826460288897
            },
            {
              "word": "make",
              "weight": 0.00013581204261200571
            },
            {
              "word": "bricks",
              "weight": 0.0003641631294509866
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.4201780894612583,
            "margin": 0.8817938204828311,
            "disagreement_mass": 0.0797175808557643
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "down",
          "confusion_candidates": [
            {
              "word": "down",
              "weight": 0.27446229656228033
            },
            {
              "word": "done",
              "weight": 0.7255210087592792
            },
            {
              "word": "in",
              "weight": 1.767072227041451e-06
            },
            {
              "word": "sun",
              "weight": 8.31977339998068e-06
            },
            {
              "word": "run",
              "weight": 5.12988314406033e-06
            },
            {
              "word": "on",
              "weight": 1.4779486695481228e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5878611878325428,
            "margin": 0.45105871219699883,
            "disagreement_mass": 0.27447899124072084
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "i had the back (down OR done OR in OR sun OR run OR on) on it",
            "retrieved_docs": [
              "You just sit down on on the deck.",
              "It's on down the line.",
              "Putting things on the back burner.",
              "I heard it on the radio.",
              "They're not done on a regular basis.",
              "because it's an invasion of personal privacy",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times"
            ],
            "scores": [
              14.165372286518933,
              14.087211565016464,
              13.095322506287008,
              12.016520296714301,
              11.456774344112745,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 16.49766000002728
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 7,
          "top1_word": "i had the back down on it",
          "confusion_candidates": [
            {
              "word": "i had the back down on it",
              "weight": -142.49969100952148
            },
            {
              "word": "i had the break down on it",
              "weight": -144.21936225891113
            },
            {
              "word": "i had the back done on it",
              "weight": -145.57414436340332
            },
            {
              "word": "i had the backs down on it",
              "weight": -145.75482368469238
            },
            {
              "word": "i had a break down on it",
              "weight": -146.85162544250488
            },
            {
              "word": "i had the breaks down on it",
              "weight": -147.44762802124023
            },
            {
              "word": "i had the work done on it",
              "weight": -147.8380584716797
            },
            {
              "word": "i had the book done on it",
              "weight": -143.55387687683105
            },
            {
              "word": "i had to back down on it",
              "weight": -148.62670135498047
            },
            {
              "word": "had the back down on it",
              "weight": -147.25649070739746
            },
            {
              "word": "i had the book down on it",
              "weight": -146.31287956237793
            },
            {
              "word": "i had the bike down on it",
              "weight": -148.12671279907227
            },
            {
              "word": "i had a back down on it",
              "weight": -147.69626998901367
            },
            {
              "word": "i had the backed down on it",
              "weight": -150.73441314697266
            },
            {
              "word": "i had the break done on it",
              "weight": -145.94584846496582
            },
            {
              "word": "had the break down on it",
              "weight": -148.95312881469727
            },
            {
              "word": "i had the black done on it",
              "weight": -147.38217544555664
            },
            {
              "word": "i had the bike done on it",
              "weight": -146.75362586975098
            },
            {
              "word": "i had the backs done on it",
              "weight": -147.6328525543213
            },
            {
              "word": "i had the back in on it",
              "weight": -150.62554931640625
            },
            {
              "word": "i had the pack down on it",
              "weight": -148.8091983795166
            },
            {
              "word": "i had the bank done on it",
              "weight": -146.69837951660156
            },
            {
              "word": "i had the brick done on it",
              "weight": -147.32869338989258
            },
            {
              "word": "i had the brakes done on it",
              "weight": -145.45701789855957
            },
            {
              "word": "i had the pack done on it",
              "weight": -147.66455078125
            },
            {
              "word": "i had the brake done on it",
              "weight": -145.77986335754395
            },
            {
              "word": "i had the mic down on it",
              "weight": -148.03073501586914
            },
            {
              "word": "i had the black sun on it",
              "weight": -148.82120513916016
            },
            {
              "word": "i had the brake down on it",
              "weight": -147.59064102172852
            },
            {
              "word": "i had the bank down on it",
              "weight": -148.63109016418457
            },
            {
              "word": "i had the brakes down on it",
              "weight": -147.38329696655273
            },
            {
              "word": "i had the pic done on it",
              "weight": -147.88604164123535
            },
            {
              "word": "i had the pick done on it",
              "weight": -147.8761920928955
            },
            {
              "word": "i had the brake run on it",
              "weight": -150.13887405395508
            },
            {
              "word": "i had the bank's done on it",
              "weight": -150.20186614990234
            },
            {
              "word": "i had the mic done on it",
              "weight": -147.41205024719238
            },
            {
              "word": "i had to break down on it",
              "weight": -151.8275260925293
            },
            {
              "word": "i had the mac done on it",
              "weight": -149.5458583831787
            },
            {
              "word": "i had the banks done on it",
              "weight": -148.6926727294922
            },
            {
              "word": "i had the books done on it",
              "weight": -146.79511833190918
            },
            {
              "word": "i had the crack down on it",
              "weight": -151.54967498779297
            },
            {
              "word": "had the back done on it",
              "weight": -150.14101028442383
            },
            {
              "word": "i had the brick down on it",
              "weight": -149.63992881774902
            },
            {
              "word": "i had the pac done on it",
              "weight": -151.36757469177246
            },
            {
              "word": "i had the bank run on it",
              "weight": -150.53406524658203
            },
            {
              "word": "i had the bic done on it",
              "weight": -150.06472396850586
            },
            {
              "word": "i had the make done on it",
              "weight": -149.7991542816162
            },
            {
              "word": "i had a break done on it",
              "weight": -148.8718662261963
            },
            {
              "word": "i had the back on on it",
              "weight": -151.45147895812988
            },
            {
              "word": "i had the bricks down on it",
              "weight": -149.66741943359375
            },
            {
              "word": "i had the bricks done on it",
              "weight": -148.3501262664795
            },
            {
              "word": "had the backs down on it",
              "weight": -150.17566299438477
            },
            {
              "word": "had the break done on it",
              "weight": -150.39250564575195
            },
            {
              "word": "had the backs done on it",
              "weight": -151.9352684020996
            },
            {
              "word": "had the back in on it",
              "weight": -155.67309951782227
            },
            {
              "word": "had the back on on it",
              "weight": -156.52510833740234
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "You just sit down on on the deck.",
              "It's on down the line.",
              "Putting things on the back burner.",
              "I heard it on the radio.",
              "They're not done on a regular basis.",
              "because it's an invasion of personal privacy",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times"
            ],
            "retrieval_time_ms": 16.49766000002728
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "i had the back down on it",
                "llm_score": -200.1730499267578,
                "old_lm_score": -36.4833984375,
                "acoustic_score": -48.342933654785156,
                "combined_score": -142.49969100952148
              },
              {
                "candidate": "i had the break down on it",
                "llm_score": -201.13938903808594,
                "old_lm_score": -36.3828125,
                "acoustic_score": -50.91652297973633,
                "combined_score": -144.21936225891113
              },
              {
                "candidate": "i had the back done on it",
                "llm_score": -207.31277465820312,
                "old_lm_score": -43.5537109375,
                "acoustic_score": -40.281803131103516,
                "combined_score": -145.57414436340332
              },
              {
                "candidate": "i had the backs down on it",
                "llm_score": -202.31927490234375,
                "old_lm_score": -38.87109375,
                "acoustic_score": -50.319278717041016,
                "combined_score": -145.75482368469238
              },
              {
                "candidate": "i had a break down on it",
                "llm_score": -198.35055541992188,
                "old_lm_score": -33.09375,
                "acoustic_score": -62.25894546508789,
                "combined_score": -146.85162544250488
              },
              {
                "candidate": "i had the breaks down on it",
                "llm_score": -204.15472412109375,
                "old_lm_score": -37.84765625,
                "acoustic_score": -52.89287567138672,
                "combined_score": -147.44762802124023
              },
              {
                "candidate": "i had the work done on it",
                "llm_score": -197.69833374023438,
                "old_lm_score": -30.71484375,
                "acoustic_score": -67.262939453125,
                "combined_score": -147.8380584716797
              },
              {
                "candidate": "i had the book done on it",
                "llm_score": -197.71295166015625,
                "old_lm_score": -40.73828125,
                "acoustic_score": -48.65652084350586,
                "combined_score": -143.55387687683105
              },
              {
                "candidate": "i had to back down on it",
                "llm_score": -195.4429931640625,
                "old_lm_score": -28.603515625,
                "acoustic_score": -73.20689392089844,
                "combined_score": -148.62670135498047
              },
              {
                "candidate": "had the back down on it",
                "llm_score": -197.5677490234375,
                "old_lm_score": -33.599609375,
                "acoustic_score": -63.34562301635742,
                "combined_score": -147.25649070739746
              },
              {
                "candidate": "i had the book down on it",
                "llm_score": -198.90322875976562,
                "old_lm_score": -37.0048828125,
                "acoustic_score": -56.717647552490234,
                "combined_score": -146.31287956237793
              },
              {
                "candidate": "i had the bike down on it",
                "llm_score": -201.78550720214844,
                "old_lm_score": -36.3076171875,
                "acoustic_score": -58.160301208496094,
                "combined_score": -148.12671279907227
              },
              {
                "candidate": "i had a back down on it",
                "llm_score": -199.90640258789062,
                "old_lm_score": -35.80078125,
                "acoustic_score": -59.68535614013672,
                "combined_score": -147.69626998901367
              },
              {
                "candidate": "i had the backed down on it",
                "llm_score": -209.48500061035156,
                "old_lm_score": -40.0322265625,
                "acoustic_score": -51.95159912109375,
                "combined_score": -150.73441314697266
              },
              {
                "candidate": "i had the break done on it",
                "llm_score": -204.4073944091797,
                "old_lm_score": -44.62890625,
                "acoustic_score": -42.85539627075195,
                "combined_score": -145.94584846496582
              },
              {
                "candidate": "had the break down on it",
                "llm_score": -198.48802185058594,
                "old_lm_score": -33.4990234375,
                "acoustic_score": -65.9192123413086,
                "combined_score": -148.95312881469727
              },
              {
                "candidate": "i had the black done on it",
                "llm_score": -204.03749084472656,
                "old_lm_score": -42.357421875,
                "acoustic_score": -48.36943817138672,
                "combined_score": -147.38217544555664
              },
              {
                "candidate": "i had the bike done on it",
                "llm_score": -201.8338623046875,
                "old_lm_score": -41.57421875,
                "acoustic_score": -50.09917068481445,
                "combined_score": -146.75362586975098
              },
              {
                "candidate": "i had the backs done on it",
                "llm_score": -207.48411560058594,
                "old_lm_score": -45.5234375,
                "acoustic_score": -42.25815200805664,
                "combined_score": -147.6328525543213
              },
              {
                "candidate": "i had the back in on it",
                "llm_score": -204.56822204589844,
                "old_lm_score": -36.705078125,
                "acoustic_score": -59.97779846191406,
                "combined_score": -150.62554931640625
              },
              {
                "candidate": "i had the pack down on it",
                "llm_score": -203.75552368164062,
                "old_lm_score": -39.7412109375,
                "acoustic_score": -54.12166213989258,
                "combined_score": -148.8091983795166
              },
              {
                "candidate": "i had the bank done on it",
                "llm_score": -203.17933654785156,
                "old_lm_score": -43.5380859375,
                "acoustic_score": -46.67933654785156,
                "combined_score": -146.69837951660156
              },
              {
                "candidate": "i had the brick done on it",
                "llm_score": -205.95176696777344,
                "old_lm_score": -45.1455078125,
                "acoustic_score": -43.56011199951172,
                "combined_score": -147.32869338989258
              },
              {
                "candidate": "i had the brakes done on it",
                "llm_score": -201.53248596191406,
                "old_lm_score": -44.5498046875,
                "acoustic_score": -44.83174514770508,
                "combined_score": -145.45701789855957
              },
              {
                "candidate": "i had the pack done on it",
                "llm_score": -205.18751525878906,
                "old_lm_score": -44.0810546875,
                "acoustic_score": -46.06053161621094,
                "combined_score": -147.66455078125
              },
              {
                "candidate": "i had the brake done on it",
                "llm_score": -202.87327575683594,
                "old_lm_score": -45.8310546875,
                "acoustic_score": -42.85539627075195,
                "combined_score": -145.77986335754395
              },
              {
                "candidate": "i had the mic down on it",
                "llm_score": -200.46446228027344,
                "old_lm_score": -38.9619140625,
                "acoustic_score": -56.635093688964844,
                "combined_score": -148.03073501586914
              },
              {
                "candidate": "i had the black sun on it",
                "llm_score": -202.50885009765625,
                "old_lm_score": -39.6171875,
                "acoustic_score": -55.51637268066406,
                "combined_score": -148.82120513916016
              },
              {
                "candidate": "i had the brake down on it",
                "llm_score": -202.33311462402344,
                "old_lm_score": -41.931640625,
                "acoustic_score": -50.916526794433594,
                "combined_score": -147.59064102172852
              },
              {
                "candidate": "i had the bank down on it",
                "llm_score": -202.47679138183594,
                "old_lm_score": -40.044921875,
                "acoustic_score": -54.7404670715332,
                "combined_score": -148.63109016418457
              },
              {
                "candidate": "i had the brakes down on it",
                "llm_score": -200.80340576171875,
                "old_lm_score": -41.0703125,
                "acoustic_score": -52.89287567138672,
                "combined_score": -147.38329696655273
              },
              {
                "candidate": "i had the pic done on it",
                "llm_score": -204.25502014160156,
                "old_lm_score": -43.8837890625,
                "acoustic_score": -47.63327407836914,
                "combined_score": -147.88604164123535
              },
              {
                "candidate": "i had the pick done on it",
                "llm_score": -204.18649291992188,
                "old_lm_score": -43.9326171875,
                "acoustic_score": -47.63327407836914,
                "combined_score": -147.8761920928955
              },
              {
                "candidate": "i had the brake run on it",
                "llm_score": -204.58456420898438,
                "old_lm_score": -39.841796875,
                "acoustic_score": -55.85138702392578,
                "combined_score": -150.13887405395508
              },
              {
                "candidate": "i had the bank's done on it",
                "llm_score": -208.2490234375,
                "old_lm_score": -43.4990234375,
                "acoustic_score": -48.65568542480469,
                "combined_score": -150.20186614990234
              },
              {
                "candidate": "i had the mic done on it",
                "llm_score": -202.70130920410156,
                "old_lm_score": -43.548828125,
                "acoustic_score": -48.5739631652832,
                "combined_score": -147.41205024719238
              },
              {
                "candidate": "i had to break down on it",
                "llm_score": -197.8511199951172,
                "old_lm_score": -30.0234375,
                "acoustic_score": -75.7804946899414,
                "combined_score": -151.8275260925293
              },
              {
                "candidate": "i had the mac done on it",
                "llm_score": -207.6627655029297,
                "old_lm_score": -44.427734375,
                "acoustic_score": -47.001216888427734,
                "combined_score": -149.5458583831787
              },
              {
                "candidate": "i had the banks done on it",
                "llm_score": -204.8292694091797,
                "old_lm_score": -43.900390625,
                "acoustic_score": -48.65568542480469,
                "combined_score": -148.6926727294922
              },
              {
                "candidate": "i had the books done on it",
                "llm_score": -200.03353881835938,
                "old_lm_score": -42.923828125,
                "acoustic_score": -50.632869720458984,
                "combined_score": -146.79511833190918
              },
              {
                "candidate": "i had the crack down on it",
                "llm_score": -199.9833984375,
                "old_lm_score": -33.3984375,
                "acoustic_score": -69.71751403808594,
                "combined_score": -151.54967498779297
              },
              {
                "candidate": "had the back done on it",
                "llm_score": -204.32760620117188,
                "old_lm_score": -40.669921875,
                "acoustic_score": -55.28449249267578,
                "combined_score": -150.14101028442383
              },
              {
                "candidate": "i had the brick down on it",
                "llm_score": -205.1547088623047,
                "old_lm_score": -42.50390625,
                "acoustic_score": -51.62124252319336,
                "combined_score": -149.63992881774902
              },
              {
                "candidate": "i had the pac done on it",
                "llm_score": -211.37677001953125,
                "old_lm_score": -45.2978515625,
                "acoustic_score": -46.06052780151367,
                "combined_score": -151.36757469177246
              },
              {
                "candidate": "i had the bank run on it",
                "llm_score": -202.83714294433594,
                "old_lm_score": -38.5556640625,
                "acoustic_score": -59.675323486328125,
                "combined_score": -150.53406524658203
              },
              {
                "candidate": "i had the bic done on it",
                "llm_score": -210.80712890625,
                "old_lm_score": -47.4677734375,
                "acoustic_score": -41.85454559326172,
                "combined_score": -150.06472396850586
              },
              {
                "candidate": "i had the make done on it",
                "llm_score": -207.25738525390625,
                "old_lm_score": -44.4716796875,
                "acoustic_score": -47.86924362182617,
                "combined_score": -149.7991542816162
              },
              {
                "candidate": "i had a break done on it",
                "llm_score": -202.20606994628906,
                "old_lm_score": -41.33984375,
                "acoustic_score": -54.197818756103516,
                "combined_score": -148.8718662261963
              },
              {
                "candidate": "i had the back on on it",
                "llm_score": -206.04141235351562,
                "old_lm_score": -40.03125,
                "acoustic_score": -56.83029556274414,
                "combined_score": -151.45147895812988
              },
              {
                "candidate": "i had the bricks down on it",
                "llm_score": -203.94329833984375,
                "old_lm_score": -41.7939453125,
                "acoustic_score": -53.59759521484375,
                "combined_score": -149.66741943359375
              },
              {
                "candidate": "i had the bricks done on it",
                "llm_score": -205.32785034179688,
                "old_lm_score": -45.8359375,
                "acoustic_score": -45.53646469116211,
                "combined_score": -148.3501262664795
              },
              {
                "candidate": "had the backs down on it",
                "llm_score": -199.04205322265625,
                "old_lm_score": -35.9873046875,
                "acoustic_score": -65.32196807861328,
                "combined_score": -150.17566299438477
              },
              {
                "candidate": "had the break done on it",
                "llm_score": -201.1818084716797,
                "old_lm_score": -41.7451171875,
                "acoustic_score": -57.85808563232422,
                "combined_score": -150.39250564575195
              },
              {
                "candidate": "had the backs done on it",
                "llm_score": -203.9700469970703,
                "old_lm_score": -42.6396484375,
                "acoustic_score": -57.260841369628906,
                "combined_score": -151.9352684020996
              },
              {
                "candidate": "had the back in on it",
                "llm_score": -202.54441833496094,
                "old_lm_score": -33.8212890625,
                "acoustic_score": -74.9804916381836,
                "combined_score": -155.67309951782227
              },
              {
                "candidate": "had the back on on it",
                "llm_score": -204.0697784423828,
                "old_lm_score": -37.1474609375,
                "acoustic_score": -71.83297729492188,
                "combined_score": -156.52510833740234
              }
            ],
            "selected": "i had the back down on it",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 1123.2989449999877
        }
      ],
      "total_time_ms": 1143.0522179999798
    },
    {
      "sentence_idx": 18,
      "ground_truth": "which i use as a reference and has been real handy",
      "top1_hypothesis": "what i do as a wife and have been real handy",
      "final_decoded": "what i do as a wife and have been real handy",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 3,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "what",
          "confusion_candidates": [
            {
              "word": "what",
              "weight": 0.0012716943414778337
            },
            {
              "word": "which",
              "weight": 0.9981154906466376
            },
            {
              "word": "with",
              "weight": 0.0006128150108845115
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.014894900771743045,
            "margin": 0.9968437963051598,
            "disagreement_mass": 0.0018845093533623736
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "i",
          "confusion_candidates": [
            {
              "word": "i",
              "weight": 0.27219806422949944
            },
            {
              "word": "eye",
              "weight": 0.7271891207586159
            },
            {
              "word": "ai",
              "weight": 0.0006128150108845115
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5903839651613372,
            "margin": 0.4549910565291164,
            "disagreement_mass": 0.27281087924138414
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "what (i OR eye OR ai) do as a wife and",
            "retrieved_docs": [
              "What do you usually do as far as budgeting.",
              "My wife and I did have a budget.",
              "My wife and I both like it.",
              "And what do you know?",
              "What can I hide and what do I have to tell?",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it"
            ],
            "scores": [
              11.754286791614906,
              10.704699424710784,
              9.983559683283387,
              9.886077116567277,
              9.864636877148808,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 12.489878999986104
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "do",
          "confusion_candidates": [
            {
              "word": "do",
              "weight": 0.0009754793955896517
            },
            {
              "word": "you",
              "weight": 0.9990209776033064
            },
            {
              "word": "use",
              "weight": 3.5430001039164294e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.007785599978662139,
            "margin": 0.9980454982077168,
            "disagreement_mass": 0.000979022396693563
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "as",
          "confusion_candidates": [
            {
              "word": "as",
              "weight": 0.9999996872246256
            },
            {
              "word": "has",
              "weight": 3.127743743821797e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 4.997440269077371e-06,
            "margin": 0.9999993744502512,
            "disagreement_mass": 3.1277537437812697e-07
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "wife",
          "confusion_candidates": [
            {
              "word": "wife",
              "weight": 0.11802894964039679
            },
            {
              "word": "gift",
              "weight": 0.0023223929772945386
            },
            {
              "word": "risk",
              "weight": 7.707825473564783e-06
            },
            {
              "word": "ref",
              "weight": 0.8787598673992202
            },
            {
              "word": "rift",
              "weight": 0.0005617400830360818
            },
            {
              "word": "riff",
              "weight": 0.00024130337031253048
            },
            {
              "word": "draft",
              "weight": 7.141013975357625e-07
            },
            {
              "word": "whip",
              "weight": 7.122185902268537e-07
            },
            {
              "word": "race",
              "weight": 1.256780727353161e-07
            },
            {
              "word": "priest",
              "weight": 7.17164293424086e-08
            },
            {
              "word": "whiff",
              "weight": 7.111466470195112e-05
            },
            {
              "word": "team",
              "weight": 1.9383048802481706e-10
            },
            {
              "word": "person",
              "weight": 2.341880262909763e-10
            },
            {
              "word": "refund",
              "weight": 5.669275584373133e-07
            },
            {
              "word": "rough",
              "weight": 9.437054104101012e-07
            },
            {
              "word": "weapon",
              "weight": 1.70442643336234e-07
            },
            {
              "word": "rest",
              "weight": 3.7577550678008743e-07
            },
            {
              "word": "swift",
              "weight": 8.54662798577688e-07
            },
            {
              "word": "roof",
              "weight": 9.806310787930205e-07
            },
            {
              "word": "safe",
              "weight": 2.855899526713366e-08
            },
            {
              "word": "raft",
              "weight": 1.3791920643622399e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.38694870789201175,
            "margin": 0.7607309177588234,
            "disagreement_mass": 0.12124013260077982
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 7,
          "span_end": 8,
          "top1_word": "have",
          "confusion_candidates": [
            {
              "word": "have",
              "weight": 0.7607091781570869
            },
            {
              "word": "has",
              "weight": 0.23929082184191308
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5502610933674223,
            "margin": 0.5214183563151739,
            "disagreement_mass": 0.23929082184291306
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "do as a wife and (have OR has) been real handy",
            "retrieved_docs": [
              "It has been real good talking to you.",
              "My wife and I did have a budget.",
              "When your wife has her baby.",
              "That's been a real big plus.",
              "A bold decision has been made.",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it"
            ],
            "scores": [
              11.875573338278873,
              11.732285039656908,
              11.235261828607875,
              10.47122957379967,
              10.47122957379967,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 12.4354829999902
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 9,
          "span_end": 10,
          "top1_word": "real",
          "confusion_candidates": [
            {
              "word": "real",
              "weight": 0.9997929378328378
            },
            {
              "word": "really",
              "weight": 0.0002070621661620238
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0019634437887158475,
            "margin": 0.9995858756666758,
            "disagreement_mass": 0.0002070621671621531
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 10,
          "span_end": 11,
          "top1_word": "handy",
          "confusion_candidates": [
            {
              "word": "handy",
              "weight": 0.7787174922570034
            },
            {
              "word": "hand",
              "weight": 0.22089741383839182
            },
            {
              "word": "hands",
              "weight": 0.00038509390360490567
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5313579353425779,
            "margin": 0.5578200784186116,
            "disagreement_mass": 0.22128250774299663
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "wife and have been real (handy OR hand OR hands)",
            "retrieved_docs": [
              "It's been real busy.",
              "Never been real thrilled.",
              "My wife and I did have a budget.",
              "Those have been real popular with my family.",
              "So you have your hands full with them?",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it"
            ],
            "scores": [
              10.438402071005278,
              10.438402071005278,
              10.376488217365106,
              10.194890407682582,
              10.154580992961058,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 10.091176000059932
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 11,
          "top1_word": "what i do as a wife and have been real handy",
          "confusion_candidates": [
            {
              "word": "what i do as a wife and have been real handy",
              "weight": -193.68783569335938
            },
            {
              "word": "what i do as a wife and have been real hand",
              "weight": -194.70721817016602
            },
            {
              "word": "which eye you as a wife and have been real handy",
              "weight": -195.61048889160156
            },
            {
              "word": "what i do as a gift and have been real handy",
              "weight": -196.92399215698242
            },
            {
              "word": "which eye you as a wife and have been real hand",
              "weight": -196.94005966186523
            },
            {
              "word": "what i do as a risk and have been real handy",
              "weight": -198.34119415283203
            },
            {
              "word": "which eye you as a ref and have been real handy",
              "weight": -198.55022048950195
            },
            {
              "word": "what i do as a gift and have been real hand",
              "weight": -197.88043212890625
            },
            {
              "word": "what i do as a rift and have been real handy",
              "weight": -198.6745948791504
            },
            {
              "word": "what i do as a wife and have been really handy",
              "weight": -195.50750732421875
            },
            {
              "word": "what i do as a risk and have been real hand",
              "weight": -198.8444938659668
            },
            {
              "word": "which eye you as a ref and have been real hand",
              "weight": -199.9103775024414
            },
            {
              "word": "what i do as a rift and have been real hand",
              "weight": -199.4778594970703
            },
            {
              "word": "which i you as a wife and have been real handy",
              "weight": -193.97911834716797
            },
            {
              "word": "what i do as a riff and have been real handy",
              "weight": -197.80166625976562
            },
            {
              "word": "which eye you as a ref and has been real handy",
              "weight": -199.08141326904297
            },
            {
              "word": "what i do as a rift and has been real handy",
              "weight": -199.54021453857422
            },
            {
              "word": "which i you as a wife and have been real hand",
              "weight": -195.09560012817383
            },
            {
              "word": "which eye you as a wife and have been really handy",
              "weight": -197.7182159423828
            },
            {
              "word": "what i do as a ref and have been real handy",
              "weight": -197.59169387817383
            },
            {
              "word": "what i do as a riff and have been real hand",
              "weight": -198.56664657592773
            },
            {
              "word": "which eye you as a ref and has been real hand",
              "weight": -200.41354751586914
            },
            {
              "word": "which i you as a ref and have been real handy",
              "weight": -196.77714920043945
            },
            {
              "word": "what i do as a rift and has been real hand",
              "weight": -200.55381393432617
            },
            {
              "word": "what i do as a gift and have been really handy",
              "weight": -198.65352249145508
            },
            {
              "word": "what i do as a riff and has been real handy",
              "weight": -198.4807472229004
            },
            {
              "word": "what i do as a risk and has been real handy",
              "weight": -199.61258697509766
            },
            {
              "word": "what i do as a draft and has been real handy",
              "weight": -200.23239135742188
            },
            {
              "word": "what i do as a ref and have been real hand",
              "weight": -198.6155242919922
            },
            {
              "word": "which eye you as a gift and have been real handy",
              "weight": -198.86106491088867
            },
            {
              "word": "what i do as a whip and has been real handy",
              "weight": -199.4385986328125
            },
            {
              "word": "what i do as a race and have been real handy",
              "weight": -200.98890686035156
            },
            {
              "word": "what i do as a gift and has been real handy",
              "weight": -198.33998107910156
            },
            {
              "word": "which i you as a ref and have been real hand",
              "weight": -197.83872985839844
            },
            {
              "word": "what i do as a wife and has been real handy",
              "weight": -195.99444198608398
            },
            {
              "word": "what i do as a priest and have been real handy",
              "weight": -198.50745391845703
            },
            {
              "word": "what i do as a draft and have been real handy",
              "weight": -199.75912475585938
            },
            {
              "word": "what i do as a risk and have been really handy",
              "weight": -199.8740692138672
            },
            {
              "word": "which eye you as a ref and have been really handy",
              "weight": -200.65109634399414
            },
            {
              "word": "what i do as a whiff and have been real handy",
              "weight": -200.47639846801758
            },
            {
              "word": "what i do as a rift and have been really handy",
              "weight": -200.57636642456055
            },
            {
              "word": "what i do as a wife and have been real hands",
              "weight": -196.5096092224121
            },
            {
              "word": "what i do as a team and have been real handy",
              "weight": -200.89017868041992
            },
            {
              "word": "what i do as a ref and has been real handy",
              "weight": -198.47962951660156
            },
            {
              "word": "what i do as a riff and has been real hand",
              "weight": -199.50125885009766
            },
            {
              "word": "what i do as a risk and has been real hand",
              "weight": -200.4623680114746
            },
            {
              "word": "what i do as a draft and has been real hand",
              "weight": -201.56235122680664
            },
            {
              "word": "which i use as a wife and have been real handy",
              "weight": -197.52684783935547
            },
            {
              "word": "which i you as a ref and has been real handy",
              "weight": -197.77494049072266
            },
            {
              "word": "which eye you as a gift and have been real hand",
              "weight": -200.08312225341797
            },
            {
              "word": "what i do as a whip and has been real hand",
              "weight": -200.8213768005371
            },
            {
              "word": "what i do as a race and have been real hand",
              "weight": -201.64276504516602
            },
            {
              "word": "what i do as a gift and has been real hand",
              "weight": -199.6356544494629
            },
            {
              "word": "what i do as a wife and has been real hand",
              "weight": -197.30657196044922
            },
            {
              "word": "what i do has a wife and have been real handy",
              "weight": -197.6972885131836
            },
            {
              "word": "what i do as a priest and have been real hand",
              "weight": -199.67434310913086
            },
            {
              "word": "what i do as a draft and have been real hand",
              "weight": -200.79925918579102
            },
            {
              "word": "what i do as a person and have been real handy",
              "weight": -199.20226287841797
            },
            {
              "word": "what i do as a refund and have been real handy",
              "weight": -199.08554458618164
            },
            {
              "word": "what i do as a rough and have been real handy",
              "weight": -198.88826370239258
            },
            {
              "word": "what i do as a whiff and have been real hand",
              "weight": -201.05014038085938
            },
            {
              "word": "which i do as a wife and have been real handy",
              "weight": -194.02027893066406
            },
            {
              "word": "which eye you as a ref and has been really handy",
              "weight": -201.16243743896484
            },
            {
              "word": "what i do as a team and have been real hand",
              "weight": -201.90564727783203
            },
            {
              "word": "what i do as a ref and has been real hand",
              "weight": -199.74969863891602
            },
            {
              "word": "which i you as a wife and have been really handy",
              "weight": -195.62120819091797
            },
            {
              "word": "which i use as a weapon and has been real handy",
              "weight": -196.86000061035156
            },
            {
              "word": "what i do as a rest and have been real handy",
              "weight": -199.28106307983398
            },
            {
              "word": "which eye you as a wife and has been real handy",
              "weight": -197.60552597045898
            },
            {
              "word": "what i do as a rift and has been really handy",
              "weight": -201.3846664428711
            },
            {
              "word": "which i use as a wife and have been real hand",
              "weight": -198.74528884887695
            },
            {
              "word": "which i you as a ref and has been real hand",
              "weight": -199.19296646118164
            },
            {
              "word": "what i do as a priest and has been real handy",
              "weight": -199.62471389770508
            },
            {
              "word": "which i use as a weapon and have been real handy",
              "weight": -197.95409774780273
            },
            {
              "word": "what i do as a riff and have been really handy",
              "weight": -199.5658721923828
            },
            {
              "word": "what i do as a weapon and has been real handy",
              "weight": -200.55215454101562
            },
            {
              "word": "what i do as a swift and have been real handy",
              "weight": -200.53415298461914
            },
            {
              "word": "what i do as a roof and have been real handy",
              "weight": -199.75006103515625
            },
            {
              "word": "what i do as a safe and have been real handy",
              "weight": -200.82242584228516
            },
            {
              "word": "what i do has a wife and have been real hand",
              "weight": -199.36327743530273
            },
            {
              "word": "what i do as a whiff and has been real handy",
              "weight": -201.44561767578125
            },
            {
              "word": "what i you as a wife and have been real handy",
              "weight": -196.8333740234375
            },
            {
              "word": "what i do as a person and have been real hand",
              "weight": -200.01700973510742
            },
            {
              "word": "what i do as a refund and have been real hand",
              "weight": -200.1494598388672
            },
            {
              "word": "what i do as a weapon and have been real handy",
              "weight": -200.1202507019043
            },
            {
              "word": "which eye you as a wife and have been real hands",
              "weight": -198.92059707641602
            },
            {
              "word": "what i do as a rough and have been real hand",
              "weight": -199.5205841064453
            },
            {
              "word": "which i do as a wife and have been real hand",
              "weight": -195.22034072875977
            },
            {
              "word": "with ai you as a wife and have been real handy",
              "weight": -200.75797271728516
            },
            {
              "word": "what i do as a whip and have been real handy",
              "weight": -199.30993270874023
            },
            {
              "word": "what i do as a raft and have been real handy",
              "weight": -200.01409530639648
            },
            {
              "word": "which i use as a weapon and has been real hand",
              "weight": -199.31225967407227
            },
            {
              "word": "what i do as a rest and have been real hand",
              "weight": -200.3966064453125
            },
            {
              "word": "which eye you as a wife and has been real hand",
              "weight": -199.0386962890625
            },
            {
              "word": "which i you as a gift and have been real handy",
              "weight": -197.4744987487793
            },
            {
              "word": "what i do as a priest and has been real hand",
              "weight": -201.12421417236328
            },
            {
              "word": "what i do as a ref and have been really handy",
              "weight": -199.44897842407227
            },
            {
              "word": "what i do as a gift and have been real hands",
              "weight": -199.7429428100586
            },
            {
              "word": "which i use as a weapon and have been real hand",
              "weight": -199.3364486694336
            },
            {
              "word": "what i do as a weapon and has been real hand",
              "weight": -202.0427589416504
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "What do you usually do as far as budgeting.",
              "My wife and I did have a budget.",
              "My wife and I both like it.",
              "And what do you know?",
              "What can I hide and what do I have to tell?",
              "so you travel a lot",
              "they were going to write",
              "any kind of a good environment to live in",
              "the best of android",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it",
              "It has been real good talking to you.",
              "When your wife has her baby.",
              "That's been a real big plus.",
              "A bold decision has been made.",
              "It's been real busy.",
              "Never been real thrilled.",
              "Those have been real popular with my family.",
              "So you have your hands full with them?"
            ],
            "retrieval_time_ms": 35.016538000036235
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "what i do as a wife and have been real handy",
                "llm_score": -234.2689208984375,
                "old_lm_score": -60.6787109375,
                "acoustic_score": -92.42803955078125,
                "combined_score": -193.68783569335938
              },
              {
                "candidate": "what i do as a wife and have been real hand",
                "llm_score": -235.04989624023438,
                "old_lm_score": -60.08984375,
                "acoustic_score": -94.27469635009766,
                "combined_score": -194.70721817016602
              },
              {
                "candidate": "which eye you as a wife and have been real handy",
                "llm_score": -246.3143310546875,
                "old_lm_score": -70.0009765625,
                "acoustic_score": -74.90567016601562,
                "combined_score": -195.61048889160156
              },
              {
                "candidate": "what i do as a gift and have been real handy",
                "llm_score": -237.90785217285156,
                "old_lm_score": -59.4345703125,
                "acoustic_score": -96.50556182861328,
                "combined_score": -196.92399215698242
              },
              {
                "candidate": "which eye you as a wife and have been real hand",
                "llm_score": -247.71568298339844,
                "old_lm_score": -69.412109375,
                "acoustic_score": -76.75232696533203,
                "combined_score": -196.94005966186523
              },
              {
                "candidate": "what i do as a risk and have been real handy",
                "llm_score": -242.3345184326172,
                "old_lm_score": -61.572265625,
                "acoustic_score": -92.77560424804688,
                "combined_score": -198.34119415283203
              },
              {
                "candidate": "which eye you as a ref and have been real handy",
                "llm_score": -253.94485473632812,
                "old_lm_score": -72.8056640625,
                "acoustic_score": -70.34992218017578,
                "combined_score": -198.55022048950195
              },
              {
                "candidate": "what i do as a gift and have been real hand",
                "llm_score": -238.5629425048828,
                "old_lm_score": -58.845703125,
                "acoustic_score": -98.35221862792969,
                "combined_score": -197.88043212890625
              },
              {
                "candidate": "what i do as a rift and have been real handy",
                "llm_score": -247.15716552734375,
                "old_lm_score": -65.93359375,
                "acoustic_score": -84.25843048095703,
                "combined_score": -198.6745948791504
              },
              {
                "candidate": "what i do as a wife and have been really handy",
                "llm_score": -229.9259490966797,
                "old_lm_score": -55.423828125,
                "acoustic_score": -105.66523742675781,
                "combined_score": -195.50750732421875
              },
              {
                "candidate": "what i do as a risk and have been real hand",
                "llm_score": -242.0833282470703,
                "old_lm_score": -60.9833984375,
                "acoustic_score": -94.62226104736328,
                "combined_score": -198.8444938659668
              },
              {
                "candidate": "which eye you as a ref and have been real hand",
                "llm_score": -255.40737915039062,
                "old_lm_score": -72.216796875,
                "acoustic_score": -72.19657897949219,
                "combined_score": -199.9103775024414
              },
              {
                "candidate": "what i do as a rift and have been real hand",
                "llm_score": -247.5059051513672,
                "old_lm_score": -65.3447265625,
                "acoustic_score": -86.10508728027344,
                "combined_score": -199.4778594970703
              },
              {
                "candidate": "which i you as a wife and have been real handy",
                "llm_score": -242.0720977783203,
                "old_lm_score": -70.98046875,
                "acoustic_score": -74.90567016601562,
                "combined_score": -193.97911834716797
              },
              {
                "candidate": "what i do as a riff and have been real handy",
                "llm_score": -244.56640625,
                "old_lm_score": -66.0537109375,
                "acoustic_score": -84.98321533203125,
                "combined_score": -197.80166625976562
              },
              {
                "candidate": "which eye you as a ref and has been real handy",
                "llm_score": -253.99522399902344,
                "old_lm_score": -72.95703125,
                "acoustic_score": -71.2105712890625,
                "combined_score": -199.08141326904297
              },
              {
                "candidate": "what i do as a rift and has been real handy",
                "llm_score": -247.8763885498047,
                "old_lm_score": -66.0849609375,
                "acoustic_score": -85.11907958984375,
                "combined_score": -199.54021453857422
              },
              {
                "candidate": "which i you as a wife and have been real hand",
                "llm_score": -243.04727172851562,
                "old_lm_score": -70.3916015625,
                "acoustic_score": -76.75232696533203,
                "combined_score": -195.09560012817383
              },
              {
                "candidate": "which eye you as a wife and have been really handy",
                "llm_score": -242.54747009277344,
                "old_lm_score": -64.74609375,
                "acoustic_score": -88.14286804199219,
                "combined_score": -197.7182159423828
              },
              {
                "candidate": "what i do as a ref and have been real handy",
                "llm_score": -242.37750244140625,
                "old_lm_score": -64.93359375,
                "acoustic_score": -87.8722915649414,
                "combined_score": -197.59169387817383
              },
              {
                "candidate": "what i do as a riff and have been real hand",
                "llm_score": -244.8385772705078,
                "old_lm_score": -65.46484375,
                "acoustic_score": -86.82987213134766,
                "combined_score": -198.56664657592773
              },
              {
                "candidate": "which eye you as a ref and has been real hand",
                "llm_score": -255.40170288085938,
                "old_lm_score": -72.3681640625,
                "acoustic_score": -73.0572280883789,
                "combined_score": -200.41354751586914
              },
              {
                "candidate": "which i you as a ref and have been real handy",
                "llm_score": -249.41921997070312,
                "old_lm_score": -73.78515625,
                "acoustic_score": -70.34992218017578,
                "combined_score": -196.77714920043945
              },
              {
                "candidate": "what i do as a rift and has been real hand",
                "llm_score": -248.6457977294922,
                "old_lm_score": -65.49609375,
                "acoustic_score": -86.96573638916016,
                "combined_score": -200.55381393432617
              },
              {
                "candidate": "what i do as a gift and have been really handy",
                "llm_score": -233.3845977783203,
                "old_lm_score": -54.1796875,
                "acoustic_score": -109.74275970458984,
                "combined_score": -198.65352249145508
              },
              {
                "candidate": "what i do as a riff and has been real handy",
                "llm_score": -244.9125518798828,
                "old_lm_score": -66.205078125,
                "acoustic_score": -85.84386444091797,
                "combined_score": -198.4807472229004
              },
              {
                "candidate": "what i do as a risk and has been real handy",
                "llm_score": -243.2363739013672,
                "old_lm_score": -62.3525390625,
                "acoustic_score": -93.63626098632812,
                "combined_score": -199.61258697509766
              },
              {
                "candidate": "what i do as a draft and has been real handy",
                "llm_score": -243.056396484375,
                "old_lm_score": -60.9638671875,
                "acoustic_score": -96.44451904296875,
                "combined_score": -200.23239135742188
              },
              {
                "candidate": "what i do as a ref and have been real hand",
                "llm_score": -243.16737365722656,
                "old_lm_score": -64.3447265625,
                "acoustic_score": -89.71894836425781,
                "combined_score": -198.6155242919922
              },
              {
                "candidate": "which eye you as a gift and have been real handy",
                "llm_score": -249.0026092529297,
                "old_lm_score": -69.736328125,
                "acoustic_score": -78.98319244384766,
                "combined_score": -198.86106491088867
              },
              {
                "candidate": "what i do as a whip and has been real handy",
                "llm_score": -241.91900634765625,
                "old_lm_score": -61.544921875,
                "acoustic_score": -95.41326904296875,
                "combined_score": -199.4385986328125
              },
              {
                "candidate": "what i do as a race and have been real handy",
                "llm_score": -243.6910400390625,
                "old_lm_score": -60.2197265625,
                "acoustic_score": -98.06704711914062,
                "combined_score": -200.98890686035156
              },
              {
                "candidate": "what i do as a gift and has been real handy",
                "llm_score": -238.72976684570312,
                "old_lm_score": -60.583984375,
                "acoustic_score": -97.3662109375,
                "combined_score": -198.33998107910156
              },
              {
                "candidate": "which i you as a ref and have been real hand",
                "llm_score": -250.2845916748047,
                "old_lm_score": -73.1962890625,
                "acoustic_score": -72.19657897949219,
                "combined_score": -197.83872985839844
              },
              {
                "candidate": "what i do as a wife and has been real handy",
                "llm_score": -236.0498046875,
                "old_lm_score": -62.650390625,
                "acoustic_score": -93.28868865966797,
                "combined_score": -195.99444198608398
              },
              {
                "candidate": "what i do as a priest and have been real handy",
                "llm_score": -237.85708618164062,
                "old_lm_score": -59.455078125,
                "acoustic_score": -99.70274353027344,
                "combined_score": -198.50745391845703
              },
              {
                "candidate": "what i do as a draft and have been real handy",
                "llm_score": -242.41778564453125,
                "old_lm_score": -61.5166015625,
                "acoustic_score": -95.5838623046875,
                "combined_score": -199.75912475585938
              },
              {
                "candidate": "what i do as a risk and have been really handy",
                "llm_score": -237.41795349121094,
                "old_lm_score": -56.3173828125,
                "acoustic_score": -106.01280212402344,
                "combined_score": -199.8740692138672
              },
              {
                "candidate": "which eye you as a ref and have been really handy",
                "llm_score": -250.16429138183594,
                "old_lm_score": -67.55078125,
                "acoustic_score": -83.58712005615234,
                "combined_score": -200.65109634399414
              },
              {
                "candidate": "what i do as a whiff and have been real handy",
                "llm_score": -248.755126953125,
                "old_lm_score": -66.5888671875,
                "acoustic_score": -85.60880279541016,
                "combined_score": -200.47639846801758
              },
              {
                "candidate": "what i do as a rift and have been really handy",
                "llm_score": -242.9783935546875,
                "old_lm_score": -60.6787109375,
                "acoustic_score": -97.4956283569336,
                "combined_score": -200.57636642456055
              },
              {
                "candidate": "what i do as a wife and have been real hands",
                "llm_score": -234.8097686767578,
                "old_lm_score": -60.6748046875,
                "acoustic_score": -97.5346450805664,
                "combined_score": -196.5096092224121
              },
              {
                "candidate": "what i do as a team and have been real handy",
                "llm_score": -237.0190887451172,
                "old_lm_score": -54.1298828125,
                "acoustic_score": -110.63138580322266,
                "combined_score": -200.89017868041992
              },
              {
                "candidate": "what i do as a ref and has been real handy",
                "llm_score": -243.141357421875,
                "old_lm_score": -65.0849609375,
                "acoustic_score": -88.73294067382812,
                "combined_score": -198.47962951660156
              },
              {
                "candidate": "what i do as a riff and has been real hand",
                "llm_score": -245.69578552246094,
                "old_lm_score": -65.6162109375,
                "acoustic_score": -87.69052124023438,
                "combined_score": -199.50125885009766
              },
              {
                "candidate": "what i do as a risk and has been real hand",
                "llm_score": -243.6781463623047,
                "old_lm_score": -61.763671875,
                "acoustic_score": -95.48291778564453,
                "combined_score": -200.4623680114746
              },
              {
                "candidate": "what i do as a draft and has been real hand",
                "llm_score": -244.45852661132812,
                "old_lm_score": -60.375,
                "acoustic_score": -98.29117584228516,
                "combined_score": -201.56235122680664
              },
              {
                "candidate": "which i use as a wife and have been real handy",
                "llm_score": -240.07012939453125,
                "old_lm_score": -64.087890625,
                "acoustic_score": -90.89567565917969,
                "combined_score": -197.52684783935547
              },
              {
                "candidate": "which i you as a ref and has been real handy",
                "llm_score": -250.4027862548828,
                "old_lm_score": -73.9365234375,
                "acoustic_score": -71.2105712890625,
                "combined_score": -197.77494049072266
              },
              {
                "candidate": "which eye you as a gift and have been real hand",
                "llm_score": -250.18893432617188,
                "old_lm_score": -69.1474609375,
                "acoustic_score": -80.82984924316406,
                "combined_score": -200.08312225341797
              },
              {
                "candidate": "what i do as a whip and has been real hand",
                "llm_score": -243.42677307128906,
                "old_lm_score": -60.9560546875,
                "acoustic_score": -97.25992584228516,
                "combined_score": -200.8213768005371
              },
              {
                "candidate": "what i do as a race and have been real hand",
                "llm_score": -243.740966796875,
                "old_lm_score": -59.630859375,
                "acoustic_score": -99.91370391845703,
                "combined_score": -201.64276504516602
              },
              {
                "candidate": "what i do as a gift and has been real hand",
                "llm_score": -240.06332397460938,
                "old_lm_score": -59.9951171875,
                "acoustic_score": -99.2128677368164,
                "combined_score": -199.6356544494629
              },
              {
                "candidate": "what i do as a wife and has been real hand",
                "llm_score": -237.41627502441406,
                "old_lm_score": -62.0615234375,
                "acoustic_score": -95.13534545898438,
                "combined_score": -197.30657196044922
              },
              {
                "candidate": "what i do has a wife and have been real handy",
                "llm_score": -238.01956176757812,
                "old_lm_score": -61.88671875,
                "acoustic_score": -95.48829650878906,
                "combined_score": -197.6972885131836
              },
              {
                "candidate": "what i do as a priest and have been real hand",
                "llm_score": -238.93307495117188,
                "old_lm_score": -58.8662109375,
                "acoustic_score": -101.54940032958984,
                "combined_score": -199.67434310913086
              },
              {
                "candidate": "what i do as a draft and have been real hand",
                "llm_score": -243.24026489257812,
                "old_lm_score": -60.927734375,
                "acoustic_score": -97.4305191040039,
                "combined_score": -200.79925918579102
              },
              {
                "candidate": "what i do as a person and have been real handy",
                "llm_score": -233.8323974609375,
                "old_lm_score": -54.740234375,
                "acoustic_score": -109.83189392089844,
                "combined_score": -199.20226287841797
              },
              {
                "candidate": "what i do as a refund and have been real handy",
                "llm_score": -241.3908233642578,
                "old_lm_score": -62.541015625,
                "acoustic_score": -94.23925018310547,
                "combined_score": -199.08554458618164
              },
              {
                "candidate": "what i do as a rough and have been real handy",
                "llm_score": -241.50584411621094,
                "old_lm_score": -63.162109375,
                "acoustic_score": -93.10857391357422,
                "combined_score": -198.88826370239258
              },
              {
                "candidate": "what i do as a whiff and have been real hand",
                "llm_score": -248.6448211669922,
                "old_lm_score": -66.0,
                "acoustic_score": -87.45545959472656,
                "combined_score": -201.05014038085938
              },
              {
                "candidate": "which i do as a wife and have been real handy",
                "llm_score": -234.82867431640625,
                "old_lm_score": -66.3115234375,
                "acoustic_score": -86.90036010742188,
                "combined_score": -194.02027893066406
              },
              {
                "candidate": "which eye you as a ref and has been really handy",
                "llm_score": -250.32437133789062,
                "old_lm_score": -67.552734375,
                "acoustic_score": -84.44776916503906,
                "combined_score": -201.16243743896484
              },
              {
                "candidate": "what i do as a team and have been real hand",
                "llm_score": -237.792236328125,
                "old_lm_score": -53.541015625,
                "acoustic_score": -112.47804260253906,
                "combined_score": -201.90564727783203
              },
              {
                "candidate": "what i do as a ref and has been real hand",
                "llm_score": -244.4237060546875,
                "old_lm_score": -64.49609375,
                "acoustic_score": -90.57959747314453,
                "combined_score": -199.74969863891602
              },
              {
                "candidate": "which i you as a wife and have been really handy",
                "llm_score": -237.37396240234375,
                "old_lm_score": -65.7255859375,
                "acoustic_score": -88.14286804199219,
                "combined_score": -195.62120819091797
              },
              {
                "candidate": "which i use as a weapon and has been real handy",
                "llm_score": -234.54119873046875,
                "old_lm_score": -60.466796875,
                "acoustic_score": -98.71200561523438,
                "combined_score": -196.86000061035156
              },
              {
                "candidate": "what i do as a rest and have been real handy",
                "llm_score": -241.37062072753906,
                "old_lm_score": -62.486328125,
                "acoustic_score": -94.7051773071289,
                "combined_score": -199.28106307983398
              },
              {
                "candidate": "which eye you as a wife and has been real handy",
                "llm_score": -247.47207641601562,
                "old_lm_score": -71.97265625,
                "acoustic_score": -75.76631927490234,
                "combined_score": -197.60552597045898
              },
              {
                "candidate": "what i do as a rift and has been really handy",
                "llm_score": -243.73239135742188,
                "old_lm_score": -60.6806640625,
                "acoustic_score": -98.35627746582031,
                "combined_score": -201.3846664428711
              },
              {
                "candidate": "which i use as a wife and have been real hand",
                "llm_score": -241.2492218017578,
                "old_lm_score": -63.4990234375,
                "acoustic_score": -92.7423324584961,
                "combined_score": -198.74528884887695
              },
              {
                "candidate": "which i you as a ref and has been real hand",
                "llm_score": -251.98104858398438,
                "old_lm_score": -73.34765625,
                "acoustic_score": -73.0572280883789,
                "combined_score": -199.19296646118164
              },
              {
                "candidate": "what i do as a priest and has been real handy",
                "llm_score": -239.07958984375,
                "old_lm_score": -59.6064453125,
                "acoustic_score": -100.56339263916016,
                "combined_score": -199.62471389770508
              },
              {
                "candidate": "which i use as a weapon and have been real handy",
                "llm_score": -237.0792999267578,
                "old_lm_score": -60.9775390625,
                "acoustic_score": -97.85135650634766,
                "combined_score": -197.95409774780273
              },
              {
                "candidate": "what i do as a riff and have been really handy",
                "llm_score": -240.1125030517578,
                "old_lm_score": -60.798828125,
                "acoustic_score": -98.22041320800781,
                "combined_score": -199.5658721923828
              },
              {
                "candidate": "what i do as a weapon and has been real handy",
                "llm_score": -241.0650177001953,
                "old_lm_score": -59.794921875,
                "acoustic_score": -100.24436950683594,
                "combined_score": -200.55215454101562
              },
              {
                "candidate": "what i do as a swift and have been real handy",
                "llm_score": -244.94871520996094,
                "old_lm_score": -63.73828125,
                "acoustic_score": -92.38130950927734,
                "combined_score": -200.53415298461914
              },
              {
                "candidate": "what i do as a roof and have been real handy",
                "llm_score": -243.5180206298828,
                "old_lm_score": -63.892578125,
                "acoustic_score": -92.08952331542969,
                "combined_score": -199.75006103515625
              },
              {
                "candidate": "what i do as a safe and have been real handy",
                "llm_score": -242.12652587890625,
                "old_lm_score": -60.384765625,
                "acoustic_score": -99.13356018066406,
                "combined_score": -200.82242584228516
              },
              {
                "candidate": "what i do has a wife and have been real hand",
                "llm_score": -240.09375,
                "old_lm_score": -61.2978515625,
                "acoustic_score": -97.33495330810547,
                "combined_score": -199.36327743530273
              },
              {
                "candidate": "what i do as a whiff and has been real handy",
                "llm_score": -249.68154907226562,
                "old_lm_score": -66.740234375,
                "acoustic_score": -86.46945190429688,
                "combined_score": -201.44561767578125
              },
              {
                "candidate": "what i you as a wife and have been real handy",
                "llm_score": -243.46095275878906,
                "old_lm_score": -69.7724609375,
                "acoustic_score": -80.43333435058594,
                "combined_score": -196.8333740234375
              },
              {
                "candidate": "what i do as a person and have been real hand",
                "llm_score": -234.2041015625,
                "old_lm_score": -54.1513671875,
                "acoustic_score": -111.67855072021484,
                "combined_score": -200.01700973510742
              },
              {
                "candidate": "what i do as a refund and have been real hand",
                "llm_score": -242.2608642578125,
                "old_lm_score": -61.9521484375,
                "acoustic_score": -96.08590698242188,
                "combined_score": -200.1494598388672
              },
              {
                "candidate": "what i do as a weapon and have been real handy",
                "llm_score": -240.55111694335938,
                "old_lm_score": -60.3056640625,
                "acoustic_score": -99.38372039794922,
                "combined_score": -200.1202507019043
              },
              {
                "candidate": "which eye you as a wife and have been real hands",
                "llm_score": -247.83184814453125,
                "old_lm_score": -69.9970703125,
                "acoustic_score": -80.01227569580078,
                "combined_score": -198.92059707641602
              },
              {
                "candidate": "what i do as a rough and have been real hand",
                "llm_score": -241.5126953125,
                "old_lm_score": -62.5732421875,
                "acoustic_score": -94.95523071289062,
                "combined_score": -199.5205841064453
              },
              {
                "candidate": "which i do as a wife and have been real hand",
                "llm_score": -235.97100830078125,
                "old_lm_score": -65.72265625,
                "acoustic_score": -88.74701690673828,
                "combined_score": -195.22034072875977
              },
              {
                "candidate": "with ai you as a wife and have been real handy",
                "llm_score": -251.97146606445312,
                "old_lm_score": -70.6708984375,
                "acoustic_score": -78.87358093261719,
                "combined_score": -200.75797271728516
              },
              {
                "candidate": "what i do as a whip and have been real handy",
                "llm_score": -241.22056579589844,
                "old_lm_score": -62.8466796875,
                "acoustic_score": -94.55261993408203,
                "combined_score": -199.30993270874023
              },
              {
                "candidate": "what i do as a raft and have been real handy",
                "llm_score": -244.38714599609375,
                "old_lm_score": -64.671875,
                "acoustic_score": -90.96916961669922,
                "combined_score": -200.01409530639648
              },
              {
                "candidate": "which i use as a weapon and has been real hand",
                "llm_score": -238.18792724609375,
                "old_lm_score": -59.8779296875,
                "acoustic_score": -100.55866241455078,
                "combined_score": -199.31225967407227
              },
              {
                "candidate": "what i do as a rest and have been real hand",
                "llm_score": -242.3439178466797,
                "old_lm_score": -61.8974609375,
                "acoustic_score": -96.55183410644531,
                "combined_score": -200.3966064453125
              },
              {
                "candidate": "which eye you as a wife and has been real hand",
                "llm_score": -249.08062744140625,
                "old_lm_score": -71.3837890625,
                "acoustic_score": -77.61297607421875,
                "combined_score": -199.0386962890625
              },
              {
                "candidate": "which i you as a gift and have been real handy",
                "llm_score": -245.24998474121094,
                "old_lm_score": -70.7158203125,
                "acoustic_score": -78.98319244384766,
                "combined_score": -197.4744987487793
              },
              {
                "candidate": "what i do as a priest and has been real hand",
                "llm_score": -240.82080078125,
                "old_lm_score": -59.017578125,
                "acoustic_score": -102.41004943847656,
                "combined_score": -201.12421417236328
              },
              {
                "candidate": "what i do as a ref and have been really handy",
                "llm_score": -238.10975646972656,
                "old_lm_score": -59.6787109375,
                "acoustic_score": -101.10948944091797,
                "combined_score": -199.44897842407227
              },
              {
                "candidate": "what i do as a gift and have been real hands",
                "llm_score": -238.44305419921875,
                "old_lm_score": -59.4306640625,
                "acoustic_score": -101.61216735839844,
                "combined_score": -199.7429428100586
              },
              {
                "candidate": "which i use as a weapon and have been real hand",
                "llm_score": -238.58621215820312,
                "old_lm_score": -60.388671875,
                "acoustic_score": -99.69801330566406,
                "combined_score": -199.3364486694336
              },
              {
                "candidate": "what i do as a weapon and has been real hand",
                "llm_score": -242.78843688964844,
                "old_lm_score": -59.2060546875,
                "acoustic_score": -102.09102630615234,
                "combined_score": -202.0427589416504
              }
            ],
            "selected": "what i do as a wife and have been real handy",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 2671.4910240000336
        }
      ],
      "total_time_ms": 2718.6543530000336
    },
    {
      "sentence_idx": 19,
      "ground_truth": "i know when i was working",
      "top1_hypothesis": "i do when i was working",
      "final_decoded": "i do when i was working",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.44811600002958585
    },
    {
      "sentence_idx": 20,
      "ground_truth": "it's a package deal",
      "top1_hypothesis": "it's a package deal",
      "final_decoded": "it's a package deal",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.17085900003621646
    },
    {
      "sentence_idx": 21,
      "ground_truth": "i have seen it",
      "top1_hypothesis": "i have seen it",
      "final_decoded": "i have seen it",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.12377699999888137
    },
    {
      "sentence_idx": 22,
      "ground_truth": "the measures already passed a senate committee",
      "top1_hypothesis": "the measure was passed a senate committee",
      "final_decoded": "the measure already passed a senate committee",
      "was_changed": true,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "measure",
          "confusion_candidates": [
            {
              "word": "measure",
              "weight": 0.41971993653631207
            },
            {
              "word": "measures",
              "weight": 0.4819588625669764
            },
            {
              "word": "measure's",
              "weight": 0.09670123535056052
            },
            {
              "word": "major",
              "weight": 6.570010019869974e-05
            },
            {
              "word": "are",
              "weight": 0.0015362026175140375
            },
            {
              "word": "mayor",
              "weight": 1.806282743829243e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.9528561119837037,
            "margin": 0.06223892603066433,
            "disagreement_mass": 0.5180411374330236
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "the (measure OR measures OR measure's OR major OR are OR mayor) was passed a senate committee",
            "retrieved_docs": [
              "The bill passed the committee by a voice vote.",
              "Measures were passed within the schools themselves.",
              "The measure passed the House by a voice vote.",
              "The measure now moves to the Senate floor for a vote.",
              "Social distancing measures are in place.",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it"
            ],
            "scores": [
              16.21011066902638,
              14.259804755596983,
              14.097836842883607,
              13.732886978489791,
              10.035191761109019,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 16.333024000005025
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "was",
          "confusion_candidates": [
            {
              "word": "was",
              "weight": 0.0008914127281514651
            },
            {
              "word": "already",
              "weight": 0.0037165442063530497
            },
            {
              "word": "always",
              "weight": 0.9930799628608389
            },
            {
              "word": "we",
              "weight": 0.00026871405135492376
            },
            {
              "word": "were",
              "weight": 1.595519002080158e-07
            },
            {
              "word": "way",
              "weight": 0.002039959678587618
            },
            {
              "word": "also",
              "weight": 1.6547956054691604e-10
            },
            {
              "word": "aa",
              "weight": 1.6001636028154671e-07
            },
            {
              "word": "orders",
              "weight": 3.0867399738842987e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.04884077938500264,
            "margin": 0.9893634186544858,
            "disagreement_mass": 0.006920037139161117
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "passed",
          "confusion_candidates": [
            {
              "word": "passed",
              "weight": 0.9784311626020081
            },
            {
              "word": "past",
              "weight": 0.0020399596785876184
            },
            {
              "word": "placed",
              "weight": 0.019528877718404128
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.11083468128169359,
            "margin": 0.958902284883604,
            "disagreement_mass": 0.02156883739799187
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "a",
          "confusion_candidates": [
            {
              "word": "a",
              "weight": 0.9999995326216478
            },
            {
              "word": "the",
              "weight": 4.673773520805101e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 7.279928758416384e-06,
            "margin": 0.9999990652442957,
            "disagreement_mass": 4.673783522424202e-07
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 7,
          "top1_word": "the measure was passed a senate committee",
          "confusion_candidates": [
            {
              "word": "the measure was passed a senate committee",
              "weight": -152.88522720336914
            },
            {
              "word": "the measure already passed a senate committee",
              "weight": -151.83886337280273
            },
            {
              "word": "the measures already passed a senate committee",
              "weight": -154.10473251342773
            },
            {
              "word": "the measures always passed a senate committee",
              "weight": -153.96746444702148
            },
            {
              "word": "the measure always passed a senate committee",
              "weight": -152.23380851745605
            },
            {
              "word": "the measures we passed a senate committee",
              "weight": -157.77338409423828
            },
            {
              "word": "the measure already passed the senate committee",
              "weight": -155.7455940246582
            },
            {
              "word": "the measure's always passed a senate committee",
              "weight": -157.05862045288086
            },
            {
              "word": "the measures were passed a senate committee",
              "weight": -158.67779159545898
            },
            {
              "word": "the measure we passed a senate committee",
              "weight": -157.06558990478516
            },
            {
              "word": "the measure was passed the senate committee",
              "weight": -158.59616470336914
            },
            {
              "word": "the measure way past a senate committee",
              "weight": -159.7562255859375
            },
            {
              "word": "the major always passed a senate committee",
              "weight": -162.88027572631836
            },
            {
              "word": "the measures always placed a senate committee",
              "weight": -160.68937301635742
            },
            {
              "word": "the measure also passed a senate committee",
              "weight": -159.83062362670898
            },
            {
              "word": "the measure always placed a senate committee",
              "weight": -158.96905136108398
            },
            {
              "word": "the measures are way past a senate committee",
              "weight": -160.49106979370117
            },
            {
              "word": "the measures way past a senate committee",
              "weight": -161.6017608642578
            },
            {
              "word": "the measure aa passed a senate committee",
              "weight": -163.1998519897461
            },
            {
              "word": "the mayor always passed a senate committee",
              "weight": -162.9563102722168
            },
            {
              "word": "the measure orders passed a senate committee",
              "weight": -161.34856414794922
            },
            {
              "word": "the measure's always placed a senate committee",
              "weight": -163.59570693969727
            },
            {
              "word": "the major always placed a senate committee",
              "weight": -167.97974014282227
            },
            {
              "word": "the mayor always placed a senate committee",
              "weight": -166.85076904296875
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "The bill passed the committee by a voice vote.",
              "Measures were passed within the schools themselves.",
              "The measure passed the House by a voice vote.",
              "The measure now moves to the Senate floor for a vote.",
              "Social distancing measures are in place.",
              "i don't know what you think about the point",
              "i believe it was about ten dollars",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it"
            ],
            "retrieval_time_ms": 16.333024000005025
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "the measure was passed a senate committee",
                "llm_score": -193.33340454101562,
                "old_lm_score": -32.4638671875,
                "acoustic_score": -79.97318267822266,
                "combined_score": -152.88522720336914
              },
              {
                "candidate": "the measure already passed a senate committee",
                "llm_score": -192.39453125,
                "old_lm_score": -35.595703125,
                "acoustic_score": -75.68749237060547,
                "combined_score": -151.83886337280273
              },
              {
                "candidate": "the measures already passed a senate committee",
                "llm_score": -195.7707977294922,
                "old_lm_score": -36.84375,
                "acoustic_score": -75.59491729736328,
                "combined_score": -154.10473251342773
              },
              {
                "candidate": "the measures always passed a senate committee",
                "llm_score": -201.7681121826172,
                "old_lm_score": -46.4580078125,
                "acoustic_score": -59.70880889892578,
                "combined_score": -153.96746444702148
              },
              {
                "candidate": "the measure always passed a senate committee",
                "llm_score": -198.15548706054688,
                "old_lm_score": -46.5107421875,
                "acoustic_score": -59.801387786865234,
                "combined_score": -152.23380851745605
              },
              {
                "candidate": "the measures we passed a senate committee",
                "llm_score": -201.73695373535156,
                "old_lm_score": -39.5654296875,
                "acoustic_score": -74.244384765625,
                "combined_score": -157.77338409423828
              },
              {
                "candidate": "the measure already passed the senate committee",
                "llm_score": -191.49215698242188,
                "old_lm_score": -33.8046875,
                "acoustic_score": -86.19434356689453,
                "combined_score": -155.7455940246582
              },
              {
                "candidate": "the measure's always passed a senate committee",
                "llm_score": -206.34690856933594,
                "old_lm_score": -48.0615234375,
                "acoustic_score": -59.70880889892578,
                "combined_score": -157.05862045288086
              },
              {
                "candidate": "the measures were passed a senate committee",
                "llm_score": -196.29034423828125,
                "old_lm_score": -35.328125,
                "acoustic_score": -85.73711395263672,
                "combined_score": -158.67779159545898
              },
              {
                "candidate": "the measure we passed a senate committee",
                "llm_score": -198.65847778320312,
                "old_lm_score": -41.1357421875,
                "acoustic_score": -74.33695983886719,
                "combined_score": -157.06558990478516
              },
              {
                "candidate": "the measure was passed the senate committee",
                "llm_score": -192.43690490722656,
                "old_lm_score": -34.275390625,
                "acoustic_score": -90.48003387451172,
                "combined_score": -158.59616470336914
              },
              {
                "candidate": "the measure way past a senate committee",
                "llm_score": -206.02587890625,
                "old_lm_score": -46.1376953125,
                "acoustic_score": -67.348876953125,
                "combined_score": -159.7562255859375
              },
              {
                "candidate": "the major always passed a senate committee",
                "llm_score": -210.69593811035156,
                "old_lm_score": -44.7275390625,
                "acoustic_score": -70.33707427978516,
                "combined_score": -162.88027572631836
              },
              {
                "candidate": "the measures always placed a senate committee",
                "llm_score": -211.30287170410156,
                "old_lm_score": -49.9482421875,
                "acoustic_score": -60.12763214111328,
                "combined_score": -160.68937301635742
              },
              {
                "candidate": "the measure also passed a senate committee",
                "llm_score": -191.7247314453125,
                "old_lm_score": -32.1865234375,
                "acoustic_score": -95.74999237060547,
                "combined_score": -159.83062362670898
              },
              {
                "candidate": "the measure always placed a senate committee",
                "llm_score": -207.7169189453125,
                "old_lm_score": -50.0009765625,
                "acoustic_score": -60.22020721435547,
                "combined_score": -158.96905136108398
              },
              {
                "candidate": "the measures are way past a senate committee",
                "llm_score": -209.08935546875,
                "old_lm_score": -48.40234375,
                "acoustic_score": -63.490440368652344,
                "combined_score": -160.49106979370117
              },
              {
                "candidate": "the measures way past a senate committee",
                "llm_score": -209.2294464111328,
                "old_lm_score": -46.7177734375,
                "acoustic_score": -67.25630187988281,
                "combined_score": -161.6017608642578
              },
              {
                "candidate": "the measure aa passed a senate committee",
                "llm_score": -205.33737182617188,
                "old_lm_score": -39.6298828125,
                "acoustic_score": -81.43244934082031,
                "combined_score": -163.1998519897461
              },
              {
                "candidate": "the mayor always passed a senate committee",
                "llm_score": -209.5567626953125,
                "old_lm_score": -44.3447265625,
                "acoustic_score": -72.0111312866211,
                "combined_score": -162.9563102722168
              },
              {
                "candidate": "the measure orders passed a senate committee",
                "llm_score": -204.59439086914062,
                "old_lm_score": -42.7392578125,
                "acoustic_score": -75.36347961425781,
                "combined_score": -161.34856414794922
              },
              {
                "candidate": "the measure's always placed a senate committee",
                "llm_score": -215.51202392578125,
                "old_lm_score": -51.5517578125,
                "acoustic_score": -60.12763214111328,
                "combined_score": -163.59570693969727
              },
              {
                "candidate": "the major always placed a senate committee",
                "llm_score": -216.98580932617188,
                "old_lm_score": -48.2177734375,
                "acoustic_score": -70.75589752197266,
                "combined_score": -167.97974014282227
              },
              {
                "candidate": "the mayor always placed a senate committee",
                "llm_score": -213.43663024902344,
                "old_lm_score": -47.8349609375,
                "acoustic_score": -72.42994689941406,
                "combined_score": -166.85076904296875
              }
            ],
            "selected": "the measure already passed a senate committee",
            "selected_index": 1,
            "changed_from_top1": true,
            "change_was_correct": true
          },
          "time_ms": 554.8565920000783
        }
      ],
      "total_time_ms": 572.9246500000045
    },
    {
      "sentence_idx": 23,
      "ground_truth": "they told me that this was a topic",
      "top1_hypothesis": "they told me that this was a topic",
      "final_decoded": "they told me that this was a topic",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.5702180000071166
    },
    {
      "sentence_idx": 24,
      "ground_truth": "in the red square or wherever said",
      "top1_hypothesis": "in the red square are weaver said",
      "final_decoded": "in the red square are weaver said",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "red",
          "confusion_candidates": [
            {
              "word": "red",
              "weight": 0.999998032132882
            },
            {
              "word": "ride",
              "weight": 1.967866117881905e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 2.7822791800500812e-05,
            "margin": 0.9999960642667641,
            "disagreement_mass": 1.967867118035649e-06
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "square",
          "confusion_candidates": [
            {
              "word": "square",
              "weight": 0.4477295133585098
            },
            {
              "word": "chair",
              "weight": 0.5284007471839344
            },
            {
              "word": "scare",
              "weight": 0.020388530200203085
            },
            {
              "word": "car",
              "weight": 0.00027983631264543937
            },
            {
              "word": "hair",
              "weight": 0.00022121316521746677
            },
            {
              "word": "sea",
              "weight": 6.99193477050969e-07
            },
            {
              "word": "squares",
              "weight": 4.271937469304669e-05
            },
            {
              "word": "cross",
              "weight": 5.413891124117523e-07
            },
            {
              "word": "chairs",
              "weight": 6.396470528090098e-05
            },
            {
              "word": "share",
              "weight": 1.9678661178819058e-06
            },
            {
              "word": "care",
              "weight": 0.001823433285588982
            },
            {
              "word": "cars",
              "weight": 4.810598905087639e-08
            },
            {
              "word": "star",
              "weight": 3.2613928310712153e-06
            },
            {
              "word": "sure",
              "weight": 0.000914950057193855
            },
            {
              "word": "tour",
              "weight": 8.40518246228855e-05
            },
            {
              "word": "pair",
              "weight": 4.4522583582672785e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.8006365412729183,
            "margin": 0.08067123382542457,
            "disagreement_mass": 0.47159925281606563
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "in the red (square OR chair OR scare OR car OR hair OR sea OR squares OR cross OR chairs OR share OR care OR cars OR star OR sure OR tour OR pair) are weaver said",
            "retrieved_docs": [
              "The red pills are a vitamin-and-iron compound.",
              "After harvest, the red peppers are usually dried.",
              "A lone star shone in the early evening sky.",
              "Tour sort of thing.",
              "Naturally curly hair runs in my family.",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic"
            ],
            "scores": [
              11.86148776556994,
              11.107450384232857,
              9.923075266292827,
              9.772136442366897,
              9.49090077141027,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 27.772968000022047
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "are",
          "confusion_candidates": [
            {
              "word": "are",
              "weight": 0.9198593946065853
            },
            {
              "word": "or",
              "weight": 0.041718588414497916
            },
            {
              "word": "r",
              "weight": 0.03490302089923987
            },
            {
              "word": "for",
              "weight": 3.127731275584108e-06
            },
            {
              "word": "ar",
              "weight": 0.0035158683474012424
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.3463838492127508,
            "margin": 0.8781408061920873,
            "disagreement_mass": 0.08014060539341472
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "weaver",
          "confusion_candidates": [
            {
              "word": "weaver",
              "weight": 0.9380364226356055
            },
            {
              "word": "ever",
              "weight": 0.027991647643658735
            },
            {
              "word": "whether",
              "weight": 0.013126575294620246
            },
            {
              "word": "weber",
              "weight": 0.0010594911502920582
            },
            {
              "word": "wheeler",
              "weight": 0.00024823067576294625
            },
            {
              "word": "wever",
              "weight": 0.015402076756463944
            },
            {
              "word": "weller",
              "weight": 0.002874248983928907
            },
            {
              "word": "webber",
              "weight": 0.0004750724650611915
            },
            {
              "word": "weather",
              "weight": 0.000661980249013472
            },
            {
              "word": "never",
              "weight": 2.63271069485361e-07
            },
            {
              "word": "either",
              "weight": 1.8353667372522804e-08
            },
            {
              "word": "over",
              "weight": 5.904961338238e-08
            },
            {
              "word": "waiver",
              "weight": 0.00010197502662539877
            },
            {
              "word": "webre",
              "weight": 2.193844361738487e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.31704965843646454,
            "margin": 0.9100447749919468,
            "disagreement_mass": 0.061963577364394506
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 7,
          "top1_word": "in the red square are weaver said",
          "confusion_candidates": [
            {
              "word": "in the red square are weaver said",
              "weight": -196.55205154418945
            },
            {
              "word": "in the red square are ever said",
              "weight": -196.82057189941406
            },
            {
              "word": "in the red chair or weaver said",
              "weight": -198.4917507171631
            },
            {
              "word": "in the red square or weaver said",
              "weight": -198.58853149414062
            },
            {
              "word": "in the red chair are weaver said",
              "weight": -198.02263641357422
            },
            {
              "word": "in the red chair or whether said",
              "weight": -198.60299491882324
            },
            {
              "word": "in the red chair are ever said",
              "weight": -198.06845474243164
            },
            {
              "word": "in the red square or whether said",
              "weight": -198.04166412353516
            },
            {
              "word": "in the red square are whether said",
              "weight": -197.24814987182617
            },
            {
              "word": "in the red scare or weaver said",
              "weight": -201.32262229919434
            },
            {
              "word": "in the red chair or ever said",
              "weight": -200.12541389465332
            },
            {
              "word": "in the red square or ever said",
              "weight": -199.81721115112305
            },
            {
              "word": "in the red chair are whether said",
              "weight": -198.94122314453125
            },
            {
              "word": "in the red scare are weaver said",
              "weight": -200.4631118774414
            },
            {
              "word": "in the red scare or whether said",
              "weight": -200.17130851745605
            },
            {
              "word": "in the red scare are ever said",
              "weight": -199.13542556762695
            },
            {
              "word": "in the red square are weber said",
              "weight": -201.73683547973633
            },
            {
              "word": "in the red chair r weaver said",
              "weight": -200.3612003326416
            },
            {
              "word": "in the red chair or weber said",
              "weight": -203.08212852478027
            },
            {
              "word": "in the red square are wheeler said",
              "weight": -201.30810928344727
            },
            {
              "word": "in the red square are wever said",
              "weight": -199.7079200744629
            },
            {
              "word": "in the red square or weber said",
              "weight": -203.22854614257812
            },
            {
              "word": "in the red car or whether said",
              "weight": -200.22503280639648
            },
            {
              "word": "in the red square are weller said",
              "weight": -200.6998634338379
            },
            {
              "word": "in the red hair are weaver said",
              "weight": -199.32675552368164
            },
            {
              "word": "in the red square are webber said",
              "weight": -202.05417251586914
            },
            {
              "word": "in the red hair are ever said",
              "weight": -199.315185546875
            },
            {
              "word": "in the red car or weaver said",
              "weight": -201.4060230255127
            },
            {
              "word": "in the red chair for weaver said",
              "weight": -203.57268905639648
            },
            {
              "word": "in the red chair or wheeler said",
              "weight": -203.08713340759277
            },
            {
              "word": "in the red chair or wever said",
              "weight": -202.5894069671631
            },
            {
              "word": "in the red chair are weber said",
              "weight": -203.08455657958984
            },
            {
              "word": "in the red scare or ever said",
              "weight": -201.55548286437988
            },
            {
              "word": "in the red car are weaver said",
              "weight": -200.25446319580078
            },
            {
              "word": "in the red chair or weller said",
              "weight": -202.5145778656006
            },
            {
              "word": "in the red square are weather said",
              "weight": -199.1575584411621
            },
            {
              "word": "in the red square or wheeler said",
              "weight": -202.7105712890625
            },
            {
              "word": "in the red square or wever said",
              "weight": -202.2067413330078
            },
            {
              "word": "in the red chair or webber said",
              "weight": -203.87592124938965
            },
            {
              "word": "in the red car are ever said",
              "weight": -199.88959121704102
            },
            {
              "word": "in the red square or weller said",
              "weight": -202.2559814453125
            },
            {
              "word": "in the red chair are wheeler said",
              "weight": -202.87296295166016
            },
            {
              "word": "in the red chair are wever said",
              "weight": -201.1192398071289
            },
            {
              "word": "in the red square for weaver said",
              "weight": -203.46077728271484
            },
            {
              "word": "in the red square or webber said",
              "weight": -204.08377075195312
            },
            {
              "word": "in the red hair or weaver said",
              "weight": -202.8718605041504
            },
            {
              "word": "in the red sea are weaver said",
              "weight": -202.5763168334961
            },
            {
              "word": "in the red squares are weaver said",
              "weight": -199.99902725219727
            },
            {
              "word": "in the red square are never said",
              "weight": -200.21774291992188
            },
            {
              "word": "in the red scare are whether said",
              "weight": -200.76364135742188
            },
            {
              "word": "in the red chair are weller said",
              "weight": -202.22441864013672
            },
            {
              "word": "in the red sea are ever said",
              "weight": -202.34503936767578
            },
            {
              "word": "in the red squares are ever said",
              "weight": -200.4573211669922
            },
            {
              "word": "in the red chair are webber said",
              "weight": -202.9481430053711
            },
            {
              "word": "in the red chair or weather said",
              "weight": -202.05474662780762
            },
            {
              "word": "in the red square r weaver said",
              "weight": -200.62652969360352
            },
            {
              "word": "in the red square are we ever said",
              "weight": -200.1106414794922
            },
            {
              "word": "in the red cross are weaver said",
              "weight": -203.53141021728516
            },
            {
              "word": "in the red scare or weber said",
              "weight": -205.67389488220215
            },
            {
              "word": "in the red square or weather said",
              "weight": -201.12218475341797
            },
            {
              "word": "in the red scare r weaver said",
              "weight": -201.40581703186035
            },
            {
              "word": "in the red cross are ever said",
              "weight": -203.59627151489258
            },
            {
              "word": "in the red chair r ever said",
              "weight": -201.4482021331787
            },
            {
              "word": "in the red hair or whether said",
              "weight": -201.09983444213867
            },
            {
              "word": "in the red chair ar weaver said",
              "weight": -203.7879581451416
            },
            {
              "word": "in the red chair are weather said",
              "weight": -200.87478637695312
            },
            {
              "word": "in the red square are either said",
              "weight": -201.72332382202148
            },
            {
              "word": "in the red chairs are weaver said",
              "weight": -201.51354217529297
            },
            {
              "word": "in the ride share or weaver said",
              "weight": -205.53720664978027
            },
            {
              "word": "in the red care are weaver said",
              "weight": -199.98148727416992
            },
            {
              "word": "in the red square are over said",
              "weight": -201.29888534545898
            },
            {
              "word": "in the red hair are whether said",
              "weight": -200.2204246520996
            },
            {
              "word": "in the red chair or waiver said",
              "weight": -202.5828456878662
            },
            {
              "word": "in the red cars are ever said",
              "weight": -202.04524612426758
            },
            {
              "word": "in the red chairs are ever said",
              "weight": -201.6737403869629
            },
            {
              "word": "in the red cross or weaver said",
              "weight": -204.98573684692383
            },
            {
              "word": "in the red square are waiver said",
              "weight": -201.6328182220459
            },
            {
              "word": "in the red care are ever said",
              "weight": -199.8205337524414
            },
            {
              "word": "in the red care or whether said",
              "weight": -200.7840576171875
            },
            {
              "word": "in the red star are weaver said",
              "weight": -202.367094039917
            },
            {
              "word": "in the red chair are never said",
              "weight": -201.8204689025879
            },
            {
              "word": "in the red chair r whether said",
              "weight": -202.99540901184082
            },
            {
              "word": "in the red square or waiver said",
              "weight": -202.26207160949707
            },
            {
              "word": "in the red square are webre said",
              "weight": -205.17920303344727
            },
            {
              "word": "in the red sea or weaver said",
              "weight": -204.7033576965332
            },
            {
              "word": "in the red star are ever said",
              "weight": -202.57686614990234
            },
            {
              "word": "in the red scare or wheeler said",
              "weight": -205.62918853759766
            },
            {
              "word": "in the red scare or wever said",
              "weight": -204.8452663421631
            },
            {
              "word": "in the red chair are we ever said",
              "weight": -201.40544509887695
            },
            {
              "word": "in the red car or ever said",
              "weight": -202.61439514160156
            },
            {
              "word": "in the red care or weaver said",
              "weight": -202.17873191833496
            },
            {
              "word": "in the ride share or whether said",
              "weight": -204.52490234375
            },
            {
              "word": "in the red scare are weber said",
              "weight": -205.54705047607422
            },
            {
              "word": "in the red scare or weller said",
              "weight": -204.5831813812256
            },
            {
              "word": "in the red sure are weaver said",
              "weight": -200.11380004882812
            },
            {
              "word": "in the red car are whether said",
              "weight": -200.99583435058594
            },
            {
              "word": "in the red cross or whether said",
              "weight": -204.50694274902344
            },
            {
              "word": "in the red tour are weaver said",
              "weight": -202.33580780029297
            },
            {
              "word": "in the red scare or webber said",
              "weight": -206.16312217712402
            },
            {
              "word": "in the red pair are weaver said",
              "weight": -201.39087677001953
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "The red pills are a vitamin-and-iron compound.",
              "After harvest, the red peppers are usually dried.",
              "A lone star shone in the early evening sky.",
              "Tour sort of thing.",
              "Naturally curly hair runs in my family.",
              "what in the world drugs are you on to",
              "android tv box",
              "a couple of times",
              "i had the back down on it",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic"
            ],
            "retrieval_time_ms": 27.772968000022047
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "in the red square are weaver said",
                "llm_score": -294.9585266113281,
                "old_lm_score": -47.16796875,
                "acoustic_score": -50.97760772705078,
                "combined_score": -196.55205154418945
              },
              {
                "candidate": "in the red square are ever said",
                "llm_score": -292.04449462890625,
                "old_lm_score": -44.0830078125,
                "acoustic_score": -57.513641357421875,
                "combined_score": -196.82057189941406
              },
              {
                "candidate": "in the red chair or weaver said",
                "llm_score": -296.2314758300781,
                "old_lm_score": -45.919921875,
                "acoustic_score": -54.83210372924805,
                "combined_score": -198.4917507171631
              },
              {
                "candidate": "in the red square or weaver said",
                "llm_score": -294.9383544921875,
                "old_lm_score": -44.9501953125,
                "acoustic_score": -57.28851318359375,
                "combined_score": -198.58853149414062
              },
              {
                "candidate": "in the red chair are weaver said",
                "llm_score": -297.9469299316406,
                "old_lm_score": -49.5771484375,
                "acoustic_score": -48.52119445800781,
                "combined_score": -198.02263641357422
              },
              {
                "candidate": "in the red chair or whether said",
                "llm_score": -293.53436279296875,
                "old_lm_score": -44.283203125,
                "acoustic_score": -59.388423919677734,
                "combined_score": -198.60299491882324
              },
              {
                "candidate": "in the red chair are ever said",
                "llm_score": -294.5874938964844,
                "old_lm_score": -46.4921875,
                "acoustic_score": -55.057228088378906,
                "combined_score": -198.06845474243164
              },
              {
                "candidate": "in the red square or whether said",
                "llm_score": -290.9250183105469,
                "old_lm_score": -43.3134765625,
                "acoustic_score": -61.84483337402344,
                "combined_score": -198.04166412353516
              },
              {
                "candidate": "in the red square are whether said",
                "llm_score": -291.9789733886719,
                "old_lm_score": -46.9833984375,
                "acoustic_score": -55.53392791748047,
                "combined_score": -197.24814987182617
              },
              {
                "candidate": "in the red scare or weaver said",
                "llm_score": -298.746337890625,
                "old_lm_score": -46.8330078125,
                "acoustic_score": -57.06589889526367,
                "combined_score": -201.32262229919434
              },
              {
                "candidate": "in the red chair or ever said",
                "llm_score": -294.0662841796875,
                "old_lm_score": -44.81640625,
                "acoustic_score": -61.36813735961914,
                "combined_score": -200.12541389465332
              },
              {
                "candidate": "in the red square or ever said",
                "llm_score": -291.96319580078125,
                "old_lm_score": -43.8466796875,
                "acoustic_score": -63.824546813964844,
                "combined_score": -199.81721115112305
              },
              {
                "candidate": "in the red chair are whether said",
                "llm_score": -295.412353515625,
                "old_lm_score": -49.392578125,
                "acoustic_score": -53.0775146484375,
                "combined_score": -198.94122314453125
              },
              {
                "candidate": "in the red scare are weaver said",
                "llm_score": -299.5960388183594,
                "old_lm_score": -50.5751953125,
                "acoustic_score": -50.75498962402344,
                "combined_score": -200.4631118774414
              },
              {
                "candidate": "in the red scare or whether said",
                "llm_score": -293.52410888671875,
                "old_lm_score": -45.1962890625,
                "acoustic_score": -61.62221908569336,
                "combined_score": -200.17130851745605
              },
              {
                "candidate": "in the red scare are ever said",
                "llm_score": -293.4895935058594,
                "old_lm_score": -47.490234375,
                "acoustic_score": -57.29102325439453,
                "combined_score": -199.13542556762695
              },
              {
                "candidate": "in the red square are weber said",
                "llm_score": -298.55926513671875,
                "old_lm_score": -47.634765625,
                "acoustic_score": -57.279640197753906,
                "combined_score": -201.73683547973633
              },
              {
                "candidate": "in the red chair r weaver said",
                "llm_score": -300.0195617675781,
                "old_lm_score": -52.181640625,
                "acoustic_score": -48.52119827270508,
                "combined_score": -200.3612003326416
              },
              {
                "candidate": "in the red chair or weber said",
                "llm_score": -299.1521911621094,
                "old_lm_score": -45.8779296875,
                "acoustic_score": -61.13413619995117,
                "combined_score": -203.08212852478027
              },
              {
                "candidate": "in the red square are wheeler said",
                "llm_score": -296.2978210449219,
                "old_lm_score": -47.080078125,
                "acoustic_score": -59.238319396972656,
                "combined_score": -201.30810928344727
              },
              {
                "candidate": "in the red square are wever said",
                "llm_score": -297.225341796875,
                "old_lm_score": -51.212890625,
                "acoustic_score": -50.97760772705078,
                "combined_score": -199.7079200744629
              },
              {
                "candidate": "in the red square or weber said",
                "llm_score": -297.9583435058594,
                "old_lm_score": -44.908203125,
                "acoustic_score": -63.590545654296875,
                "combined_score": -203.22854614257812
              },
              {
                "candidate": "in the red car or whether said",
                "llm_score": -290.21942138671875,
                "old_lm_score": -43.369140625,
                "acoustic_score": -66.86150360107422,
                "combined_score": -200.22503280639648
              },
              {
                "candidate": "in the red square are weller said",
                "llm_score": -297.530517578125,
                "old_lm_score": -49.8740234375,
                "acoustic_score": -53.99518585205078,
                "combined_score": -200.6998634338379
              },
              {
                "candidate": "in the red hair are weaver said",
                "llm_score": -292.92388916015625,
                "old_lm_score": -48.03515625,
                "acoustic_score": -57.69446563720703,
                "combined_score": -199.32675552368164
              },
              {
                "candidate": "in the red square are webber said",
                "llm_score": -298.4390563964844,
                "old_lm_score": -48.3896484375,
                "acoustic_score": -57.279640197753906,
                "combined_score": -202.05417251586914
              },
              {
                "candidate": "in the red hair are ever said",
                "llm_score": -289.4496765136719,
                "old_lm_score": -44.9501953125,
                "acoustic_score": -64.23049926757812,
                "combined_score": -199.315185546875
              },
              {
                "candidate": "in the red car or weaver said",
                "llm_score": -294.3740539550781,
                "old_lm_score": -46.1328125,
                "acoustic_score": -62.305179595947266,
                "combined_score": -201.4060230255127
              },
              {
                "candidate": "in the red chair for weaver said",
                "llm_score": -297.0613098144531,
                "old_lm_score": -44.6142578125,
                "acoustic_score": -65.46981048583984,
                "combined_score": -203.57268905639648
              },
              {
                "candidate": "in the red chair or wheeler said",
                "llm_score": -297.2494201660156,
                "old_lm_score": -45.83203125,
                "acoustic_score": -63.09281539916992,
                "combined_score": -203.08713340759277
              },
              {
                "candidate": "in the red chair or wever said",
                "llm_score": -300.3818664550781,
                "old_lm_score": -49.96484375,
                "acoustic_score": -54.83210372924805,
                "combined_score": -202.5894069671631
              },
              {
                "candidate": "in the red chair are weber said",
                "llm_score": -301.30194091796875,
                "old_lm_score": -50.0439453125,
                "acoustic_score": -54.82322692871094,
                "combined_score": -203.08455657958984
              },
              {
                "candidate": "in the red scare or ever said",
                "llm_score": -293.779541015625,
                "old_lm_score": -45.7294921875,
                "acoustic_score": -63.601932525634766,
                "combined_score": -201.55548286437988
              },
              {
                "candidate": "in the red car are weaver said",
                "llm_score": -294.96875,
                "old_lm_score": -49.5458984375,
                "acoustic_score": -55.99427795410156,
                "combined_score": -200.25446319580078
              },
              {
                "candidate": "in the red chair or weller said",
                "llm_score": -298.5534973144531,
                "old_lm_score": -48.6259765625,
                "acoustic_score": -57.84968185424805,
                "combined_score": -202.5145778656006
              },
              {
                "candidate": "in the red square are weather said",
                "llm_score": -292.97845458984375,
                "old_lm_score": -49.802734375,
                "acoustic_score": -55.53392791748047,
                "combined_score": -199.1575584411621
              },
              {
                "candidate": "in the red square or wheeler said",
                "llm_score": -295.0096130371094,
                "old_lm_score": -44.8623046875,
                "acoustic_score": -65.54922485351562,
                "combined_score": -202.7105712890625
              },
              {
                "candidate": "in the red square or wever said",
                "llm_score": -298.1298522949219,
                "old_lm_score": -48.9951171875,
                "acoustic_score": -57.28851318359375,
                "combined_score": -202.2067413330078
              },
              {
                "candidate": "in the red chair or webber said",
                "llm_score": -299.4761047363281,
                "old_lm_score": -47.1416015625,
                "acoustic_score": -61.13413619995117,
                "combined_score": -203.87592124938965
              },
              {
                "candidate": "in the red car are ever said",
                "llm_score": -290.7879333496094,
                "old_lm_score": -46.4609375,
                "acoustic_score": -62.530311584472656,
                "combined_score": -199.88959121704102
              },
              {
                "candidate": "in the red square or weller said",
                "llm_score": -296.54962158203125,
                "old_lm_score": -47.65625,
                "acoustic_score": -60.30609130859375,
                "combined_score": -202.2559814453125
              },
              {
                "candidate": "in the red chair are wheeler said",
                "llm_score": -299.4747619628906,
                "old_lm_score": -49.4892578125,
                "acoustic_score": -56.78190612792969,
                "combined_score": -202.87296295166016
              },
              {
                "candidate": "in the red chair are wever said",
                "llm_score": -300.09521484375,
                "old_lm_score": -53.6220703125,
                "acoustic_score": -48.52119445800781,
                "combined_score": -201.1192398071289
              },
              {
                "candidate": "in the red square for weaver said",
                "llm_score": -295.0402526855469,
                "old_lm_score": -43.955078125,
                "acoustic_score": -67.92622375488281,
                "combined_score": -203.46077728271484
              },
              {
                "candidate": "in the red square or webber said",
                "llm_score": -298.4051208496094,
                "old_lm_score": -46.171875,
                "acoustic_score": -63.590545654296875,
                "combined_score": -204.08377075195312
              },
              {
                "candidate": "in the red hair or weaver said",
                "llm_score": -295.76861572265625,
                "old_lm_score": -45.9697265625,
                "acoustic_score": -64.00537872314453,
                "combined_score": -202.8718605041504
              },
              {
                "candidate": "in the red sea are weaver said",
                "llm_score": -293.6818542480469,
                "old_lm_score": -44.53125,
                "acoustic_score": -66.93952941894531,
                "combined_score": -202.5763168334961
              },
              {
                "candidate": "in the red squares are weaver said",
                "llm_score": -292.6504821777344,
                "old_lm_score": -48.6767578125,
                "acoustic_score": -58.670814514160156,
                "combined_score": -199.99902725219727
              },
              {
                "candidate": "in the red square are never said",
                "llm_score": -287.3128662109375,
                "old_lm_score": -42.9619140625,
                "acoustic_score": -70.16070556640625,
                "combined_score": -200.21774291992188
              },
              {
                "candidate": "in the red scare are whether said",
                "llm_score": -295.8253479003906,
                "old_lm_score": -50.390625,
                "acoustic_score": -55.311309814453125,
                "combined_score": -200.76364135742188
              },
              {
                "candidate": "in the red chair are weller said",
                "llm_score": -300.6268615722656,
                "old_lm_score": -52.283203125,
                "acoustic_score": -51.53877258300781,
                "combined_score": -202.22441864013672
              },
              {
                "candidate": "in the red sea are ever said",
                "llm_score": -289.7682189941406,
                "old_lm_score": -41.4462890625,
                "acoustic_score": -73.47557067871094,
                "combined_score": -202.34503936767578
              },
              {
                "candidate": "in the red squares are ever said",
                "llm_score": -290.1159973144531,
                "old_lm_score": -45.591796875,
                "acoustic_score": -65.20684814453125,
                "combined_score": -200.4573211669922
              },
              {
                "candidate": "in the red chair are webber said",
                "llm_score": -300.27423095703125,
                "old_lm_score": -50.798828125,
                "acoustic_score": -54.82322692871094,
                "combined_score": -202.9481430053711
              },
              {
                "candidate": "in the red chair or weather said",
                "llm_score": -296.1810302734375,
                "old_lm_score": -48.5400390625,
                "acoustic_score": -59.388423919677734,
                "combined_score": -202.05474662780762
              },
              {
                "candidate": "in the red square r weaver said",
                "llm_score": -297.51177978515625,
                "old_lm_score": -52.763671875,
                "acoustic_score": -50.97760772705078,
                "combined_score": -200.62652969360352
              },
              {
                "candidate": "in the red square are we ever said",
                "llm_score": -294.4241943359375,
                "old_lm_score": -50.7314453125,
                "acoustic_score": -55.065643310546875,
                "combined_score": -200.1106414794922
              },
              {
                "candidate": "in the red cross are weaver said",
                "llm_score": -295.3236999511719,
                "old_lm_score": -45.0927734375,
                "acoustic_score": -66.64634704589844,
                "combined_score": -203.53141021728516
              },
              {
                "candidate": "in the red scare or weber said",
                "llm_score": -301.1888427734375,
                "old_lm_score": -46.791015625,
                "acoustic_score": -63.3679313659668,
                "combined_score": -205.67389488220215
              },
              {
                "candidate": "in the red square or weather said",
                "llm_score": -292.8292236328125,
                "old_lm_score": -47.5703125,
                "acoustic_score": -61.84483337402344,
                "combined_score": -201.12218475341797
              },
              {
                "candidate": "in the red scare r weaver said",
                "llm_score": -298.837890625,
                "old_lm_score": -53.21875,
                "acoustic_score": -50.7549934387207,
                "combined_score": -201.40581703186035
              },
              {
                "candidate": "in the red cross are ever said",
                "llm_score": -292.0023498535156,
                "old_lm_score": -42.0078125,
                "acoustic_score": -73.18238067626953,
                "combined_score": -203.59627151489258
              },
              {
                "candidate": "in the red chair r ever said",
                "llm_score": -296.76104736328125,
                "old_lm_score": -51.078125,
                "acoustic_score": -55.05723190307617,
                "combined_score": -201.4482021331787
              },
              {
                "candidate": "in the red hair or whether said",
                "llm_score": -289.3049621582031,
                "old_lm_score": -44.3330078125,
                "acoustic_score": -68.56169891357422,
                "combined_score": -201.09983444213867
              },
              {
                "candidate": "in the red chair ar weaver said",
                "llm_score": -304.6699523925781,
                "old_lm_score": -54.384765625,
                "acoustic_score": -48.52119827270508,
                "combined_score": -203.7879581451416
              },
              {
                "candidate": "in the red chair are weather said",
                "llm_score": -296.46014404296875,
                "old_lm_score": -52.2119140625,
                "acoustic_score": -53.0775146484375,
                "combined_score": -200.87478637695312
              },
              {
                "candidate": "in the red square are either said",
                "llm_score": -288.3777160644531,
                "old_lm_score": -42.5126953125,
                "acoustic_score": -72.55623626708984,
                "combined_score": -201.72332382202148
              },
              {
                "candidate": "in the red chairs are weaver said",
                "llm_score": -296.08319091796875,
                "old_lm_score": -50.7294921875,
                "acoustic_score": -56.21440124511719,
                "combined_score": -201.51354217529297
              },
              {
                "candidate": "in the ride share or weaver said",
                "llm_score": -300.6278076171875,
                "old_lm_score": -47.3203125,
                "acoustic_score": -63.12629318237305,
                "combined_score": -205.53720664978027
              },
              {
                "candidate": "in the red care are weaver said",
                "llm_score": -296.3428649902344,
                "old_lm_score": -54.2373046875,
                "acoustic_score": -49.38280487060547,
                "combined_score": -199.98148727416992
              },
              {
                "candidate": "in the red square are over said",
                "llm_score": -288.6973876953125,
                "old_lm_score": -43.9970703125,
                "acoustic_score": -69.90331268310547,
                "combined_score": -201.29888534545898
              },
              {
                "candidate": "in the red hair are whether said",
                "llm_score": -290.3394775390625,
                "old_lm_score": -47.8505859375,
                "acoustic_score": -62.25078582763672,
                "combined_score": -200.2204246520996
              },
              {
                "candidate": "in the red chair or waiver said",
                "llm_score": -296.7293395996094,
                "old_lm_score": -49.54296875,
                "acoustic_score": -58.89338302612305,
                "combined_score": -202.5828456878662
              },
              {
                "candidate": "in the red cars are ever said",
                "llm_score": -289.9851379394531,
                "old_lm_score": -43.8818359375,
                "acoustic_score": -70.22351837158203,
                "combined_score": -202.04524612426758
              },
              {
                "candidate": "in the red chairs are ever said",
                "llm_score": -292.9525146484375,
                "old_lm_score": -47.64453125,
                "acoustic_score": -62.75043487548828,
                "combined_score": -201.6737403869629
              },
              {
                "candidate": "in the red cross or weaver said",
                "llm_score": -294.46246337890625,
                "old_lm_score": -42.5517578125,
                "acoustic_score": -72.9572525024414,
                "combined_score": -204.98573684692383
              },
              {
                "candidate": "in the red square are waiver said",
                "llm_score": -296.63592529296875,
                "old_lm_score": -51.5908203125,
                "acoustic_score": -55.03889083862305,
                "combined_score": -201.6328182220459
              },
              {
                "candidate": "in the red care are ever said",
                "llm_score": -292.56988525390625,
                "old_lm_score": -51.15234375,
                "acoustic_score": -55.91883850097656,
                "combined_score": -199.8205337524414
              },
              {
                "candidate": "in the red care or whether said",
                "llm_score": -292.2839050292969,
                "old_lm_score": -49.0341796875,
                "acoustic_score": -60.250030517578125,
                "combined_score": -200.7840576171875
              },
              {
                "candidate": "in the red star are weaver said",
                "llm_score": -294.8141174316406,
                "old_lm_score": -48.43359375,
                "acoustic_score": -61.48647689819336,
                "combined_score": -202.367094039917
              },
              {
                "candidate": "in the red chair are never said",
                "llm_score": -290.5655517578125,
                "old_lm_score": -45.37109375,
                "acoustic_score": -67.70429229736328,
                "combined_score": -201.8204689025879
              },
              {
                "candidate": "in the red chair r whether said",
                "llm_score": -300.2189636230469,
                "old_lm_score": -52.6943359375,
                "acoustic_score": -53.077518463134766,
                "combined_score": -202.99540901184082
              },
              {
                "candidate": "in the red square or waiver said",
                "llm_score": -294.6011047363281,
                "old_lm_score": -48.5732421875,
                "acoustic_score": -61.349796295166016,
                "combined_score": -202.26207160949707
              },
              {
                "candidate": "in the red square are webre said",
                "llm_score": -302.3756408691406,
                "old_lm_score": -50.703125,
                "acoustic_score": -57.279640197753906,
                "combined_score": -205.17920303344727
              },
              {
                "candidate": "in the red sea or weaver said",
                "llm_score": -293.4375305175781,
                "old_lm_score": -42.71875,
                "acoustic_score": -73.25043487548828,
                "combined_score": -204.7033576965332
              },
              {
                "candidate": "in the red star are ever said",
                "llm_score": -291.7825927734375,
                "old_lm_score": -45.3486328125,
                "acoustic_score": -68.02250671386719,
                "combined_score": -202.57686614990234
              },
              {
                "candidate": "in the red scare or wheeler said",
                "llm_score": -299.1866455078125,
                "old_lm_score": -46.7451171875,
                "acoustic_score": -65.32661437988281,
                "combined_score": -205.62918853759766
              },
              {
                "candidate": "in the red scare or wever said",
                "llm_score": -301.7467041015625,
                "old_lm_score": -50.8779296875,
                "acoustic_score": -57.06589889526367,
                "combined_score": -204.8452663421631
              },
              {
                "candidate": "in the red chair are we ever said",
                "llm_score": -297.06103515625,
                "old_lm_score": -53.140625,
                "acoustic_score": -52.609230041503906,
                "combined_score": -201.40544509887695
              },
              {
                "candidate": "in the red car or ever said",
                "llm_score": -291.3582763671875,
                "old_lm_score": -45.029296875,
                "acoustic_score": -68.84121704101562,
                "combined_score": -202.61439514160156
              },
              {
                "candidate": "in the red care or weaver said",
                "llm_score": -297.01141357421875,
                "old_lm_score": -51.65234375,
                "acoustic_score": -55.69370651245117,
                "combined_score": -202.17873191833496
              },
              {
                "candidate": "in the ride share or whether said",
                "llm_score": -295.68359375,
                "old_lm_score": -45.68359375,
                "acoustic_score": -67.6826171875,
                "combined_score": -204.52490234375
              },
              {
                "candidate": "in the red scare are weber said",
                "llm_score": -302.9950866699219,
                "old_lm_score": -51.0419921875,
                "acoustic_score": -57.05702209472656,
                "combined_score": -205.54705047607422
              },
              {
                "candidate": "in the red scare or weller said",
                "llm_score": -299.5438232421875,
                "old_lm_score": -49.5390625,
                "acoustic_score": -60.08347702026367,
                "combined_score": -204.5831813812256
              },
              {
                "candidate": "in the red sure are weaver said",
                "llm_score": -295.9754638671875,
                "old_lm_score": -54.998046875,
                "acoustic_score": -49.25408935546875,
                "combined_score": -200.11380004882812
              },
              {
                "candidate": "in the red car are whether said",
                "llm_score": -292.0797424316406,
                "old_lm_score": -49.361328125,
                "acoustic_score": -60.55059814453125,
                "combined_score": -200.99583435058594
              },
              {
                "candidate": "in the red cross or whether said",
                "llm_score": -290.58526611328125,
                "old_lm_score": -40.9150390625,
                "acoustic_score": -77.51358032226562,
                "combined_score": -204.50694274902344
              },
              {
                "candidate": "in the red tour are weaver said",
                "llm_score": -298.03204345703125,
                "old_lm_score": -52.7578125,
                "acoustic_score": -53.88175964355469,
                "combined_score": -202.33580780029297
              },
              {
                "candidate": "in the red scare or webber said",
                "llm_score": -300.90362548828125,
                "old_lm_score": -48.0546875,
                "acoustic_score": -63.3679313659668,
                "combined_score": -206.16312217712402
              },
              {
                "candidate": "in the red pair are weaver said",
                "llm_score": -295.5067443847656,
                "old_lm_score": -52.271484375,
                "acoustic_score": -55.00352478027344,
                "combined_score": -201.39087677001953
              }
            ],
            "selected": "in the red square are weaver said",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 2244.5220910000216
        }
      ],
      "total_time_ms": 2278.629142
    },
    {
      "sentence_idx": 25,
      "ground_truth": "they did a lot of play work and stuff",
      "top1_hypothesis": "they did a lot of paper work and stuff",
      "final_decoded": "they did a lot of paper work and stuff",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 1.8269360000431334
    },
    {
      "sentence_idx": 26,
      "ground_truth": "you can gain too much weight",
      "top1_hypothesis": "you can gain too much weight",
      "final_decoded": "you can gain too much weight",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "gain",
          "confusion_candidates": [
            {
              "word": "gain",
              "weight": 0.8500972920400007
            },
            {
              "word": "gained",
              "weight": 0.0005037823820236825
            },
            {
              "word": "can",
              "weight": 0.14939892557697562
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.425912564296728,
            "margin": 0.7006983664630251,
            "disagreement_mass": 0.14990270795999927
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "too",
          "confusion_candidates": [
            {
              "word": "too",
              "weight": 0.9885399565731542
            },
            {
              "word": "to",
              "weight": 0.01146004342584585
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0626077842989545,
            "margin": 0.9770799131473084,
            "disagreement_mass": 0.011460043426845812
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "weight",
          "confusion_candidates": [
            {
              "word": "weight",
              "weight": 0.6188052828057267
            },
            {
              "word": "right",
              "weight": 0.3798198090597822
            },
            {
              "word": "white",
              "weight": 0.00137490813349105
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.6737521488279737,
            "margin": 0.23898547374594448,
            "disagreement_mass": 0.38119471719427334
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "you can gain too much (weight OR right OR white)",
            "retrieved_docs": [
              "Too much curiosity can get you into trouble.",
              "It's just so much weight lifting.",
              "It's too much trouble.",
              "That's too much trouble.",
              "I live right near White Rock Lake.",
              "a couple of times",
              "i had the back down on it",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff"
            ],
            "scores": [
              13.828973005623627,
              11.905544088639674,
              11.08748483417968,
              11.08748483417968,
              10.83442055766153,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 11.380585999972936
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 6,
          "top1_word": "you can gain too much weight",
          "confusion_candidates": [
            {
              "word": "you can gain too much weight",
              "weight": -126.49186325073242
            },
            {
              "word": "you can gain too much right",
              "weight": -131.25776481628418
            },
            {
              "word": "you can gained too much weight",
              "weight": -132.94367599487305
            },
            {
              "word": "you can can too much right",
              "weight": -132.18163776397705
            },
            {
              "word": "you can gain to much right",
              "weight": -135.19145011901855
            },
            {
              "word": "you can gain too much white",
              "weight": -134.6986198425293
            },
            {
              "word": "you can can too much weight",
              "weight": -132.45911026000977
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "Too much curiosity can get you into trouble.",
              "It's just so much weight lifting.",
              "It's too much trouble.",
              "That's too much trouble.",
              "I live right near White Rock Lake.",
              "a couple of times",
              "i had the back down on it",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff"
            ],
            "retrieval_time_ms": 11.380585999972936
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "you can gain too much weight",
                "llm_score": -183.47994995117188,
                "old_lm_score": -28.3173828125,
                "acoustic_score": -41.18639373779297,
                "combined_score": -126.49186325073242
              },
              {
                "candidate": "you can gain too much right",
                "llm_score": -191.9951171875,
                "old_lm_score": -36.6181640625,
                "acoustic_score": -33.90224838256836,
                "combined_score": -131.25776481628418
              },
              {
                "candidate": "you can gained too much weight",
                "llm_score": -189.27664184570312,
                "old_lm_score": -35.609375,
                "acoustic_score": -41.00133514404297,
                "combined_score": -132.94367599487305
              },
              {
                "candidate": "you can can too much right",
                "llm_score": -193.4211883544922,
                "old_lm_score": -42.00390625,
                "acoustic_score": -28.938180923461914,
                "combined_score": -132.18163776397705
              },
              {
                "candidate": "you can gain to much right",
                "llm_score": -196.89666748046875,
                "old_lm_score": -39.583984375,
                "acoustic_score": -33.90224838256836,
                "combined_score": -135.19145011901855
              },
              {
                "candidate": "you can gain too much white",
                "llm_score": -193.79052734375,
                "old_lm_score": -37.5,
                "acoustic_score": -38.106712341308594,
                "combined_score": -134.6986198425293
              },
              {
                "candidate": "you can can too much weight",
                "llm_score": -190.24179077148438,
                "old_lm_score": -38.4541015625,
                "acoustic_score": -36.222328186035156,
                "combined_score": -132.45911026000977
              }
            ],
            "selected": "you can gain too much weight",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 161.771243999965
        }
      ],
      "total_time_ms": 173.88649999998051
    },
    {
      "sentence_idx": 27,
      "ground_truth": "recent legislation",
      "top1_hypothesis": "recent legislation",
      "final_decoded": "recent legislation",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.20900900005926815
    },
    {
      "sentence_idx": 28,
      "ground_truth": "i'm a car buff too",
      "top1_hypothesis": "i'm a car buff to",
      "final_decoded": "i'm a car buff to",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "i'm",
          "confusion_candidates": [
            {
              "word": "i'm",
              "weight": 0.9999959683732288
            },
            {
              "word": "am",
              "weight": 4.031625771089247e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 5.410981451128496e-05,
            "margin": 0.9999919367474577,
            "disagreement_mass": 4.031626771205943e-06
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "car",
          "confusion_candidates": [
            {
              "word": "car",
              "weight": 0.9999977795422637
            },
            {
              "word": "score",
              "weight": 1.478111954297639e-09
            },
            {
              "word": "star",
              "weight": 2.072869942956222e-06
            },
            {
              "word": "core",
              "weight": 3.947974650099291e-09
            },
            {
              "word": "are",
              "weight": 1.4210452200777084e-07
            },
            {
              "word": "r",
              "weight": 5.618480086287016e-11
            }
          ],
          "uncertainty_metrics": {
            "entropy": 3.169551344673973e-05,
            "margin": 0.9999957066723207,
            "disagreement_mass": 2.2204577363460487e-06
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "buff",
          "confusion_candidates": [
            {
              "word": "buff",
              "weight": 0.9960784108036945
            },
            {
              "word": "both",
              "weight": 0.0037771880756983394
            },
            {
              "word": "by",
              "weight": 4.280204365066076e-06
            },
            {
              "word": "but",
              "weight": 1.4346512543205231e-05
            },
            {
              "word": "if",
              "weight": 1.0527925391513585e-06
            },
            {
              "word": "of",
              "weight": 5.49070329287625e-07
            },
            {
              "word": "buffs",
              "weight": 0.00011978679483990599
            },
            {
              "word": "up",
              "weight": 3.7313878385298526e-08
            },
            {
              "word": "a",
              "weight": 2.1878778163413856e-07
            },
            {
              "word": "off",
              "weight": 1.6884007567647739e-07
            },
            {
              "word": "the",
              "weight": 2.0540128669597324e-08
            },
            {
              "word": "buffer",
              "weight": 3.94026312592554e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.026358955487094476,
            "margin": 0.9923012227279961,
            "disagreement_mass": 0.003921589196305475
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "to",
          "confusion_candidates": [
            {
              "word": "to",
              "weight": 0.6076803431282674
            },
            {
              "word": "too",
              "weight": 0.21865352239363953
            },
            {
              "word": "you",
              "weight": 0.08004470119520046
            },
            {
              "word": "u",
              "weight": 0.07707339577089624
            },
            {
              "word": "do",
              "weight": 0.008895544058082957
            },
            {
              "word": "two",
              "weight": 0.005456820961585893
            },
            {
              "word": "view",
              "weight": 0.001078305287599631
            },
            {
              "word": "due",
              "weight": 0.0008600181143242326
            },
            {
              "word": "who",
              "weight": 6.21801649875086e-06
            },
            {
              "word": "few",
              "weight": 0.00024544814910248475
            },
            {
              "word": "true",
              "weight": 5.6829238024103315e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.1208292626420377,
            "margin": 0.3890268207346278,
            "disagreement_mass": 0.39231965687173265
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "i'm a car buff (to OR too OR you OR u OR do OR two OR view OR due OR who OR few OR true)",
            "retrieved_docs": [
              "Who told you to do it?",
              "How do you view this whole subject?",
              "Who do you work for?",
              "True to life.",
              "I don't think I'm a real true believer.",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation"
            ],
            "scores": [
              12.279641471395593,
              12.043588774100527,
              11.377051334599432,
              11.294097727052696,
              10.978965479573294,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 24.659966000058375
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 5,
          "top1_word": "i'm a car buff to",
          "confusion_candidates": [
            {
              "word": "i'm a car buff to",
              "weight": -122.43515586853027
            },
            {
              "word": "i'm a car buff too",
              "weight": -123.14090538024902
            },
            {
              "word": "i'm a car buff you",
              "weight": -123.85959053039551
            },
            {
              "word": "i'm a car buff u",
              "weight": -124.52336311340332
            },
            {
              "word": "i'm a car both u",
              "weight": -128.03145599365234
            },
            {
              "word": "i'm a car buff do",
              "weight": -125.83684635162354
            },
            {
              "word": "i'm a car by u",
              "weight": -130.46812057495117
            },
            {
              "word": "i'm a car both to",
              "weight": -127.00104236602783
            },
            {
              "word": "i'm a car buff two",
              "weight": -126.84232139587402
            },
            {
              "word": "i'm a car but u",
              "weight": -129.18836402893066
            },
            {
              "word": "i'm a car if you",
              "weight": -127.12652969360352
            },
            {
              "word": "i'm a car but you",
              "weight": -127.56772804260254
            },
            {
              "word": "i'm a car both you",
              "weight": -127.7609634399414
            },
            {
              "word": "i'm a score of to",
              "weight": -132.39437103271484
            },
            {
              "word": "i'm a car buff view",
              "weight": -128.61028575897217
            },
            {
              "word": "i'm a car both too",
              "weight": -128.93456745147705
            },
            {
              "word": "i'm a car buffs too",
              "weight": -130.00979804992676
            },
            {
              "word": "i'm a car of u",
              "weight": -131.2079906463623
            },
            {
              "word": "i'm a car but to",
              "weight": -129.07602500915527
            },
            {
              "word": "i'm a car by two",
              "weight": -130.32254028320312
            },
            {
              "word": "i'm a car if u",
              "weight": -129.80561447143555
            },
            {
              "word": "i'm a car buffs to",
              "weight": -129.2949924468994
            },
            {
              "word": "i'm a car both do",
              "weight": -129.26232147216797
            },
            {
              "word": "i'm a star both u",
              "weight": -131.08633041381836
            },
            {
              "word": "i'm a car buff due",
              "weight": -126.95032596588135
            },
            {
              "word": "i'm a car buff who",
              "weight": -126.60594177246094
            },
            {
              "word": "i'm a car up to",
              "weight": -130.99017143249512
            },
            {
              "word": "i'm a car a u",
              "weight": -132.02783584594727
            },
            {
              "word": "i'm a car but do",
              "weight": -129.43411445617676
            },
            {
              "word": "i'm a car by to",
              "weight": -130.8477783203125
            },
            {
              "word": "i'm a car by you",
              "weight": -131.19159317016602
            },
            {
              "word": "i'm a core of u",
              "weight": -131.50653076171875
            },
            {
              "word": "i'm a car but two",
              "weight": -130.4525203704834
            },
            {
              "word": "i'm a car buff few",
              "weight": -128.82164764404297
            },
            {
              "word": "i'm a car of two",
              "weight": -129.6344871520996
            },
            {
              "word": "i'm a car of you",
              "weight": -130.46600151062012
            },
            {
              "word": "i'm a car but too",
              "weight": -130.7862377166748
            },
            {
              "word": "i'm a car both two",
              "weight": -129.72438526153564
            },
            {
              "word": "i'm a car a few",
              "weight": -130.04777717590332
            },
            {
              "word": "i'm a car buffs you",
              "weight": -130.19512557983398
            },
            {
              "word": "i'm a star both to",
              "weight": -129.31463813781738
            },
            {
              "word": "i'm a car off to",
              "weight": -130.86812591552734
            },
            {
              "word": "i'm a car buffs u",
              "weight": -130.9517936706543
            },
            {
              "word": "i'm a are both u",
              "weight": -131.4971160888672
            },
            {
              "word": "i'm a car by the u",
              "weight": -134.9701976776123
            },
            {
              "word": "i am a car buff to",
              "weight": -128.96670532226562
            },
            {
              "word": "i'm a are both too",
              "weight": -130.72356796264648
            },
            {
              "word": "i'm a car buffer u",
              "weight": -131.99540519714355
            },
            {
              "word": "i'm a star both you",
              "weight": -130.90791702270508
            },
            {
              "word": "i'm a car off u",
              "weight": -132.4760913848877
            },
            {
              "word": "i'm a car both view",
              "weight": -131.68423652648926
            },
            {
              "word": "i'm a r a u",
              "weight": -132.34440231323242
            },
            {
              "word": "i'm a car of view",
              "weight": -132.71046447753906
            },
            {
              "word": "i'm a car buff true",
              "weight": -131.00282287597656
            },
            {
              "word": "i'm a star both too",
              "weight": -131.47146034240723
            },
            {
              "word": "i'm a star both do",
              "weight": -132.23496627807617
            },
            {
              "word": "i am a car buff too",
              "weight": -130.0275115966797
            },
            {
              "word": "i am a car buff you",
              "weight": -130.6160373687744
            },
            {
              "word": "i am a car buff u",
              "weight": -130.9968662261963
            },
            {
              "word": "i'm a star both two",
              "weight": -132.59590339660645
            },
            {
              "word": "i'm a star both view",
              "weight": -134.23119163513184
            },
            {
              "word": "i am a car both u",
              "weight": -134.4501895904541
            },
            {
              "word": "i am a car buff do",
              "weight": -132.41288948059082
            },
            {
              "word": "i am a car by u",
              "weight": -136.81628227233887
            },
            {
              "word": "i am a car both to",
              "weight": -133.2467041015625
            },
            {
              "word": "i am a car buff two",
              "weight": -133.3730239868164
            },
            {
              "word": "i am a car but u",
              "weight": -135.6344337463379
            },
            {
              "word": "i am a car if you",
              "weight": -133.63166427612305
            },
            {
              "word": "i am a car but you",
              "weight": -134.08810806274414
            },
            {
              "word": "i am a car both you",
              "weight": -134.26269721984863
            },
            {
              "word": "i am a car buff view",
              "weight": -135.2050437927246
            },
            {
              "word": "i am a car both too",
              "weight": -135.46868133544922
            },
            {
              "word": "i am a car buffs too",
              "weight": -136.74575233459473
            },
            {
              "word": "i am a car of u",
              "weight": -137.62474060058594
            },
            {
              "word": "i am a car but to",
              "weight": -135.4121856689453
            },
            {
              "word": "i am a car by two",
              "weight": -136.78764724731445
            },
            {
              "word": "i am a car if u",
              "weight": -136.26232528686523
            },
            {
              "word": "i am a car buffs to",
              "weight": -135.7851505279541
            },
            {
              "word": "i am a car both do",
              "weight": -135.66054725646973
            },
            {
              "word": "i am a car buff due",
              "weight": -133.42761421203613
            },
            {
              "word": "i am a car buff who",
              "weight": -133.03634643554688
            },
            {
              "word": "i am a car up to",
              "weight": -137.4498519897461
            },
            {
              "word": "i am a car a u",
              "weight": -138.45902061462402
            },
            {
              "word": "i am a car but do",
              "weight": -135.64605331420898
            },
            {
              "word": "i am a car by to",
              "weight": -137.3068962097168
            },
            {
              "word": "i am a car by you",
              "weight": -137.65165519714355
            },
            {
              "word": "i am a car but two",
              "weight": -136.8260726928711
            },
            {
              "word": "i am a car buff few",
              "weight": -135.39642524719238
            },
            {
              "word": "i am a car of two",
              "weight": -136.1227626800537
            },
            {
              "word": "i am a car of you",
              "weight": -136.9116668701172
            },
            {
              "word": "i am a car but too",
              "weight": -137.24258422851562
            },
            {
              "word": "i am a car both two",
              "weight": -136.15963745117188
            },
            {
              "word": "i am a car a few",
              "weight": -136.6423454284668
            },
            {
              "word": "i am a car buffs you",
              "weight": -136.82191848754883
            },
            {
              "word": "i am a car off to",
              "weight": -137.41367530822754
            },
            {
              "word": "i am a car buffs u",
              "weight": -137.30047988891602
            },
            {
              "word": "i am a car by the u",
              "weight": -141.52150917053223
            },
            {
              "word": "i am a car buffer u",
              "weight": -138.46569061279297
            },
            {
              "word": "i am a car off u",
              "weight": -138.71772384643555
            },
            {
              "word": "i am a car both view",
              "weight": -138.06311416625977
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "Who told you to do it?",
              "How do you view this whole subject?",
              "Who do you work for?",
              "True to life.",
              "I don't think I'm a real true believer.",
              "what i do as a wife and have been real handy",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation"
            ],
            "retrieval_time_ms": 24.659966000058375
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "i'm a car buff to",
                "llm_score": -181.12832641601562,
                "old_lm_score": -36.7275390625,
                "acoustic_score": -27.014446258544922,
                "combined_score": -122.43515586853027
              },
              {
                "candidate": "i'm a car buff too",
                "llm_score": -181.51736450195312,
                "old_lm_score": -37.75,
                "acoustic_score": -27.014446258544922,
                "combined_score": -123.14090538024902
              },
              {
                "candidate": "i'm a car buff you",
                "llm_score": -181.94674682617188,
                "old_lm_score": -38.2294921875,
                "acoustic_score": -27.54294204711914,
                "combined_score": -123.85959053039551
              },
              {
                "candidate": "i'm a car buff u",
                "llm_score": -183.2147216796875,
                "old_lm_score": -38.2890625,
                "acoustic_score": -27.54294204711914,
                "combined_score": -124.52336311340332
              },
              {
                "candidate": "i'm a car both u",
                "llm_score": -186.60601806640625,
                "old_lm_score": -38.0390625,
                "acoustic_score": -31.417831420898438,
                "combined_score": -128.03145599365234
              },
              {
                "candidate": "i'm a car buff do",
                "llm_score": -183.6940155029297,
                "old_lm_score": -39.919921875,
                "acoustic_score": -28.059755325317383,
                "combined_score": -125.83684635162354
              },
              {
                "candidate": "i'm a car by u",
                "llm_score": -184.95567321777344,
                "old_lm_score": -32.521484375,
                "acoustic_score": -43.459083557128906,
                "combined_score": -130.46812057495117
              },
              {
                "candidate": "i'm a car both to",
                "llm_score": -183.6791534423828,
                "old_lm_score": -39.43359375,
                "acoustic_score": -30.88933753967285,
                "combined_score": -127.00104236602783
              },
              {
                "candidate": "i'm a car buff two",
                "llm_score": -185.21609497070312,
                "old_lm_score": -41.4541015625,
                "acoustic_score": -27.014446258544922,
                "combined_score": -126.84232139587402
              },
              {
                "candidate": "i'm a car but u",
                "llm_score": -183.008544921875,
                "old_lm_score": -34.654296875,
                "acoustic_score": -40.71388626098633,
                "combined_score": -129.18836402893066
              },
              {
                "candidate": "i'm a car if you",
                "llm_score": -176.87904357910156,
                "old_lm_score": -33.1474609375,
                "acoustic_score": -44.22655487060547,
                "combined_score": -127.12652969360352
              },
              {
                "candidate": "i'm a car but you",
                "llm_score": -179.38543701171875,
                "old_lm_score": -35.0361328125,
                "acoustic_score": -40.71388626098633,
                "combined_score": -127.56772804260254
              },
              {
                "candidate": "i'm a car both you",
                "llm_score": -184.38436889648438,
                "old_lm_score": -39.7197265625,
                "acoustic_score": -31.417831420898438,
                "combined_score": -127.7609634399414
              },
              {
                "candidate": "i'm a score of to",
                "llm_score": -181.21383666992188,
                "old_lm_score": -27.61328125,
                "acoustic_score": -55.96162414550781,
                "combined_score": -132.39437103271484
              },
              {
                "candidate": "i'm a car buff view",
                "llm_score": -187.13082885742188,
                "old_lm_score": -41.4970703125,
                "acoustic_score": -28.59267234802246,
                "combined_score": -128.61028575897217
              },
              {
                "candidate": "i'm a car both too",
                "llm_score": -186.61651611328125,
                "old_lm_score": -40.36328125,
                "acoustic_score": -30.88933753967285,
                "combined_score": -128.93456745147705
              },
              {
                "candidate": "i'm a car buffs too",
                "llm_score": -186.94384765625,
                "old_lm_score": -38.85546875,
                "acoustic_score": -34.220279693603516,
                "combined_score": -130.00979804992676
              },
              {
                "candidate": "i'm a car of u",
                "llm_score": -184.16476440429688,
                "old_lm_score": -33.7939453125,
                "acoustic_score": -44.457271575927734,
                "combined_score": -131.2079906463623
              },
              {
                "candidate": "i'm a car but to",
                "llm_score": -182.02818298339844,
                "old_lm_score": -35.9384765625,
                "acoustic_score": -40.18539047241211,
                "combined_score": -129.07602500915527
              },
              {
                "candidate": "i'm a car by two",
                "llm_score": -183.11585998535156,
                "old_lm_score": -34.5986328125,
                "acoustic_score": -42.93058776855469,
                "combined_score": -130.32254028320312
              },
              {
                "candidate": "i'm a car if u",
                "llm_score": -181.42568969726562,
                "old_lm_score": -33.958984375,
                "acoustic_score": -44.22655487060547,
                "combined_score": -129.80561447143555
              },
              {
                "candidate": "i'm a car buffs to",
                "llm_score": -185.3960723876953,
                "old_lm_score": -38.9736328125,
                "acoustic_score": -34.220279693603516,
                "combined_score": -129.2949924468994
              },
              {
                "candidate": "i'm a car both do",
                "llm_score": -186.34878540039062,
                "old_lm_score": -40.2412109375,
                "acoustic_score": -31.934646606445312,
                "combined_score": -129.26232147216797
              },
              {
                "candidate": "i'm a star both u",
                "llm_score": -185.20855712890625,
                "old_lm_score": -35.5341796875,
                "acoustic_score": -41.42992401123047,
                "combined_score": -131.08633041381836
              },
              {
                "candidate": "i'm a car buff due",
                "llm_score": -183.5996856689453,
                "old_lm_score": -42.2412109375,
                "acoustic_score": -28.059755325317383,
                "combined_score": -126.95032596588135
              },
              {
                "candidate": "i'm a car buff who",
                "llm_score": -177.98141479492188,
                "old_lm_score": -37.3369140625,
                "acoustic_score": -37.8935546875,
                "combined_score": -126.60594177246094
              },
              {
                "candidate": "i'm a car up to",
                "llm_score": -181.634033203125,
                "old_lm_score": -32.4794921875,
                "acoustic_score": -47.866817474365234,
                "combined_score": -130.99017143249512
              },
              {
                "candidate": "i'm a car a u",
                "llm_score": -185.28176879882812,
                "old_lm_score": -34.056640625,
                "acoustic_score": -44.717262268066406,
                "combined_score": -132.02783584594727
              },
              {
                "candidate": "i'm a car but do",
                "llm_score": -181.8269805908203,
                "old_lm_score": -35.810546875,
                "acoustic_score": -41.2307014465332,
                "combined_score": -129.43411445617676
              },
              {
                "candidate": "i'm a car by to",
                "llm_score": -183.7405548095703,
                "old_lm_score": -35.0244140625,
                "acoustic_score": -42.93058776855469,
                "combined_score": -130.8477783203125
              },
              {
                "candidate": "i'm a car by you",
                "llm_score": -184.15847778320312,
                "old_lm_score": -34.765625,
                "acoustic_score": -43.459083557128906,
                "combined_score": -131.19159317016602
              },
              {
                "candidate": "i'm a core of u",
                "llm_score": -180.42059326171875,
                "old_lm_score": -30.5234375,
                "acoustic_score": -52.06903076171875,
                "combined_score": -131.50653076171875
              },
              {
                "candidate": "i'm a car but two",
                "llm_score": -183.7323455810547,
                "old_lm_score": -36.9873046875,
                "acoustic_score": -40.18539047241211,
                "combined_score": -130.4525203704834
              },
              {
                "candidate": "i'm a car buff few",
                "llm_score": -186.0883026123047,
                "old_lm_score": -42.6884765625,
                "acoustic_score": -28.86651611328125,
                "combined_score": -128.82164764404297
              },
              {
                "candidate": "i'm a car of two",
                "llm_score": -180.13609313964844,
                "old_lm_score": -35.2041015625,
                "acoustic_score": -43.92877960205078,
                "combined_score": -129.6344871520996
              },
              {
                "candidate": "i'm a car of you",
                "llm_score": -181.5030517578125,
                "old_lm_score": -34.9716796875,
                "acoustic_score": -44.457271575927734,
                "combined_score": -130.46600151062012
              },
              {
                "candidate": "i'm a car but too",
                "llm_score": -184.2620849609375,
                "old_lm_score": -37.125,
                "acoustic_score": -40.18539047241211,
                "combined_score": -130.7862377166748
              },
              {
                "candidate": "i'm a car both two",
                "llm_score": -186.78404235839844,
                "old_lm_score": -41.775390625,
                "acoustic_score": -30.88933753967285,
                "combined_score": -129.72438526153564
              },
              {
                "candidate": "i'm a car a few",
                "llm_score": -179.79202270507812,
                "old_lm_score": -34.2626953125,
                "acoustic_score": -46.040836334228516,
                "combined_score": -130.04777717590332
              },
              {
                "candidate": "i'm a car buffs you",
                "llm_score": -185.6444091796875,
                "old_lm_score": -39.9970703125,
                "acoustic_score": -34.74877166748047,
                "combined_score": -130.19512557983398
              },
              {
                "candidate": "i'm a star both to",
                "llm_score": -180.79913330078125,
                "old_lm_score": -36.9287109375,
                "acoustic_score": -40.901432037353516,
                "combined_score": -129.31463813781738
              },
              {
                "candidate": "i'm a car off to",
                "llm_score": -182.5275115966797,
                "old_lm_score": -35.798828125,
                "acoustic_score": -43.409912109375,
                "combined_score": -130.86812591552734
              },
              {
                "candidate": "i'm a car buffs u",
                "llm_score": -186.97415161132812,
                "old_lm_score": -40.1806640625,
                "acoustic_score": -34.74877166748047,
                "combined_score": -130.9517936706543
              },
              {
                "candidate": "i'm a are both u",
                "llm_score": -183.27017211914062,
                "old_lm_score": -35.603515625,
                "acoustic_score": -44.12054443359375,
                "combined_score": -131.4971160888672
              },
              {
                "candidate": "i'm a car by the u",
                "llm_score": -188.99710083007812,
                "old_lm_score": -34.3857421875,
                "acoustic_score": -46.557552337646484,
                "combined_score": -134.9701976776123
              },
              {
                "candidate": "i am a car buff to",
                "llm_score": -181.7700958251953,
                "old_lm_score": -39.416015625,
                "acoustic_score": -36.74729919433594,
                "combined_score": -128.96670532226562
              },
              {
                "candidate": "i'm a are both too",
                "llm_score": -181.76622009277344,
                "old_lm_score": -36.0888671875,
                "acoustic_score": -43.59204864501953,
                "combined_score": -130.72356796264648
              },
              {
                "candidate": "i'm a car buffer u",
                "llm_score": -188.30413818359375,
                "old_lm_score": -40.111328125,
                "acoustic_score": -35.57534408569336,
                "combined_score": -131.99540519714355
              },
              {
                "candidate": "i'm a star both you",
                "llm_score": -183.1710662841797,
                "old_lm_score": -37.21484375,
                "acoustic_score": -41.42992401123047,
                "combined_score": -130.90791702270508
              },
              {
                "candidate": "i'm a car off u",
                "llm_score": -184.94639587402344,
                "old_lm_score": -36.0673828125,
                "acoustic_score": -43.93840408325195,
                "combined_score": -132.4760913848877
              },
              {
                "candidate": "i'm a car both view",
                "llm_score": -189.08255004882812,
                "old_lm_score": -41.818359375,
                "acoustic_score": -32.46756362915039,
                "combined_score": -131.68423652648926
              },
              {
                "candidate": "i'm a r a u",
                "llm_score": -177.84402465820312,
                "old_lm_score": -29.4248046875,
                "acoustic_score": -57.41997528076172,
                "combined_score": -132.34440231323242
              },
              {
                "candidate": "i'm a car of view",
                "llm_score": -184.52232360839844,
                "old_lm_score": -35.3916015625,
                "acoustic_score": -45.50700378417969,
                "combined_score": -132.71046447753906
              },
              {
                "candidate": "i'm a car buff true",
                "llm_score": -186.68519592285156,
                "old_lm_score": -41.0087890625,
                "acoustic_score": -34.31166076660156,
                "combined_score": -131.00282287597656
              },
              {
                "candidate": "i'm a star both too",
                "llm_score": -184.18309020996094,
                "old_lm_score": -37.8583984375,
                "acoustic_score": -40.901432037353516,
                "combined_score": -131.47146034240723
              },
              {
                "candidate": "i'm a star both do",
                "llm_score": -184.786865234375,
                "old_lm_score": -37.736328125,
                "acoustic_score": -41.946739196777344,
                "combined_score": -132.23496627807617
              },
              {
                "candidate": "i am a car buff too",
                "llm_score": -182.86924743652344,
                "old_lm_score": -40.4384765625,
                "acoustic_score": -36.74729919433594,
                "combined_score": -130.0275115966797
              },
              {
                "candidate": "i am a car buff you",
                "llm_score": -183.03831481933594,
                "old_lm_score": -40.91796875,
                "acoustic_score": -37.27579116821289,
                "combined_score": -130.6160373687744
              },
              {
                "candidate": "i am a car buff u",
                "llm_score": -183.7404022216797,
                "old_lm_score": -40.9775390625,
                "acoustic_score": -37.27579116821289,
                "combined_score": -130.9968662261963
              },
              {
                "candidate": "i'm a star both two",
                "llm_score": -185.01986694335938,
                "old_lm_score": -39.2705078125,
                "acoustic_score": -40.901432037353516,
                "combined_score": -132.59590339660645
              },
              {
                "candidate": "i'm a star both view",
                "llm_score": -186.66925048828125,
                "old_lm_score": -39.3134765625,
                "acoustic_score": -42.47965621948242,
                "combined_score": -134.23119163513184
              },
              {
                "candidate": "i am a car both u",
                "llm_score": -187.02215576171875,
                "old_lm_score": -40.7275390625,
                "acoustic_score": -41.15068435668945,
                "combined_score": -134.4501895904541
              },
              {
                "candidate": "i am a car buff do",
                "llm_score": -184.42477416992188,
                "old_lm_score": -42.6083984375,
                "acoustic_score": -37.792606353759766,
                "combined_score": -132.41288948059082
              },
              {
                "candidate": "i am a car by u",
                "llm_score": -185.2306671142578,
                "old_lm_score": -35.2099609375,
                "acoustic_score": -53.19193649291992,
                "combined_score": -136.81628227233887
              },
              {
                "candidate": "i am a car both to",
                "llm_score": -183.7491455078125,
                "old_lm_score": -42.1220703125,
                "acoustic_score": -40.6221923828125,
                "combined_score": -133.2467041015625
              },
              {
                "candidate": "i am a car buff two",
                "llm_score": -185.85617065429688,
                "old_lm_score": -44.142578125,
                "acoustic_score": -36.74729919433594,
                "combined_score": -133.3730239868164
              },
              {
                "candidate": "i am a car but u",
                "llm_score": -183.47935485839844,
                "old_lm_score": -37.3427734375,
                "acoustic_score": -50.446739196777344,
                "combined_score": -135.6344337463379
              },
              {
                "candidate": "i am a car if you",
                "llm_score": -177.46798706054688,
                "old_lm_score": -35.8359375,
                "acoustic_score": -53.95940399169922,
                "combined_score": -133.63166427612305
              },
              {
                "candidate": "i am a car but you",
                "llm_score": -180.00486755371094,
                "old_lm_score": -37.724609375,
                "acoustic_score": -50.446739196777344,
                "combined_score": -134.08810806274414
              },
              {
                "candidate": "i am a car both you",
                "llm_score": -184.9665069580078,
                "old_lm_score": -42.408203125,
                "acoustic_score": -41.15068435668945,
                "combined_score": -134.26269721984863
              },
              {
                "candidate": "i am a car buff view",
                "llm_score": -187.89901733398438,
                "old_lm_score": -44.185546875,
                "acoustic_score": -38.325523376464844,
                "combined_score": -135.2050437927246
              },
              {
                "candidate": "i am a car both too",
                "llm_score": -187.26341247558594,
                "old_lm_score": -43.0517578125,
                "acoustic_score": -40.6221923828125,
                "combined_score": -135.46868133544922
              },
              {
                "candidate": "i am a car buffs too",
                "llm_score": -187.9944305419922,
                "old_lm_score": -41.5439453125,
                "acoustic_score": -43.953128814697266,
                "combined_score": -136.74575233459473
              },
              {
                "candidate": "i am a car of u",
                "llm_score": -184.57693481445312,
                "old_lm_score": -36.482421875,
                "acoustic_score": -54.19012451171875,
                "combined_score": -137.62474060058594
              },
              {
                "candidate": "i am a car but to",
                "llm_score": -182.2791748046875,
                "old_lm_score": -38.626953125,
                "acoustic_score": -49.918243408203125,
                "combined_score": -135.4121856689453
              },
              {
                "candidate": "i am a car by two",
                "llm_score": -183.62474060058594,
                "old_lm_score": -37.287109375,
                "acoustic_score": -52.66344451904297,
                "combined_score": -136.78764724731445
              },
              {
                "candidate": "i am a car if u",
                "llm_score": -181.91778564453125,
                "old_lm_score": -36.6474609375,
                "acoustic_score": -53.95940399169922,
                "combined_score": -136.26232528686523
              },
              {
                "candidate": "i am a car buffs to",
                "llm_score": -185.95506286621094,
                "old_lm_score": -41.662109375,
                "acoustic_score": -43.953128814697266,
                "combined_score": -135.7851505279541
              },
              {
                "candidate": "i am a car both do",
                "llm_score": -186.72390747070312,
                "old_lm_score": -42.9296875,
                "acoustic_score": -41.66749954223633,
                "combined_score": -135.66054725646973
              },
              {
                "candidate": "i am a car buff due",
                "llm_score": -184.1329345703125,
                "old_lm_score": -44.9296875,
                "acoustic_score": -37.792606353759766,
                "combined_score": -133.42761421203613
              },
              {
                "candidate": "i am a car buff who",
                "llm_score": -178.4208984375,
                "old_lm_score": -40.025390625,
                "acoustic_score": -47.62640380859375,
                "combined_score": -133.03634643554688
              },
              {
                "candidate": "i am a car up to",
                "llm_score": -182.13206481933594,
                "old_lm_score": -35.16796875,
                "acoustic_score": -57.59967041015625,
                "combined_score": -137.4498519897461
              },
              {
                "candidate": "i am a car a u",
                "llm_score": -185.72280883789062,
                "old_lm_score": -36.7451171875,
                "acoustic_score": -54.45011520385742,
                "combined_score": -138.45902061462402
              },
              {
                "candidate": "i am a car but do",
                "llm_score": -181.82952880859375,
                "old_lm_score": -38.4990234375,
                "acoustic_score": -50.96355438232422,
                "combined_score": -135.64605331420898
              },
              {
                "candidate": "i am a car by to",
                "llm_score": -184.23745727539062,
                "old_lm_score": -37.712890625,
                "acoustic_score": -52.66344451904297,
                "combined_score": -137.3068962097168
              },
              {
                "candidate": "i am a car by you",
                "llm_score": -184.6572723388672,
                "old_lm_score": -37.4541015625,
                "acoustic_score": -53.19193649291992,
                "combined_score": -137.65165519714355
              },
              {
                "candidate": "i am a car but two",
                "llm_score": -184.05812072753906,
                "old_lm_score": -39.67578125,
                "acoustic_score": -49.918243408203125,
                "combined_score": -136.8260726928711
              },
              {
                "candidate": "i am a car buff few",
                "llm_score": -186.8165283203125,
                "old_lm_score": -45.376953125,
                "acoustic_score": -38.599369049072266,
                "combined_score": -135.39642524719238
              },
              {
                "candidate": "i am a car of two",
                "llm_score": -180.69131469726562,
                "old_lm_score": -37.892578125,
                "acoustic_score": -53.6616325378418,
                "combined_score": -136.1227626800537
              },
              {
                "candidate": "i am a car of you",
                "llm_score": -181.97305297851562,
                "old_lm_score": -37.66015625,
                "acoustic_score": -54.19012451171875,
                "combined_score": -136.9116668701172
              },
              {
                "candidate": "i am a car but too",
                "llm_score": -184.75344848632812,
                "old_lm_score": -39.8134765625,
                "acoustic_score": -49.918243408203125,
                "combined_score": -137.24258422851562
              },
              {
                "candidate": "i am a car both two",
                "llm_score": -187.23321533203125,
                "old_lm_score": -44.4638671875,
                "acoustic_score": -40.6221923828125,
                "combined_score": -136.15963745117188
              },
              {
                "candidate": "i am a car a few",
                "llm_score": -180.55982971191406,
                "old_lm_score": -36.951171875,
                "acoustic_score": -55.77368927001953,
                "combined_score": -136.6423454284668
              },
              {
                "candidate": "i am a car buffs you",
                "llm_score": -186.47666931152344,
                "old_lm_score": -42.685546875,
                "acoustic_score": -44.48162078857422,
                "combined_score": -136.82191848754883
              },
              {
                "candidate": "i am a car off to",
                "llm_score": -183.19728088378906,
                "old_lm_score": -38.4873046875,
                "acoustic_score": -53.142765045166016,
                "combined_score": -137.41367530822754
              },
              {
                "candidate": "i am a car buffs u",
                "llm_score": -187.2501983642578,
                "old_lm_score": -42.869140625,
                "acoustic_score": -44.48162078857422,
                "combined_score": -137.30047988891602
              },
              {
                "candidate": "i am a car by the u",
                "llm_score": -189.6783905029297,
                "old_lm_score": -37.07421875,
                "acoustic_score": -56.290409088134766,
                "combined_score": -141.52150917053223
              },
              {
                "candidate": "i am a car buffer u",
                "llm_score": -188.82337951660156,
                "old_lm_score": -42.7998046875,
                "acoustic_score": -45.308197021484375,
                "combined_score": -138.46569061279297
              },
              {
                "candidate": "i am a car off u",
                "llm_score": -185.00833129882812,
                "old_lm_score": -38.755859375,
                "acoustic_score": -53.67125701904297,
                "combined_score": -138.71772384643555
              },
              {
                "candidate": "i am a car both view",
                "llm_score": -189.41897583007812,
                "old_lm_score": -44.5068359375,
                "acoustic_score": -42.200416564941406,
                "combined_score": -138.06311416625977
              }
            ],
            "selected": "i'm a car buff to",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 1890.0753849999319
        }
      ],
      "total_time_ms": 1921.59793299993
    },
    {
      "sentence_idx": 29,
      "ground_truth": "joy springs from a grateful heart",
      "top1_hypothesis": "to fans from a grateful heart",
      "final_decoded": "two fans from a grateful heart",
      "was_changed": true,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 2,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "to",
          "confusion_candidates": [
            {
              "word": "to",
              "weight": 0.4713154383003654
            },
            {
              "word": "two",
              "weight": 0.2201556653662759
            },
            {
              "word": "drew",
              "weight": 0.08444861685536567
            },
            {
              "word": "do",
              "weight": 0.14265300082619334
            },
            {
              "word": "true",
              "weight": 0.02239932082639499
            },
            {
              "word": "draw",
              "weight": 0.011186691898789307
            },
            {
              "word": "the",
              "weight": 0.00010179457944292909
            },
            {
              "word": "tour",
              "weight": 0.02036490341656486
            },
            {
              "word": "good",
              "weight": 0.0003553889394771725
            },
            {
              "word": "gore",
              "weight": 0.013251828647584639
            },
            {
              "word": "new",
              "weight": 7.517031709980616e-05
            },
            {
              "word": "tory",
              "weight": 0.001508293404180383
            },
            {
              "word": "for",
              "weight": 1.8397261226516865e-05
            },
            {
              "word": "tool",
              "weight": 0.00036808948513236147
            },
            {
              "word": "deux",
              "weight": 0.004794348476286794
            },
            {
              "word": "du",
              "weight": 0.0032467075243949027
            },
            {
              "word": "join",
              "weight": 6.247071205964668e-05
            },
            {
              "word": "your",
              "weight": 2.2884759278303557e-05
            },
            {
              "word": "dew",
              "weight": 0.002652292370071986
            },
            {
              "word": "dear",
              "weight": 4.877339708347702e-05
            },
            {
              "word": "de",
              "weight": 0.00012299858059798414
            },
            {
              "word": "yuri",
              "weight": 0.0001347426911554204
            },
            {
              "word": "crew",
              "weight": 3.3642363683170216e-05
            },
            {
              "word": "der",
              "weight": 0.00041402151150794314
            },
            {
              "word": "d",
              "weight": 0.00014754798070662573
            },
            {
              "word": "so",
              "weight": 3.84405569196106e-06
            },
            {
              "word": "story",
              "weight": 4.917881373180539e-05
            },
            {
              "word": "see",
              "weight": 5.381838552738121e-06
            },
            {
              "word": "more",
              "weight": 1.9909860724570945e-06
            },
            {
              "word": "g",
              "weight": 5.657381403174572e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.533208747804901,
            "margin": 0.2511597729340895,
            "disagreement_mass": 0.5286845616996346
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(to OR two OR drew OR do OR true OR draw OR the OR tour OR good OR gore OR new OR tory OR for OR tool OR deux OR du OR join OR your OR dew OR dear OR de OR yuri OR crew OR der OR d OR so OR story OR see OR more OR g) fans from a grateful heart",
            "retrieved_docs": [
              "We draw two main conclusions from these facts.",
              "Who do you want to see join the battle?",
              "Draw your own conclusions.",
              "It's like God changes your heart to not do that.",
              "Draw each graph on a new axis.",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to"
            ],
            "scores": [
              14.332235068220022,
              13.921195512393115,
              13.345134386745546,
              12.89710877683054,
              12.878893889725786,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 42.69009900008314
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "fans",
          "confusion_candidates": [
            {
              "word": "fans",
              "weight": 0.885350481623435
            },
            {
              "word": "things",
              "weight": 0.0003805694172743956
            },
            {
              "word": "pins",
              "weight": 0.018438437219730774
            },
            {
              "word": "spans",
              "weight": 0.035857090655012816
            },
            {
              "word": "planes",
              "weight": 0.0007646214624496072
            },
            {
              "word": "pings",
              "weight": 0.013372581281702205
            },
            {
              "word": "springs",
              "weight": 0.0012944243183603784
            },
            {
              "word": "fins",
              "weight": 0.018974518291031448
            },
            {
              "word": "plans",
              "weight": 0.004096918868644007
            },
            {
              "word": "pans",
              "weight": 0.004705792997107359
            },
            {
              "word": "fangs",
              "weight": 0.008359975259423818
            },
            {
              "word": "pigs",
              "weight": 0.0013070245636339715
            },
            {
              "word": "friends",
              "weight": 7.054459262072518e-06
            },
            {
              "word": "flags",
              "weight": 0.00020646531030580505
            },
            {
              "word": "spins",
              "weight": 0.0023907048793977777
            },
            {
              "word": "scenes",
              "weight": 1.1845126030675563e-05
            },
            {
              "word": "pens",
              "weight": 0.00030342734004935016
            },
            {
              "word": "finns",
              "weight": 0.0038741010292326727
            },
            {
              "word": "panes",
              "weight": 0.00027811150181094376
            },
            {
              "word": "kids",
              "weight": 8.963334458450363e-07
            },
            {
              "word": "kings",
              "weight": 1.639047547856498e-05
            },
            {
              "word": "fines",
              "weight": 2.0727634451791993e-06
            },
            {
              "word": "finn's",
              "weight": 2.4942557562908403e-07
            },
            {
              "word": "wins",
              "weight": 4.840486794160636e-07
            },
            {
              "word": "phones",
              "weight": 4.827967744774926e-06
            },
            {
              "word": "flames",
              "weight": 1.2774241866544399e-09
            },
            {
              "word": "bids",
              "weight": 9.321033113925594e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5901660704648689,
            "margin": 0.8494933909684221,
            "disagreement_mass": 0.11464951837656501
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "to (fans OR things OR pins OR spans OR planes OR pings OR springs OR fins OR plans OR pans OR fangs OR pigs OR friends OR flags OR spins OR scenes OR pens OR finns OR panes OR kids OR kings OR fines OR finn's OR wins OR phones OR flames OR bids) from a grateful heart",
            "retrieved_docs": [
              "We went to Six Flags Saturday.",
              "She plans it all out.",
              "A person's heart can be changed.",
              "The latest Android phones for less.",
              "To the heart of the matter though.",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to"
            ],
            "scores": [
              10.079909164969242,
              9.568650191125684,
              9.300074604091243,
              8.87176695744912,
              8.834552752740779,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 37.10540999998102
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "grateful",
          "confusion_candidates": [
            {
              "word": "grateful",
              "weight": 0.9977739886778738
            },
            {
              "word": "little",
              "weight": 0.0021830788185624515
            },
            {
              "word": "digital",
              "weight": 4.2932502563772175e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.016031021679170802,
            "margin": 0.9955909098593113,
            "disagreement_mass": 0.002226011322126187
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "heart",
          "confusion_candidates": [
            {
              "word": "heart",
              "weight": 0.9997380035267417
            },
            {
              "word": "hard",
              "weight": 0.00021906396969452254
            },
            {
              "word": "art",
              "weight": 4.2932502563772175e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.002539551460502968,
            "margin": 0.9995189395570472,
            "disagreement_mass": 0.000261996473258308
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 6,
          "top1_word": "to fans from a grateful heart",
          "confusion_candidates": [
            {
              "word": "to fans from a grateful heart",
              "weight": -184.06155395507812
            },
            {
              "word": "fans from a grateful heart",
              "weight": -186.9831657409668
            },
            {
              "word": "two fans from a grateful heart",
              "weight": -183.97108459472656
            },
            {
              "word": "drew fans from a grateful heart",
              "weight": -189.27691650390625
            },
            {
              "word": "do fans from a grateful heart",
              "weight": -185.09986877441406
            },
            {
              "word": "two things from a grateful heart",
              "weight": -185.09510803222656
            },
            {
              "word": "true fans from a grateful heart",
              "weight": -186.50444793701172
            },
            {
              "word": "draw fans from a grateful heart",
              "weight": -185.14557647705078
            },
            {
              "word": "two pins from a grateful heart",
              "weight": -184.6997528076172
            },
            {
              "word": "the fans from a grateful heart",
              "weight": -187.97819137573242
            },
            {
              "word": "two spans from a grateful heart",
              "weight": -186.12080764770508
            },
            {
              "word": "two planes from a grateful heart",
              "weight": -186.31493377685547
            },
            {
              "word": "two pings from a grateful heart",
              "weight": -187.06185150146484
            },
            {
              "word": "two springs from a grateful heart",
              "weight": -184.95529174804688
            },
            {
              "word": "two fins from a grateful heart",
              "weight": -186.92289352416992
            },
            {
              "word": "two plans from a grateful heart",
              "weight": -186.20561599731445
            },
            {
              "word": "two pans from a grateful heart",
              "weight": -187.16999435424805
            },
            {
              "word": "tour spans from a grateful heart",
              "weight": -189.33484268188477
            },
            {
              "word": "good things from a grateful heart",
              "weight": -185.36230087280273
            },
            {
              "word": "do things from a grateful heart",
              "weight": -184.41226959228516
            },
            {
              "word": "gore fans from a grateful heart",
              "weight": -188.6548957824707
            },
            {
              "word": "to fans from a little heart",
              "weight": -187.03419876098633
            },
            {
              "word": "new fans from a grateful heart",
              "weight": -189.76450729370117
            },
            {
              "word": "two fangs from a grateful heart",
              "weight": -187.1365966796875
            },
            {
              "word": "the fins from a grateful heart",
              "weight": -190.2927703857422
            },
            {
              "word": "two pigs from a grateful heart",
              "weight": -188.15784454345703
            },
            {
              "word": "to fans from a little hard",
              "weight": -188.17776489257812
            },
            {
              "word": "tory plans from a grateful heart",
              "weight": -191.00725173950195
            },
            {
              "word": "do pigs from a grateful heart",
              "weight": -188.21500396728516
            },
            {
              "word": "for fans from a grateful heart",
              "weight": -189.39125061035156
            },
            {
              "word": "two friends from a grateful heart",
              "weight": -187.19445037841797
            },
            {
              "word": "two flags from a grateful heart",
              "weight": -188.24090194702148
            },
            {
              "word": "two spins from a grateful heart",
              "weight": -187.17706298828125
            },
            {
              "word": "to plans from a grateful heart",
              "weight": -188.16808700561523
            },
            {
              "word": "the pins from a grateful heart",
              "weight": -189.72980880737305
            },
            {
              "word": "tool fans from a grateful heart",
              "weight": -190.5220718383789
            },
            {
              "word": "two scenes from a grateful heart",
              "weight": -188.63247680664062
            },
            {
              "word": "to spans from a grateful heart",
              "weight": -188.98950576782227
            },
            {
              "word": "to pings from a grateful heart",
              "weight": -188.60382843017578
            },
            {
              "word": "plans from a grateful heart",
              "weight": -189.86795806884766
            },
            {
              "word": "pings from a grateful heart",
              "weight": -190.40250778198242
            },
            {
              "word": "fins from a grateful heart",
              "weight": -189.94983673095703
            },
            {
              "word": "scenes from a grateful heart",
              "weight": -192.19260025024414
            },
            {
              "word": "the plans from a grateful heart",
              "weight": -189.75715255737305
            },
            {
              "word": "deux fins from a grateful heart",
              "weight": -191.2530403137207
            },
            {
              "word": "two pens from a grateful heart",
              "weight": -187.97436904907227
            },
            {
              "word": "spans from a grateful heart",
              "weight": -190.16382598876953
            },
            {
              "word": "du finns from a grateful heart",
              "weight": -194.06306838989258
            },
            {
              "word": "fans from a little heart",
              "weight": -189.08841705322266
            },
            {
              "word": "pins from a grateful heart",
              "weight": -189.8610954284668
            },
            {
              "word": "two fans from a little heart",
              "weight": -186.8320198059082
            },
            {
              "word": "join fans from a grateful heart",
              "weight": -188.70563888549805
            },
            {
              "word": "your fans from a grateful heart",
              "weight": -188.79106521606445
            },
            {
              "word": "two panes from a grateful heart",
              "weight": -188.28490447998047
            },
            {
              "word": "the finns from a grateful heart",
              "weight": -193.3652458190918
            },
            {
              "word": "tour plans from a grateful heart",
              "weight": -190.28186416625977
            },
            {
              "word": "dew fans from a grateful heart",
              "weight": -190.42108917236328
            },
            {
              "word": "drew fans from a little heart",
              "weight": -191.90522384643555
            },
            {
              "word": "the pings from a grateful heart",
              "weight": -190.72228622436523
            },
            {
              "word": "fans from a little hard",
              "weight": -190.53824996948242
            },
            {
              "word": "springs from a grateful heart",
              "weight": -190.75821685791016
            },
            {
              "word": "to springs from a grateful heart",
              "weight": -188.3144302368164
            },
            {
              "word": "two fans from a little hard",
              "weight": -188.24793243408203
            },
            {
              "word": "two kids from a grateful heart",
              "weight": -188.8697395324707
            },
            {
              "word": "tour fans from a grateful heart",
              "weight": -189.8098602294922
            },
            {
              "word": "to fans from a digital art",
              "weight": -187.96318817138672
            },
            {
              "word": "dear fans from a grateful heart",
              "weight": -190.30360794067383
            },
            {
              "word": "drew fans from a little hard",
              "weight": -192.93697357177734
            },
            {
              "word": "pigs from a grateful heart",
              "weight": -192.11065292358398
            },
            {
              "word": "do fans from a little heart",
              "weight": -188.35285568237305
            },
            {
              "word": "two kings from a grateful heart",
              "weight": -188.32255935668945
            },
            {
              "word": "to fines from a grateful heart",
              "weight": -193.3731460571289
            },
            {
              "word": "the scenes from a grateful heart",
              "weight": -192.34950256347656
            },
            {
              "word": "de finns from a grateful heart",
              "weight": -195.48401260375977
            },
            {
              "word": "yuri fans from a grateful heart",
              "weight": -191.98936462402344
            },
            {
              "word": "finn's from a grateful heart",
              "weight": -193.40570068359375
            },
            {
              "word": "to fins from a grateful heart",
              "weight": -189.04888534545898
            },
            {
              "word": "do fans from a little hard",
              "weight": -189.58706665039062
            },
            {
              "word": "crew fans from a grateful heart",
              "weight": -192.34834671020508
            },
            {
              "word": "der fans from a grateful heart",
              "weight": -191.3946418762207
            },
            {
              "word": "deux pans from a grateful heart",
              "weight": -192.60544204711914
            },
            {
              "word": "the springs from a grateful heart",
              "weight": -189.73785781860352
            },
            {
              "word": "two wins from a grateful heart",
              "weight": -190.99148559570312
            },
            {
              "word": "two phones from a grateful heart",
              "weight": -191.0976676940918
            },
            {
              "word": "d fans from a grateful heart",
              "weight": -188.61516571044922
            },
            {
              "word": "so fans from a grateful heart",
              "weight": -189.96170806884766
            },
            {
              "word": "fangs from a grateful heart",
              "weight": -188.9669532775879
            },
            {
              "word": "to pins from a grateful heart",
              "weight": -189.06331634521484
            },
            {
              "word": "story spans from a grateful heart",
              "weight": -189.62057495117188
            },
            {
              "word": "d pins from a grateful heart",
              "weight": -190.79107666015625
            },
            {
              "word": "true finns from a grateful heart",
              "weight": -193.99072647094727
            },
            {
              "word": "good fans from a grateful heart",
              "weight": -187.1515350341797
            },
            {
              "word": "flames from a grateful heart",
              "weight": -192.65934371948242
            },
            {
              "word": "see fans from a grateful heart",
              "weight": -191.18228149414062
            },
            {
              "word": "two bids from a grateful heart",
              "weight": -191.81696319580078
            },
            {
              "word": "the pigs from a grateful heart",
              "weight": -192.3163948059082
            },
            {
              "word": "planes from a grateful heart",
              "weight": -190.45583724975586
            },
            {
              "word": "more fans from a grateful heart",
              "weight": -191.08255004882812
            },
            {
              "word": "to planes from a grateful heart",
              "weight": -190.6334991455078
            },
            {
              "word": "g fans from a grateful heart",
              "weight": -189.04835891723633
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "We draw two main conclusions from these facts.",
              "Who do you want to see join the battle?",
              "Draw your own conclusions.",
              "It's like God changes your heart to not do that.",
              "Draw each graph on a new axis.",
              "i do when i was working",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "We went to Six Flags Saturday.",
              "She plans it all out.",
              "A person's heart can be changed.",
              "The latest Android phones for less.",
              "To the heart of the matter though."
            ],
            "retrieval_time_ms": 79.79550900006416
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "to fans from a grateful heart",
                "llm_score": -253.90872192382812,
                "old_lm_score": -39.591796875,
                "acoustic_score": -74.62258911132812,
                "combined_score": -184.06155395507812
              },
              {
                "candidate": "fans from a grateful heart",
                "llm_score": -250.0469207763672,
                "old_lm_score": -32.263671875,
                "acoustic_score": -91.6557388305664,
                "combined_score": -186.9831657409668
              },
              {
                "candidate": "two fans from a grateful heart",
                "llm_score": -252.516845703125,
                "old_lm_score": -40.802734375,
                "acoustic_score": -74.62258911132812,
                "combined_score": -183.97108459472656
              },
              {
                "candidate": "drew fans from a grateful heart",
                "llm_score": -262.63385009765625,
                "old_lm_score": -40.6201171875,
                "acoustic_score": -75.29986572265625,
                "combined_score": -189.27691650390625
              },
              {
                "candidate": "do fans from a grateful heart",
                "llm_score": -254.79823303222656,
                "old_lm_score": -41.5712890625,
                "acoustic_score": -73.83021545410156,
                "combined_score": -185.09986877441406
              },
              {
                "candidate": "two things from a grateful heart",
                "llm_score": -248.6616668701172,
                "old_lm_score": -36.4794921875,
                "acoustic_score": -85.04905700683594,
                "combined_score": -185.09510803222656
              },
              {
                "candidate": "true fans from a grateful heart",
                "llm_score": -255.74185180664062,
                "old_lm_score": -41.1748046875,
                "acoustic_score": -76.09223937988281,
                "combined_score": -186.50444793701172
              },
              {
                "candidate": "draw fans from a grateful heart",
                "llm_score": -252.35238647460938,
                "old_lm_score": -40.880859375,
                "acoustic_score": -77.05790710449219,
                "combined_score": -185.14557647705078
              },
              {
                "candidate": "two pins from a grateful heart",
                "llm_score": -251.9297637939453,
                "old_lm_score": -41.412109375,
                "acoustic_score": -76.05763244628906,
                "combined_score": -184.6997528076172
              },
              {
                "candidate": "the fans from a grateful heart",
                "llm_score": -253.03271484375,
                "old_lm_score": -36.08203125,
                "acoustic_score": -86.84163665771484,
                "combined_score": -187.97819137573242
              },
              {
                "candidate": "two spans from a grateful heart",
                "llm_score": -254.84268188476562,
                "old_lm_score": -41.732421875,
                "acoustic_score": -75.66651153564453,
                "combined_score": -186.12080764770508
              },
              {
                "candidate": "two planes from a grateful heart",
                "llm_score": -251.9623565673828,
                "old_lm_score": -39.5029296875,
                "acoustic_score": -81.16458129882812,
                "combined_score": -186.31493377685547
              },
              {
                "candidate": "two pings from a grateful heart",
                "llm_score": -256.1910400390625,
                "old_lm_score": -42.5478515625,
                "acoustic_score": -75.38481140136719,
                "combined_score": -187.06185150146484
              },
              {
                "candidate": "two springs from a grateful heart",
                "llm_score": -249.7102508544922,
                "old_lm_score": -40.3955078125,
                "acoustic_score": -79.80482482910156,
                "combined_score": -184.95529174804688
              },
              {
                "candidate": "two fins from a grateful heart",
                "llm_score": -256.1129150390625,
                "old_lm_score": -43.150390625,
                "acoustic_score": -74.58248138427734,
                "combined_score": -186.92289352416992
              },
              {
                "candidate": "two plans from a grateful heart",
                "llm_score": -252.3758544921875,
                "old_lm_score": -41.2880859375,
                "acoustic_score": -78.7472915649414,
                "combined_score": -186.20561599731445
              },
              {
                "candidate": "two pans from a grateful heart",
                "llm_score": -255.34478759765625,
                "old_lm_score": -42.8974609375,
                "acoustic_score": -76.09774017333984,
                "combined_score": -187.16999435424805
              },
              {
                "candidate": "tour spans from a grateful heart",
                "llm_score": -261.00341796875,
                "old_lm_score": -44.3203125,
                "acoustic_score": -73.34595489501953,
                "combined_score": -189.33484268188477
              },
              {
                "candidate": "good things from a grateful heart",
                "llm_score": -246.05821228027344,
                "old_lm_score": -37.4541015625,
                "acoustic_score": -87.21228790283203,
                "combined_score": -185.36230087280273
              },
              {
                "candidate": "do things from a grateful heart",
                "llm_score": -245.63035583496094,
                "old_lm_score": -38.9375,
                "acoustic_score": -84.25668334960938,
                "combined_score": -184.41226959228516
              },
              {
                "candidate": "gore fans from a grateful heart",
                "llm_score": -259.5404357910156,
                "old_lm_score": -44.3857421875,
                "acoustic_score": -73.38361358642578,
                "combined_score": -188.6548957824707
              },
              {
                "candidate": "to fans from a little heart",
                "llm_score": -253.81065368652344,
                "old_lm_score": -41.9501953125,
                "acoustic_score": -78.30754852294922,
                "combined_score": -187.03419876098633
              },
              {
                "candidate": "new fans from a grateful heart",
                "llm_score": -256.5875244140625,
                "old_lm_score": -39.5439453125,
                "acoustic_score": -83.39754486083984,
                "combined_score": -189.76450729370117
              },
              {
                "candidate": "two fangs from a grateful heart",
                "llm_score": -256.04315185546875,
                "old_lm_score": -44.2802734375,
                "acoustic_score": -73.94976806640625,
                "combined_score": -187.1365966796875
              },
              {
                "candidate": "the fins from a grateful heart",
                "llm_score": -255.9070587158203,
                "old_lm_score": -37.876953125,
                "acoustic_score": -86.80152893066406,
                "combined_score": -190.2927703857422
              },
              {
                "candidate": "two pigs from a grateful heart",
                "llm_score": -255.34814453125,
                "old_lm_score": -41.6416015625,
                "acoustic_score": -79.32594299316406,
                "combined_score": -188.15784454345703
              },
              {
                "candidate": "to fans from a little hard",
                "llm_score": -253.90440368652344,
                "old_lm_score": -40.166015625,
                "acoustic_score": -82.28511047363281,
                "combined_score": -188.17776489257812
              },
              {
                "candidate": "tory plans from a grateful heart",
                "llm_score": -262.0719909667969,
                "old_lm_score": -42.7626953125,
                "acoustic_score": -77.17981719970703,
                "combined_score": -191.00725173950195
              },
              {
                "candidate": "do pigs from a grateful heart",
                "llm_score": -255.8095245361328,
                "old_lm_score": -42.0869140625,
                "acoustic_score": -78.5335693359375,
                "combined_score": -188.21500396728516
              },
              {
                "candidate": "for fans from a grateful heart",
                "llm_score": -254.43345642089844,
                "old_lm_score": -38.732421875,
                "acoustic_score": -85.61662292480469,
                "combined_score": -189.39125061035156
              },
              {
                "candidate": "two friends from a grateful heart",
                "llm_score": -249.0813446044922,
                "old_lm_score": -37.81640625,
                "acoustic_score": -87.49114990234375,
                "combined_score": -187.19445037841797
              },
              {
                "candidate": "two flags from a grateful heart",
                "llm_score": -254.55072021484375,
                "old_lm_score": -41.390625,
                "acoustic_score": -80.54045867919922,
                "combined_score": -188.24090194702148
              },
              {
                "candidate": "two spins from a grateful heart",
                "llm_score": -254.87225341796875,
                "old_lm_score": -43.85546875,
                "acoustic_score": -75.62640380859375,
                "combined_score": -187.17706298828125
              },
              {
                "candidate": "to plans from a grateful heart",
                "llm_score": -255.20606994628906,
                "old_lm_score": -42.3828125,
                "acoustic_score": -78.7472915649414,
                "combined_score": -188.16808700561523
              },
              {
                "candidate": "the pins from a grateful heart",
                "llm_score": -253.5520782470703,
                "old_lm_score": -37.630859375,
                "acoustic_score": -88.27667999267578,
                "combined_score": -189.72980880737305
              },
              {
                "candidate": "tool fans from a grateful heart",
                "llm_score": -259.69122314453125,
                "old_lm_score": -42.341796875,
                "acoustic_score": -79.01112365722656,
                "combined_score": -190.5220718383789
              },
              {
                "candidate": "two scenes from a grateful heart",
                "llm_score": -252.4745635986328,
                "old_lm_score": -38.9375,
                "acoustic_score": -85.85289001464844,
                "combined_score": -188.63247680664062
              },
              {
                "candidate": "to spans from a grateful heart",
                "llm_score": -258.2802734375,
                "old_lm_score": -44.0322265625,
                "acoustic_score": -75.66651153564453,
                "combined_score": -188.98950576782227
              },
              {
                "candidate": "to pings from a grateful heart",
                "llm_score": -257.6031188964844,
                "old_lm_score": -44.2197265625,
                "acoustic_score": -75.38481140136719,
                "combined_score": -188.60382843017578
              },
              {
                "candidate": "plans from a grateful heart",
                "llm_score": -249.92031860351562,
                "old_lm_score": -34.03515625,
                "acoustic_score": -95.78044128417969,
                "combined_score": -189.86795806884766
              },
              {
                "candidate": "pings from a grateful heart",
                "llm_score": -252.64096069335938,
                "old_lm_score": -35.74609375,
                "acoustic_score": -92.41796112060547,
                "combined_score": -190.40250778198242
              },
              {
                "candidate": "fins from a grateful heart",
                "llm_score": -252.12974548339844,
                "old_lm_score": -36.154296875,
                "acoustic_score": -91.61563110351562,
                "combined_score": -189.94983673095703
              },
              {
                "candidate": "scenes from a grateful heart",
                "llm_score": -250.96888732910156,
                "old_lm_score": -30.5302734375,
                "acoustic_score": -102.88603973388672,
                "combined_score": -192.19260025024414
              },
              {
                "candidate": "the plans from a grateful heart",
                "llm_score": -252.04600524902344,
                "old_lm_score": -36.501953125,
                "acoustic_score": -90.96634674072266,
                "combined_score": -189.75715255737305
              },
              {
                "candidate": "deux fins from a grateful heart",
                "llm_score": -263.5333557128906,
                "old_lm_score": -45.1826171875,
                "acoustic_score": -73.79010772705078,
                "combined_score": -191.2530403137207
              },
              {
                "candidate": "two pens from a grateful heart",
                "llm_score": -254.4026641845703,
                "old_lm_score": -42.6826171875,
                "acoustic_score": -78.86345672607422,
                "combined_score": -187.97436904907227
              },
              {
                "candidate": "spans from a grateful heart",
                "llm_score": -251.74322509765625,
                "old_lm_score": -35.884765625,
                "acoustic_score": -92.69966125488281,
                "combined_score": -190.16382598876953
              },
              {
                "candidate": "du finns from a grateful heart",
                "llm_score": -268.9502868652344,
                "old_lm_score": -45.3857421875,
                "acoustic_score": -73.79010772705078,
                "combined_score": -194.06306838989258
              },
              {
                "candidate": "fans from a little heart",
                "llm_score": -248.2140655517578,
                "old_lm_score": -34.6220703125,
                "acoustic_score": -95.3406982421875,
                "combined_score": -189.08841705322266
              },
              {
                "candidate": "pins from a grateful heart",
                "llm_score": -250.88433837890625,
                "old_lm_score": -35.7470703125,
                "acoustic_score": -93.09078216552734,
                "combined_score": -189.8610954284668
              },
              {
                "candidate": "two fans from a little heart",
                "llm_score": -252.1953582763672,
                "old_lm_score": -43.1611328125,
                "acoustic_score": -78.30754852294922,
                "combined_score": -186.8320198059082
              },
              {
                "candidate": "join fans from a grateful heart",
                "llm_score": -254.28472900390625,
                "old_lm_score": -41.556640625,
                "acoustic_score": -81.56990814208984,
                "combined_score": -188.70563888549805
              },
              {
                "candidate": "your fans from a grateful heart",
                "llm_score": -253.45135498046875,
                "old_lm_score": -40.5595703125,
                "acoustic_score": -83.57120513916016,
                "combined_score": -188.79106521606445
              },
              {
                "candidate": "two panes from a grateful heart",
                "llm_score": -254.93661499023438,
                "old_lm_score": -43.1181640625,
                "acoustic_score": -78.51502990722656,
                "combined_score": -188.28490447998047
              },
              {
                "candidate": "the finns from a grateful heart",
                "llm_score": -260.934814453125,
                "old_lm_score": -38.994140625,
                "acoustic_score": -86.8015365600586,
                "combined_score": -193.3652458190918
              },
              {
                "candidate": "tour plans from a grateful heart",
                "llm_score": -259.9270324707031,
                "old_lm_score": -44.2099609375,
                "acoustic_score": -76.4267349243164,
                "combined_score": -190.28186416625977
              },
              {
                "candidate": "dew fans from a grateful heart",
                "llm_score": -261.464111328125,
                "old_lm_score": -45.5478515625,
                "acoustic_score": -73.83021545410156,
                "combined_score": -190.42108917236328
              },
              {
                "candidate": "drew fans from a little heart",
                "llm_score": -261.84710693359375,
                "old_lm_score": -42.978515625,
                "acoustic_score": -78.98482513427734,
                "combined_score": -191.90522384643555
              },
              {
                "candidate": "the pings from a grateful heart",
                "llm_score": -255.14637756347656,
                "old_lm_score": -38.6943359375,
                "acoustic_score": -87.6038589477539,
                "combined_score": -190.72228622436523
              },
              {
                "candidate": "fans from a little hard",
                "llm_score": -248.92034912109375,
                "old_lm_score": -32.837890625,
                "acoustic_score": -99.3182601928711,
                "combined_score": -190.53824996948242
              },
              {
                "candidate": "springs from a grateful heart",
                "llm_score": -250.599365234375,
                "old_lm_score": -34.0791015625,
                "acoustic_score": -96.83796691894531,
                "combined_score": -190.75821685791016
              },
              {
                "candidate": "to springs from a grateful heart",
                "llm_score": -254.22540283203125,
                "old_lm_score": -42.5986328125,
                "acoustic_score": -79.80482482910156,
                "combined_score": -188.3144302368164
              },
              {
                "candidate": "two fans from a little hard",
                "llm_score": -252.83380126953125,
                "old_lm_score": -41.376953125,
                "acoustic_score": -82.28511047363281,
                "combined_score": -188.24793243408203
              },
              {
                "candidate": "two kids from a grateful heart",
                "llm_score": -250.3688201904297,
                "old_lm_score": -37.6962890625,
                "acoustic_score": -89.67436981201172,
                "combined_score": -188.8697395324707
              },
              {
                "candidate": "tour fans from a grateful heart",
                "llm_score": -260.85968017578125,
                "old_lm_score": -46.4580078125,
                "acoustic_score": -72.30203247070312,
                "combined_score": -189.8098602294922
              },
              {
                "candidate": "to fans from a digital art",
                "llm_score": -252.42478942871094,
                "old_lm_score": -41.7470703125,
                "acoustic_score": -81.7545166015625,
                "combined_score": -187.96318817138672
              },
              {
                "candidate": "dear fans from a grateful heart",
                "llm_score": -257.233154296875,
                "old_lm_score": -41.9296875,
                "acoustic_score": -81.44437408447266,
                "combined_score": -190.30360794067383
              },
              {
                "candidate": "drew fans from a little hard",
                "llm_score": -261.71722412109375,
                "old_lm_score": -41.1943359375,
                "acoustic_score": -82.96238708496094,
                "combined_score": -192.93697357177734
              },
              {
                "candidate": "pigs from a grateful heart",
                "llm_score": -253.36514282226562,
                "old_lm_score": -34.4970703125,
                "acoustic_score": -96.35909271240234,
                "combined_score": -192.11065292358398
              },
              {
                "candidate": "do fans from a little heart",
                "llm_score": -255.26084899902344,
                "old_lm_score": -43.9296875,
                "acoustic_score": -77.51517486572266,
                "combined_score": -188.35285568237305
              },
              {
                "candidate": "two kings from a grateful heart",
                "llm_score": -252.18060302734375,
                "old_lm_score": -40.9404296875,
                "acoustic_score": -83.52408599853516,
                "combined_score": -188.32255935668945
              },
              {
                "candidate": "to fines from a grateful heart",
                "llm_score": -260.2139587402344,
                "old_lm_score": -38.9736328125,
                "acoustic_score": -87.55870056152344,
                "combined_score": -193.3731460571289
              },
              {
                "candidate": "the scenes from a grateful heart",
                "llm_score": -252.90830993652344,
                "old_lm_score": -33.71875,
                "acoustic_score": -98.07194519042969,
                "combined_score": -192.34950256347656
              },
              {
                "candidate": "de finns from a grateful heart",
                "llm_score": -268.5189514160156,
                "old_lm_score": -43.109375,
                "acoustic_score": -79.3396987915039,
                "combined_score": -195.48401260375977
              },
              {
                "candidate": "yuri fans from a grateful heart",
                "llm_score": -261.620849609375,
                "old_lm_score": -43.279296875,
                "acoustic_score": -79.07858276367188,
                "combined_score": -191.98936462402344
              },
              {
                "candidate": "finn's from a grateful heart",
                "llm_score": -258.1615905761719,
                "old_lm_score": -37.0341796875,
                "acoustic_score": -91.61563110351562,
                "combined_score": -193.40570068359375
              },
              {
                "candidate": "to fins from a grateful heart",
                "llm_score": -257.9586486816406,
                "old_lm_score": -45.556640625,
                "acoustic_score": -74.58248138427734,
                "combined_score": -189.04888534545898
              },
              {
                "candidate": "do fans from a little hard",
                "llm_score": -255.535888671875,
                "old_lm_score": -42.1455078125,
                "acoustic_score": -81.49273681640625,
                "combined_score": -189.58706665039062
              },
              {
                "candidate": "crew fans from a grateful heart",
                "llm_score": -260.95123291015625,
                "old_lm_score": -42.0595703125,
                "acoustic_score": -81.6858901977539,
                "combined_score": -192.34834671020508
              },
              {
                "candidate": "der fans from a grateful heart",
                "llm_score": -261.553955078125,
                "old_lm_score": -44.5712890625,
                "acoustic_score": -76.6640396118164,
                "combined_score": -191.3946418762207
              },
              {
                "candidate": "deux pans from a grateful heart",
                "llm_score": -264.654541015625,
                "old_lm_score": -45.2509765625,
                "acoustic_score": -75.30536651611328,
                "combined_score": -192.60544204711914
              },
              {
                "candidate": "the springs from a grateful heart",
                "llm_score": -250.54754638671875,
                "old_lm_score": -36.904296875,
                "acoustic_score": -92.02387237548828,
                "combined_score": -189.73785781860352
              },
              {
                "candidate": "two wins from a grateful heart",
                "llm_score": -253.99618530273438,
                "old_lm_score": -37.8876953125,
                "acoustic_score": -90.09909057617188,
                "combined_score": -190.99148559570312
              },
              {
                "candidate": "two phones from a grateful heart",
                "llm_score": -256.508544921875,
                "old_lm_score": -40.2216796875,
                "acoustic_score": -85.4651107788086,
                "combined_score": -191.0976676940918
              },
              {
                "candidate": "d fans from a grateful heart",
                "llm_score": -254.58489990234375,
                "old_lm_score": -43.265625,
                "acoustic_score": -79.37980651855469,
                "combined_score": -188.61516571044922
              },
              {
                "candidate": "so fans from a grateful heart",
                "llm_score": -254.00869750976562,
                "old_lm_score": -40.00390625,
                "acoustic_score": -85.91081237792969,
                "combined_score": -189.96170806884766
              },
              {
                "candidate": "fangs from a grateful heart",
                "llm_score": -249.47637939453125,
                "old_lm_score": -37.474609375,
                "acoustic_score": -90.98291778564453,
                "combined_score": -188.9669532775879
              },
              {
                "candidate": "to pins from a grateful heart",
                "llm_score": -257.0943908691406,
                "old_lm_score": -44.974609375,
                "acoustic_score": -76.05763244628906,
                "combined_score": -189.06331634521484
              },
              {
                "candidate": "story spans from a grateful heart",
                "llm_score": -255.8753662109375,
                "old_lm_score": -42.642578125,
                "acoustic_score": -80.72320556640625,
                "combined_score": -189.62057495117188
              },
              {
                "candidate": "d pins from a grateful heart",
                "llm_score": -258.1598815917969,
                "old_lm_score": -42.607421875,
                "acoustic_score": -80.81484985351562,
                "combined_score": -190.79107666015625
              },
              {
                "candidate": "true finns from a grateful heart",
                "llm_score": -266.9351806640625,
                "old_lm_score": -44.994140625,
                "acoustic_score": -76.05213165283203,
                "combined_score": -193.99072647094727
              },
              {
                "candidate": "good fans from a grateful heart",
                "llm_score": -252.87661743164062,
                "old_lm_score": -44.640625,
                "acoustic_score": -76.78582763671875,
                "combined_score": -187.1515350341797
              },
              {
                "candidate": "flames from a grateful heart",
                "llm_score": -251.39456176757812,
                "old_lm_score": -32.2021484375,
                "acoustic_score": -101.72197723388672,
                "combined_score": -192.65934371948242
              },
              {
                "candidate": "see fans from a grateful heart",
                "llm_score": -256.7863464355469,
                "old_lm_score": -40.5595703125,
                "acoustic_score": -85.01864624023438,
                "combined_score": -191.18228149414062
              },
              {
                "candidate": "two bids from a grateful heart",
                "llm_score": -256.3023986816406,
                "old_lm_score": -38.81640625,
                "acoustic_score": -88.51512145996094,
                "combined_score": -191.81696319580078
              },
              {
                "candidate": "the pigs from a grateful heart",
                "llm_score": -255.78604125976562,
                "old_lm_score": -37.3017578125,
                "acoustic_score": -91.54499053955078,
                "combined_score": -192.3163948059082
              },
              {
                "candidate": "planes from a grateful heart",
                "llm_score": -248.7334747314453,
                "old_lm_score": -33.98046875,
                "acoustic_score": -98.1977310180664,
                "combined_score": -190.45583724975586
              },
              {
                "candidate": "more fans from a grateful heart",
                "llm_score": -255.5924835205078,
                "old_lm_score": -39.6201171875,
                "acoustic_score": -86.95249938964844,
                "combined_score": -191.08255004882812
              },
              {
                "candidate": "to planes from a grateful heart",
                "llm_score": -257.5360107421875,
                "old_lm_score": -42.56640625,
                "acoustic_score": -81.16458129882812,
                "combined_score": -190.6334991455078
              },
              {
                "candidate": "g fans from a grateful heart",
                "llm_score": -254.8710174560547,
                "old_lm_score": -43.15625,
                "acoustic_score": -80.06945037841797,
                "combined_score": -189.04835891723633
              }
            ],
            "selected": "two fans from a grateful heart",
            "selected_index": 2,
            "changed_from_top1": true,
            "change_was_correct": false
          },
          "time_ms": 2215.7747510000263
        }
      ],
      "total_time_ms": 2300.046031000079
    },
    {
      "sentence_idx": 30,
      "ground_truth": "char onion over grill never allow oil to smoke",
      "top1_hypothesis": "in over will never allow all to see",
      "final_decoded": "still in over will never allow all to see",
      "was_changed": true,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 3,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "in",
          "confusion_candidates": [
            {
              "word": "in",
              "weight": 0.20258773046936823
            },
            {
              "word": "win",
              "weight": 0.7974122695296316
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5039689208222166,
            "margin": 0.5948245390602633,
            "disagreement_mass": 0.20258773047036838
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(in OR win) over will never allow all",
            "retrieved_docs": [
              "He will allow a rare lie.",
              "Cyclical programs will never compile.",
              "Allow leeway here, but rationalize all errors.",
              "If you look all over in the other countries.",
              "Do they allow atheists in church?",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart"
            ],
            "scores": [
              11.520419811142757,
              10.224329120983942,
              9.88634082161866,
              9.431545540396591,
              9.314058529631325,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 10.119522999957553
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "over",
          "confusion_candidates": [
            {
              "word": "over",
              "weight": 0.9999999932793753
            },
            {
              "word": "of",
              "weight": 6.719624753137288e-09
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.3317009259739218e-07,
            "margin": 0.9999999865597505,
            "disagreement_mass": 6.720624723399737e-09
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "will",
          "confusion_candidates": [
            {
              "word": "will",
              "weight": 0.19918858546628912
            },
            {
              "word": "title",
              "weight": 0.7830640737124656
            },
            {
              "word": "trial",
              "weight": 0.017468048261509533
            },
            {
              "word": "kill",
              "weight": 5.565545295143403e-05
            },
            {
              "word": "cal",
              "weight": 3.8848705346941226e-05
            },
            {
              "word": "royal",
              "weight": 8.851045084064217e-06
            },
            {
              "word": "kyle",
              "weight": 0.00010974300835913125
            },
            {
              "word": "titles",
              "weight": 3.9419789100883466e-07
            },
            {
              "word": "tell",
              "weight": 6.279620229760044e-05
            },
            {
              "word": "real",
              "weight": 5.227629237624598e-07
            },
            {
              "word": "still",
              "weight": 2.8347818197949724e-09
            },
            {
              "word": "darrell",
              "weight": 2.4086157984945186e-06
            },
            {
              "word": "til",
              "weight": 6.973330152677402e-08
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5862790091381942,
            "margin": 0.5838754882461764,
            "disagreement_mass": 0.21693592628753444
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "in over (will OR title OR trial OR kill OR cal OR royal OR kyle OR titles OR tell OR real OR still OR darrell OR til) never allow all to see",
            "retrieved_docs": [
              "They will kill you.",
              "You will see them in management.",
              "He will allow a rare lie.",
              "Never been real thrilled.",
              "They never go to see them.",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart"
            ],
            "scores": [
              13.888154931919416,
              11.612435537464307,
              11.520419811142757,
              11.149445142804394,
              11.104598796579126,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 23.92882300000565
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "never",
          "confusion_candidates": [
            {
              "word": "never",
              "weight": 0.9999968858736112
            },
            {
              "word": "ever",
              "weight": 3.1141253887870225e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 4.2599866165445144e-05,
            "margin": 0.9999937717482225,
            "disagreement_mass": 3.1141263887590753e-06
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "allow",
          "confusion_candidates": [
            {
              "word": "allow",
              "weight": 0.8665867986451519
            },
            {
              "word": "at",
              "weight": 0.09192590934858609
            },
            {
              "word": "it",
              "weight": 0.04057444642212474
            },
            {
              "word": "really",
              "weight": 0.0009128421489923147
            },
            {
              "word": "eat",
              "weight": 3.4341448860938802e-09
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.4799099401745573,
            "margin": 0.7746608892965657,
            "disagreement_mass": 0.13341320135484813
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "all",
          "confusion_candidates": [
            {
              "word": "all",
              "weight": 0.15690644059348705
            },
            {
              "word": "oil",
              "weight": 0.8421336866029646
            },
            {
              "word": "her",
              "weight": 4.703065355599218e-05
            },
            {
              "word": "cool",
              "weight": 0.0009128421489923149
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.442157340460961,
            "margin": 0.6852272460094776,
            "disagreement_mass": 0.15786631339703538
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 7,
          "span_end": 8,
          "top1_word": "see",
          "confusion_candidates": [
            {
              "word": "see",
              "weight": 0.016142496002755025
            },
            {
              "word": "seek",
              "weight": 0.06896072586736332
            },
            {
              "word": "suck",
              "weight": 0.8767463358398988
            },
            {
              "word": "smoke",
              "weight": 0.024215274687913575
            },
            {
              "word": "some",
              "weight": 0.013933314895890909
            },
            {
              "word": "soak",
              "weight": 1.852705178198743e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5160174860820947,
            "margin": 0.8077856099725355,
            "disagreement_mass": 0.1232536641601012
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "will never allow all to (see OR seek OR suck OR smoke OR some OR soak)",
            "retrieved_docs": [
              "He will allow a rare lie.",
              "They never go to see them.",
              "You never see them.",
              "I never see that.",
              "Cyclical programs will never compile.",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart"
            ],
            "scores": [
              11.520419811142757,
              11.104598796579126,
              10.971529237500576,
              10.971529237500576,
              10.224329120983942,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 13.624235999941448
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 8,
          "top1_word": "in over will never allow all to see",
          "confusion_candidates": [
            {
              "word": "in over will never allow all to see",
              "weight": -236.82858276367188
            },
            {
              "word": "to win over title never at all to see",
              "weight": -238.5150146484375
            },
            {
              "word": "to win over will never allow all to see",
              "weight": -236.93339920043945
            },
            {
              "word": "to win over title never it all to see",
              "weight": -241.1906623840332
            },
            {
              "word": "in over will never allow all to seek",
              "weight": -237.1180877685547
            },
            {
              "word": "to win over title never at all to seek",
              "weight": -238.71607971191406
            },
            {
              "word": "in over trial never at all to see",
              "weight": -238.53600311279297
            },
            {
              "word": "to win over title never allow all to see",
              "weight": -240.51293182373047
            },
            {
              "word": "so in over will never allow all to see",
              "weight": -238.47019958496094
            },
            {
              "word": "to win over will never allow all to seek",
              "weight": -237.13129043579102
            },
            {
              "word": "in over kill never at all to see",
              "weight": -242.0872802734375
            },
            {
              "word": "goal in over will never allow all to see",
              "weight": -238.45372009277344
            },
            {
              "word": "to win over trial never at all to see",
              "weight": -237.12115478515625
            },
            {
              "word": "to in over will never allow all to see",
              "weight": -236.69037628173828
            },
            {
              "word": "in over will never allow oil to suck",
              "weight": -237.99747848510742
            },
            {
              "word": "go in over will never allow all to see",
              "weight": -236.71258163452148
            },
            {
              "word": "to win over title ever at all to see",
              "weight": -242.27626037597656
            },
            {
              "word": "to win over cal never at all to see",
              "weight": -240.55442810058594
            },
            {
              "word": "in over will never allow her to suck",
              "weight": -239.68553161621094
            },
            {
              "word": "to win over royal never at all to see",
              "weight": -243.61136627197266
            },
            {
              "word": "to win over kill never at all to see",
              "weight": -242.48804473876953
            },
            {
              "word": "in over will never allow oil to smoke",
              "weight": -237.92996978759766
            },
            {
              "word": "to win over will never allow oil to suck",
              "weight": -237.42759323120117
            },
            {
              "word": "to win over kyle never at all to see",
              "weight": -240.63844299316406
            },
            {
              "word": "to win over title never really cool to smoke",
              "weight": -244.27553939819336
            },
            {
              "word": "in over will never allow oil to some",
              "weight": -239.4435272216797
            },
            {
              "word": "in over titles never at all to see",
              "weight": -240.65184783935547
            },
            {
              "word": "two in over will never allow all to see",
              "weight": -237.80280303955078
            },
            {
              "word": "to win over will never allow her to suck",
              "weight": -239.24066925048828
            },
            {
              "word": "in of will never allow all to see",
              "weight": -238.9903564453125
            },
            {
              "word": "in over title never at all to see",
              "weight": -239.21114349365234
            },
            {
              "word": "in over tell never at all to see",
              "weight": -239.20443725585938
            },
            {
              "word": "to win over will never allow oil to smoke",
              "weight": -237.74748992919922
            },
            {
              "word": "in over will never allow all to suck",
              "weight": -237.49444580078125
            },
            {
              "word": "in over will never allow all to some",
              "weight": -237.22996520996094
            },
            {
              "word": "to win over title never at all to suck",
              "weight": -238.5074462890625
            },
            {
              "word": "to win over title never it all to seek",
              "weight": -242.23144912719727
            },
            {
              "word": "to win over will never allow oil to some",
              "weight": -239.10006713867188
            },
            {
              "word": "in over trial never it all to see",
              "weight": -240.85876846313477
            },
            {
              "word": "to win over title never at all to some",
              "weight": -237.02092361450195
            },
            {
              "word": "to win over tell never at all to see",
              "weight": -239.9426040649414
            },
            {
              "word": "still in over will never allow all to see",
              "weight": -235.44793319702148
            },
            {
              "word": "in over will never allow all to smoke",
              "weight": -237.28243255615234
            },
            {
              "word": "in over trial never at all to seek",
              "weight": -238.63121795654297
            },
            {
              "word": "to win over will never allow all to suck",
              "weight": -236.97404861450195
            },
            {
              "word": "to win over will never allow all to some",
              "weight": -237.4073715209961
            },
            {
              "word": "to win over title never at all to smoke",
              "weight": -239.71096420288086
            },
            {
              "word": "to win over title never allow all to seek",
              "weight": -240.57648468017578
            },
            {
              "word": "in over trial never allow all to see",
              "weight": -239.67351150512695
            },
            {
              "word": "in over kill never it all to see",
              "weight": -243.3599967956543
            },
            {
              "word": "so in over will never allow all to seek",
              "weight": -238.73013305664062
            },
            {
              "word": "toll in over will never allow all to see",
              "weight": -239.53431701660156
            },
            {
              "word": "to win over trial never it all to see",
              "weight": -239.9538803100586
            },
            {
              "word": "to win over real never at all to see",
              "weight": -241.20753479003906
            },
            {
              "word": "so in over trial never at all to see",
              "weight": -238.26072692871094
            },
            {
              "word": "in over kill never at all to seek",
              "weight": -242.1210479736328
            },
            {
              "word": "to win over will never allow all to smoke",
              "weight": -237.73220825195312
            },
            {
              "word": "goal in over will never allow all to seek",
              "weight": -238.75921630859375
            },
            {
              "word": "to win over trial never at all to seek",
              "weight": -237.27804565429688
            },
            {
              "word": "in of trial never at all to see",
              "weight": -239.45891571044922
            },
            {
              "word": "to win over cal never it all to see",
              "weight": -243.38370895385742
            },
            {
              "word": "to in over will never allow all to seek",
              "weight": -236.82917022705078
            },
            {
              "word": "to win over title never really cool to see",
              "weight": -243.57586669921875
            },
            {
              "word": "in over kill never allow all to see",
              "weight": -241.6764793395996
            },
            {
              "word": "to win over royal never it all to see",
              "weight": -245.81178283691406
            },
            {
              "word": "go in over will never allow all to seek",
              "weight": -237.20112228393555
            },
            {
              "word": "to win over trial never allow all to see",
              "weight": -239.01294708251953
            },
            {
              "word": "goal in over trial never at all to see",
              "weight": -240.05703735351562
            },
            {
              "word": "to win over title ever at all to seek",
              "weight": -241.91224670410156
            },
            {
              "word": "to win over kill never it all to see",
              "weight": -244.25582885742188
            },
            {
              "word": "to in over trial never at all to see",
              "weight": -237.76435089111328
            },
            {
              "word": "to win over cal never at all to seek",
              "weight": -240.75115966796875
            },
            {
              "word": "go in over trial never at all to see",
              "weight": -236.79199981689453
            },
            {
              "word": "to win over royal never at all to seek",
              "weight": -243.35718536376953
            },
            {
              "word": "so in over kill never at all to see",
              "weight": -241.96302032470703
            },
            {
              "word": "to win over title never allow oil to suck",
              "weight": -241.0081672668457
            },
            {
              "word": "to win over cal never allow all to see",
              "weight": -241.84746932983398
            },
            {
              "word": "to win over kyle never it all to see",
              "weight": -243.2841453552246
            },
            {
              "word": "to win over kill never at all to seek",
              "weight": -242.41751861572266
            },
            {
              "word": "in over still never at all to see",
              "weight": -240.22056579589844
            },
            {
              "word": "so in over will never allow oil to suck",
              "weight": -239.48844528198242
            },
            {
              "word": "to win over royal never allow all to see",
              "weight": -243.36346435546875
            },
            {
              "word": "in over titles never it all to see",
              "weight": -242.7379493713379
            },
            {
              "word": "to win over darrell never at all to see",
              "weight": -243.381103515625
            },
            {
              "word": "to win over kill never allow all to see",
              "weight": -242.4941864013672
            },
            {
              "word": "in over til never at all to see",
              "weight": -240.4006576538086
            },
            {
              "word": "to win over title never allow her to suck",
              "weight": -242.84133529663086
            },
            {
              "word": "in over will never allow oil to soak",
              "weight": -239.4549331665039
            },
            {
              "word": "goal in over kill never at all to see",
              "weight": -242.87859344482422
            },
            {
              "word": "in over will never eat all to see",
              "weight": -242.65655517578125
            },
            {
              "word": "in over title never it all to see",
              "weight": -240.76355361938477
            },
            {
              "word": "in over tell never it all to see",
              "weight": -239.96270370483398
            },
            {
              "word": "to in over kill never at all to see",
              "weight": -241.12351989746094
            },
            {
              "word": "to win over kyle never at all to seek",
              "weight": -240.88641357421875
            },
            {
              "word": "tool in over will never allow all to see",
              "weight": -239.23431015014648
            },
            {
              "word": "in over trial never really cool to smoke",
              "weight": -244.8381004333496
            },
            {
              "word": "so in over will never allow her to suck",
              "weight": -241.38075637817383
            },
            {
              "word": "goal in over will never allow oil to suck",
              "weight": -239.80154037475586
            },
            {
              "word": "in over titles never at all to seek",
              "weight": -241.1493911743164
            },
            {
              "word": "in over will never allow her to smoke",
              "weight": -240.51864624023438
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "He will allow a rare lie.",
              "Cyclical programs will never compile.",
              "Allow leeway here, but rationalize all errors.",
              "If you look all over in the other countries.",
              "Do they allow atheists in church?",
              "it's a package deal",
              "i have seen it",
              "the measure already passed a senate committee",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "They will kill you.",
              "You will see them in management.",
              "Never been real thrilled.",
              "They never go to see them.",
              "You never see them.",
              "I never see that."
            ],
            "retrieval_time_ms": 47.67258199990465
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "in over will never allow all to see",
                "llm_score": -298.39056396484375,
                "old_lm_score": -46.134765625,
                "acoustic_score": -129.1318359375,
                "combined_score": -236.82858276367188
              },
              {
                "candidate": "to win over title never at all to see",
                "llm_score": -309.83892822265625,
                "old_lm_score": -54.4013671875,
                "acoustic_score": -112.78973388671875,
                "combined_score": -238.5150146484375
              },
              {
                "candidate": "to win over will never allow all to see",
                "llm_score": -302.63323974609375,
                "old_lm_score": -50.732421875,
                "acoustic_score": -120.50113677978516,
                "combined_score": -236.93339920043945
              },
              {
                "candidate": "to win over title never it all to see",
                "llm_score": -317.2165222167969,
                "old_lm_score": -58.3994140625,
                "acoustic_score": -106.76538848876953,
                "combined_score": -241.1906623840332
              },
              {
                "candidate": "in over will never allow all to seek",
                "llm_score": -302.29815673828125,
                "old_lm_score": -51.70703125,
                "acoustic_score": -120.23098754882812,
                "combined_score": -237.1180877685547
              },
              {
                "candidate": "to win over title never at all to seek",
                "llm_score": -313.56964111328125,
                "old_lm_score": -59.9736328125,
                "acoustic_score": -103.88888549804688,
                "combined_score": -238.71607971191406
              },
              {
                "candidate": "in over trial never at all to see",
                "llm_score": -305.6097412109375,
                "old_lm_score": -52.3935546875,
                "acoustic_score": -119.06871032714844,
                "combined_score": -238.53600311279297
              },
              {
                "candidate": "to win over title never allow all to see",
                "llm_score": -314.8820495605469,
                "old_lm_score": -57.861328125,
                "acoustic_score": -108.28248596191406,
                "combined_score": -240.51293182373047
              },
              {
                "candidate": "so in over will never allow all to see",
                "llm_score": -306.7574768066406,
                "old_lm_score": -53.935546875,
                "acoustic_score": -116.24737548828125,
                "combined_score": -238.47019958496094
              },
              {
                "candidate": "to win over will never allow all to seek",
                "llm_score": -306.35760498046875,
                "old_lm_score": -56.3046875,
                "acoustic_score": -111.60028839111328,
                "combined_score": -237.13129043579102
              },
              {
                "candidate": "in over kill never at all to see",
                "llm_score": -307.081787109375,
                "old_lm_score": -47.263671875,
                "acoustic_score": -129.8291015625,
                "combined_score": -242.0872802734375
              },
              {
                "candidate": "goal in over will never allow all to see",
                "llm_score": -309.4261474609375,
                "old_lm_score": -56.9365234375,
                "acoustic_score": -110.54476928710938,
                "combined_score": -238.45372009277344
              },
              {
                "candidate": "to win over trial never at all to see",
                "llm_score": -306.8130798339844,
                "old_lm_score": -56.9912109375,
                "acoustic_score": -110.43801879882812,
                "combined_score": -237.12115478515625
              },
              {
                "candidate": "to in over will never allow all to see",
                "llm_score": -305.3231201171875,
                "old_lm_score": -56.4111328125,
                "acoustic_score": -111.64649963378906,
                "combined_score": -236.69037628173828
              },
              {
                "candidate": "in over will never allow oil to suck",
                "llm_score": -307.87677001953125,
                "old_lm_score": -56.384765625,
                "acoustic_score": -111.7334213256836,
                "combined_score": -237.99747848510742
              },
              {
                "candidate": "go in over will never allow all to see",
                "llm_score": -304.80712890625,
                "old_lm_score": -55.970703125,
                "acoustic_score": -112.64733123779297,
                "combined_score": -236.71258163452148
              },
              {
                "candidate": "to win over title ever at all to see",
                "llm_score": -309.9412841796875,
                "old_lm_score": -50.0263671875,
                "acoustic_score": -124.58486938476562,
                "combined_score": -242.27626037597656
              },
              {
                "candidate": "to win over cal never at all to see",
                "llm_score": -308.7130432128906,
                "old_lm_score": -52.3349609375,
                "acoustic_score": -120.06085205078125,
                "combined_score": -240.55442810058594
              },
              {
                "candidate": "in over will never allow her to suck",
                "llm_score": -301.69207763671875,
                "old_lm_score": -47.0810546875,
                "acoustic_score": -130.59793090820312,
                "combined_score": -239.68553161621094
              },
              {
                "candidate": "to win over royal never at all to see",
                "llm_score": -313.3477783203125,
                "old_lm_score": -50.9423828125,
                "acoustic_score": -122.93257141113281,
                "combined_score": -243.61136627197266
              },
              {
                "candidate": "to win over kill never at all to see",
                "llm_score": -311.9163513183594,
                "old_lm_score": -51.861328125,
                "acoustic_score": -121.19841003417969,
                "combined_score": -242.48804473876953
              },
              {
                "candidate": "in over will never allow oil to smoke",
                "llm_score": -307.1549072265625,
                "old_lm_score": -56.2353515625,
                "acoustic_score": -112.46968078613281,
                "combined_score": -237.92996978759766
              },
              {
                "candidate": "to win over will never allow oil to suck",
                "llm_score": -310.7700500488281,
                "old_lm_score": -60.982421875,
                "acoustic_score": -103.10271453857422,
                "combined_score": -237.42759323120117
              },
              {
                "candidate": "to win over kyle never at all to see",
                "llm_score": -309.9947509765625,
                "old_lm_score": -53.9072265625,
                "acoustic_score": -117.37490844726562,
                "combined_score": -240.63844299316406
              },
              {
                "candidate": "to win over title never really cool to smoke",
                "llm_score": -322.9700012207031,
                "old_lm_score": -59.6240234375,
                "acoustic_score": -105.9570541381836,
                "combined_score": -244.27553939819336
              },
              {
                "candidate": "in over will never allow oil to some",
                "llm_score": -309.33734130859375,
                "old_lm_score": -55.7001953125,
                "acoustic_score": -113.84951782226562,
                "combined_score": -239.4435272216797
              },
              {
                "candidate": "in over titles never at all to see",
                "llm_score": -304.39251708984375,
                "old_lm_score": -48.37890625,
                "acoustic_score": -128.5322723388672,
                "combined_score": -240.65184783935547
              },
              {
                "candidate": "two in over will never allow all to see",
                "llm_score": -307.1251220703125,
                "old_lm_score": -56.833984375,
                "acoustic_score": -111.64649963378906,
                "combined_score": -237.80280303955078
              },
              {
                "candidate": "to win over will never allow her to suck",
                "llm_score": -304.83538818359375,
                "old_lm_score": -51.6787109375,
                "acoustic_score": -121.96723937988281,
                "combined_score": -239.24066925048828
              },
              {
                "candidate": "in of will never allow all to see",
                "llm_score": -296.1987609863281,
                "old_lm_score": -43.62109375,
                "acoustic_score": -138.16085815429688,
                "combined_score": -238.9903564453125
              },
              {
                "candidate": "in over title never at all to see",
                "llm_score": -305.0028381347656,
                "old_lm_score": -51.9990234375,
                "acoustic_score": -121.42042541503906,
                "combined_score": -239.21114349365234
              },
              {
                "candidate": "in over tell never at all to see",
                "llm_score": -305.99072265625,
                "old_lm_score": -53.0009765625,
                "acoustic_score": -119.41717529296875,
                "combined_score": -239.20443725585938
              },
              {
                "candidate": "to win over will never allow oil to smoke",
                "llm_score": -310.822998046875,
                "old_lm_score": -60.8330078125,
                "acoustic_score": -103.83897399902344,
                "combined_score": -237.74748992919922
              },
              {
                "candidate": "in over will never allow all to suck",
                "llm_score": -305.0528259277344,
                "old_lm_score": -55.6806640625,
                "acoustic_score": -114.25540161132812,
                "combined_score": -237.49444580078125
              },
              {
                "candidate": "in over will never allow all to some",
                "llm_score": -303.45269775390625,
                "old_lm_score": -54.6357421875,
                "acoustic_score": -116.37149047851562,
                "combined_score": -237.22996520996094
              },
              {
                "candidate": "to win over title never at all to suck",
                "llm_score": -315.1543273925781,
                "old_lm_score": -63.947265625,
                "acoustic_score": -97.91329956054688,
                "combined_score": -238.5074462890625
              },
              {
                "candidate": "to win over title never it all to seek",
                "llm_score": -322.6266784667969,
                "old_lm_score": -63.9716796875,
                "acoustic_score": -97.86454010009766,
                "combined_score": -242.23144912719727
              },
              {
                "candidate": "to win over will never allow oil to some",
                "llm_score": -312.6834716796875,
                "old_lm_score": -60.2978515625,
                "acoustic_score": -105.21881103515625,
                "combined_score": -239.10006713867188
              },
              {
                "candidate": "in over trial never it all to see",
                "llm_score": -312.28155517578125,
                "old_lm_score": -56.3916015625,
                "acoustic_score": -113.04438018798828,
                "combined_score": -240.85876846313477
              },
              {
                "candidate": "to win over title never at all to some",
                "llm_score": -311.110107421875,
                "old_lm_score": -62.90234375,
                "acoustic_score": -100.0293960571289,
                "combined_score": -237.02092361450195
              },
              {
                "candidate": "to win over tell never at all to see",
                "llm_score": -311.5000915527344,
                "old_lm_score": -57.5986328125,
                "acoustic_score": -110.78648376464844,
                "combined_score": -239.9426040649414
              },
              {
                "candidate": "still in over will never allow all to see",
                "llm_score": -302.49273681640625,
                "old_lm_score": -57.6064453125,
                "acoustic_score": -110.79668426513672,
                "combined_score": -235.44793319702148
              },
              {
                "candidate": "in over will never allow all to smoke",
                "llm_score": -304.0419616699219,
                "old_lm_score": -55.53125,
                "acoustic_score": -114.99165344238281,
                "combined_score": -237.28243255615234
              },
              {
                "candidate": "in over trial never at all to seek",
                "llm_score": -309.1287536621094,
                "old_lm_score": -57.9658203125,
                "acoustic_score": -110.16786193847656,
                "combined_score": -238.63121795654297
              },
              {
                "candidate": "to win over will never allow all to suck",
                "llm_score": -308.0450744628906,
                "old_lm_score": -60.2783203125,
                "acoustic_score": -105.62470245361328,
                "combined_score": -236.97404861450195
              },
              {
                "candidate": "to win over will never allow all to some",
                "llm_score": -307.8405456542969,
                "old_lm_score": -59.2333984375,
                "acoustic_score": -107.74079895019531,
                "combined_score": -237.4073715209961
              },
              {
                "candidate": "to win over title never at all to smoke",
                "llm_score": -316.9745178222656,
                "old_lm_score": -63.7978515625,
                "acoustic_score": -98.6495590209961,
                "combined_score": -239.71096420288086
              },
              {
                "candidate": "to win over title never allow all to seek",
                "llm_score": -318.3377380371094,
                "old_lm_score": -63.43359375,
                "acoustic_score": -99.38163757324219,
                "combined_score": -240.57648468017578
              },
              {
                "candidate": "in over trial never allow all to see",
                "llm_score": -308.9320373535156,
                "old_lm_score": -55.853515625,
                "acoustic_score": -114.56147003173828,
                "combined_score": -239.67351150512695
              },
              {
                "candidate": "in over kill never it all to see",
                "llm_score": -311.65350341796875,
                "old_lm_score": -51.26171875,
                "acoustic_score": -123.80477142333984,
                "combined_score": -243.3599967956543
              },
              {
                "candidate": "so in over will never allow all to seek",
                "llm_score": -310.6059265136719,
                "old_lm_score": -59.5078125,
                "acoustic_score": -107.34652709960938,
                "combined_score": -238.73013305664062
              },
              {
                "candidate": "toll in over will never allow all to see",
                "llm_score": -311.1551513671875,
                "old_lm_score": -58.46484375,
                "acoustic_score": -109.44863891601562,
                "combined_score": -239.53431701660156
              },
              {
                "candidate": "to win over trial never it all to see",
                "llm_score": -314.50482177734375,
                "old_lm_score": -60.9892578125,
                "acoustic_score": -104.41368103027344,
                "combined_score": -239.9538803100586
              },
              {
                "candidate": "to win over real never at all to see",
                "llm_score": -309.383056640625,
                "old_lm_score": -53.5224609375,
                "acoustic_score": -119.50955200195312,
                "combined_score": -241.20753479003906
              },
              {
                "candidate": "so in over trial never at all to see",
                "llm_score": -310.1428527832031,
                "old_lm_score": -60.1943359375,
                "acoustic_score": -106.18426513671875,
                "combined_score": -238.26072692871094
              },
              {
                "candidate": "in over kill never at all to seek",
                "llm_score": -310.4779052734375,
                "old_lm_score": -52.8359375,
                "acoustic_score": -120.92825317382812,
                "combined_score": -242.1210479736328
              },
              {
                "candidate": "to win over will never allow all to smoke",
                "llm_score": -308.97454833984375,
                "old_lm_score": -60.12890625,
                "acoustic_score": -106.3609619140625,
                "combined_score": -237.73220825195312
              },
              {
                "candidate": "goal in over will never allow all to seek",
                "llm_score": -313.36572265625,
                "old_lm_score": -62.5087890625,
                "acoustic_score": -101.6439208984375,
                "combined_score": -238.75921630859375
              },
              {
                "candidate": "to win over trial never at all to seek",
                "llm_score": -310.4554443359375,
                "old_lm_score": -62.5634765625,
                "acoustic_score": -101.53717041015625,
                "combined_score": -237.27804565429688
              },
              {
                "candidate": "in of trial never at all to see",
                "llm_score": -301.5193176269531,
                "old_lm_score": -49.30078125,
                "acoustic_score": -128.0977325439453,
                "combined_score": -239.45891571044922
              },
              {
                "candidate": "to win over cal never it all to see",
                "llm_score": -316.39788818359375,
                "old_lm_score": -56.3330078125,
                "acoustic_score": -114.0365219116211,
                "combined_score": -243.38370895385742
              },
              {
                "candidate": "to in over will never allow all to seek",
                "llm_score": -308.9292907714844,
                "old_lm_score": -61.9833984375,
                "acoustic_score": -102.74565124511719,
                "combined_score": -236.82917022705078
              },
              {
                "candidate": "to win over title never really cool to see",
                "llm_score": -313.72540283203125,
                "old_lm_score": -53.3291015625,
                "acoustic_score": -120.09722900390625,
                "combined_score": -243.57586669921875
              },
              {
                "candidate": "in over kill never allow all to see",
                "llm_score": -307.3074645996094,
                "old_lm_score": -50.7236328125,
                "acoustic_score": -125.32186126708984,
                "combined_score": -241.6764793395996
              },
              {
                "candidate": "to win over royal never it all to see",
                "llm_score": -319.77490234375,
                "old_lm_score": -54.9404296875,
                "acoustic_score": -116.90823364257812,
                "combined_score": -245.81178283691406
              },
              {
                "candidate": "go in over will never allow all to seek",
                "llm_score": -309.11279296875,
                "old_lm_score": -61.54296875,
                "acoustic_score": -103.7464828491211,
                "combined_score": -237.20112228393555
              },
              {
                "candidate": "to win over trial never allow all to see",
                "llm_score": -311.6439514160156,
                "old_lm_score": -60.451171875,
                "acoustic_score": -105.93077087402344,
                "combined_score": -239.01294708251953
              },
              {
                "candidate": "goal in over trial never at all to see",
                "llm_score": -316.4371032714844,
                "old_lm_score": -63.1953125,
                "acoustic_score": -100.48165893554688,
                "combined_score": -240.05703735351562
              },
              {
                "candidate": "to win over title ever at all to seek",
                "llm_score": -312.5418395996094,
                "old_lm_score": -55.5986328125,
                "acoustic_score": -115.68402099609375,
                "combined_score": -241.91224670410156
              },
              {
                "candidate": "to win over kill never it all to see",
                "llm_score": -317.47821044921875,
                "old_lm_score": -55.859375,
                "acoustic_score": -115.174072265625,
                "combined_score": -244.25582885742188
              },
              {
                "candidate": "to in over trial never at all to see",
                "llm_score": -311.275390625,
                "old_lm_score": -62.669921875,
                "acoustic_score": -101.58338928222656,
                "combined_score": -237.76435089111328
              },
              {
                "candidate": "to win over cal never at all to seek",
                "llm_score": -312.4350891113281,
                "old_lm_score": -57.9072265625,
                "acoustic_score": -111.16000366210938,
                "combined_score": -240.75115966796875
              },
              {
                "candidate": "go in over trial never at all to see",
                "llm_score": -308.7702941894531,
                "old_lm_score": -62.2294921875,
                "acoustic_score": -102.58421325683594,
                "combined_score": -236.79199981689453
              },
              {
                "candidate": "to win over royal never at all to seek",
                "llm_score": -316.1679992675781,
                "old_lm_score": -56.5146484375,
                "acoustic_score": -114.03172302246094,
                "combined_score": -243.35718536376953
              },
              {
                "candidate": "so in over kill never at all to see",
                "llm_score": -311.91693115234375,
                "old_lm_score": -55.064453125,
                "acoustic_score": -116.94465637207031,
                "combined_score": -241.96302032470703
              },
              {
                "candidate": "to win over title never allow oil to suck",
                "llm_score": -323.02093505859375,
                "old_lm_score": -68.111328125,
                "acoustic_score": -90.88407135009766,
                "combined_score": -241.0081672668457
              },
              {
                "candidate": "to win over cal never allow all to see",
                "llm_score": -312.3464050292969,
                "old_lm_score": -55.794921875,
                "acoustic_score": -115.5536117553711,
                "combined_score": -241.84746932983398
              },
              {
                "candidate": "to win over kyle never it all to see",
                "llm_score": -317.31243896484375,
                "old_lm_score": -57.9052734375,
                "acoustic_score": -111.35057830810547,
                "combined_score": -243.2841453552246
              },
              {
                "candidate": "to win over kill never at all to seek",
                "llm_score": -315.1038818359375,
                "old_lm_score": -57.43359375,
                "acoustic_score": -112.29756164550781,
                "combined_score": -242.41751861572266
              },
              {
                "candidate": "in over still never at all to see",
                "llm_score": -302.19195556640625,
                "old_lm_score": -48.927734375,
                "acoustic_score": -129.32144165039062,
                "combined_score": -240.22056579589844
              },
              {
                "candidate": "so in over will never allow oil to suck",
                "llm_score": -315.9423828125,
                "old_lm_score": -64.185546875,
                "acoustic_score": -98.84896087646484,
                "combined_score": -239.48844528198242
              },
              {
                "candidate": "to win over royal never allow all to see",
                "llm_score": -313.8992614746094,
                "old_lm_score": -54.40234375,
                "acoustic_score": -118.42532348632812,
                "combined_score": -243.36346435546875
              },
              {
                "candidate": "in over titles never it all to see",
                "llm_score": -310.59100341796875,
                "old_lm_score": -52.376953125,
                "acoustic_score": -122.50794219970703,
                "combined_score": -242.7379493713379
              },
              {
                "candidate": "to win over darrell never at all to see",
                "llm_score": -315.25787353515625,
                "old_lm_score": -55.78125,
                "acoustic_score": -115.72308349609375,
                "combined_score": -243.381103515625
              },
              {
                "candidate": "to win over kill never allow all to see",
                "llm_score": -312.9759216308594,
                "old_lm_score": -55.3212890625,
                "acoustic_score": -116.691162109375,
                "combined_score": -242.4941864013672
              },
              {
                "candidate": "in over til never at all to see",
                "llm_score": -305.7548522949219,
                "old_lm_score": -52.3017578125,
                "acoustic_score": -122.74470520019531,
                "combined_score": -240.4006576538086
              },
              {
                "candidate": "to win over title never allow her to suck",
                "llm_score": -317.12646484375,
                "old_lm_score": -58.8076171875,
                "acoustic_score": -109.74858856201172,
                "combined_score": -242.84133529663086
              },
              {
                "candidate": "in over will never allow oil to soak",
                "llm_score": -307.14312744140625,
                "old_lm_score": -55.6005859375,
                "acoustic_score": -116.16615295410156,
                "combined_score": -239.4549331665039
              },
              {
                "candidate": "goal in over kill never at all to see",
                "llm_score": -316.44970703125,
                "old_lm_score": -58.0654296875,
                "acoustic_score": -111.24205017089844,
                "combined_score": -242.87859344482422
              },
              {
                "candidate": "in over will never eat all to see",
                "llm_score": -307.2557373046875,
                "old_lm_score": -49.31640625,
                "acoustic_score": -128.740966796875,
                "combined_score": -242.65655517578125
              },
              {
                "candidate": "in over title never it all to see",
                "llm_score": -310.1339416503906,
                "old_lm_score": -55.9970703125,
                "acoustic_score": -115.3960952758789,
                "combined_score": -240.76355361938477
              },
              {
                "candidate": "in over tell never it all to see",
                "llm_score": -309.5335388183594,
                "old_lm_score": -56.9990234375,
                "acoustic_score": -113.3928451538086,
                "combined_score": -239.96270370483398
              },
              {
                "candidate": "to in over kill never at all to see",
                "llm_score": -312.36322021484375,
                "old_lm_score": -57.5400390625,
                "acoustic_score": -112.34378051757812,
                "combined_score": -241.12351989746094
              },
              {
                "candidate": "to win over kyle never at all to seek",
                "llm_score": -313.81927490234375,
                "old_lm_score": -59.4794921875,
                "acoustic_score": -108.47406005859375,
                "combined_score": -240.88641357421875
              },
              {
                "candidate": "tool in over will never allow all to see",
                "llm_score": -309.9705810546875,
                "old_lm_score": -58.9541015625,
                "acoustic_score": -109.54393768310547,
                "combined_score": -239.23431015014648
              },
              {
                "candidate": "in over trial never really cool to smoke",
                "llm_score": -319.8239440917969,
                "old_lm_score": -57.6162109375,
                "acoustic_score": -112.23604583740234,
                "combined_score": -244.8381004333496
              },
              {
                "candidate": "so in over will never allow her to suck",
                "llm_score": -310.16619873046875,
                "old_lm_score": -54.8818359375,
                "acoustic_score": -117.7134780883789,
                "combined_score": -241.38075637817383
              },
              {
                "candidate": "goal in over will never allow oil to suck",
                "llm_score": -319.27020263671875,
                "old_lm_score": -67.1865234375,
                "acoustic_score": -93.14635467529297,
                "combined_score": -239.80154037475586
              },
              {
                "candidate": "in over titles never at all to seek",
                "llm_score": -308.7161865234375,
                "old_lm_score": -53.951171875,
                "acoustic_score": -119.63142395019531,
                "combined_score": -241.1493911743164
              },
              {
                "candidate": "in over will never allow her to smoke",
                "llm_score": -301.6025085449219,
                "old_lm_score": -48.1005859375,
                "acoustic_score": -131.33419799804688,
                "combined_score": -240.51864624023438
              }
            ],
            "selected": "still in over will never allow all to see",
            "selected_index": 41,
            "changed_from_top1": true,
            "change_was_correct": false
          },
          "time_ms": 2304.6570629999223
        }
      ],
      "total_time_ms": 2359.974008999984
    },
    {
      "sentence_idx": 31,
      "ground_truth": "noise causes air pollution",
      "top1_hypothesis": "no cause cause air pollution",
      "final_decoded": "no cause cause air pollution",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 3.089240000008431
    },
    {
      "sentence_idx": 32,
      "ground_truth": "and then you sprinkle the cheese on top of that",
      "top1_hypothesis": "and then you people the case on top of that",
      "final_decoded": "and then you people the case on top of that",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 9.198242000024948
    },
    {
      "sentence_idx": 33,
      "ground_truth": "just saying that clear vision is a necessity",
      "top1_hypothesis": "just seeing that clear vision is a necessity",
      "final_decoded": "just seeing that clear vision is a necessity",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "seeing",
          "confusion_candidates": [
            {
              "word": "seeing",
              "weight": 0.9418094957598832
            },
            {
              "word": "saying",
              "weight": 0.058180059037002775
            },
            {
              "word": "sing",
              "weight": 1.044520211390144e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.22205986399115096,
            "margin": 0.8836294367228804,
            "disagreement_mass": 0.05819050424011685
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "clear",
          "confusion_candidates": [
            {
              "word": "clear",
              "weight": 0.09659527528536496
            },
            {
              "word": "klare",
              "weight": 0.6975814309376521
            },
            {
              "word": "care",
              "weight": 0.0354860137521205
            },
            {
              "word": "their",
              "weight": 4.5985466553800347e-07
            },
            {
              "word": "claire",
              "weight": 0.11102842099499821
            },
            {
              "word": "core",
              "weight": 0.00040658521660812336
            },
            {
              "word": "car",
              "weight": 0.0003649327872879792
            },
            {
              "word": "clare",
              "weight": 0.0378493701303302
            },
            {
              "word": "clearer",
              "weight": 9.987799207434128e-05
            },
            {
              "word": "klar",
              "weight": 0.0016430147688434908
            },
            {
              "word": "clair",
              "weight": 0.018773427957868516
            },
            {
              "word": "kerry",
              "weight": 2.5766602474932495e-05
            },
            {
              "word": "your",
              "weight": 2.1125308538465882e-10
            },
            {
              "word": "clary",
              "weight": 0.00014481978397063531
            },
            {
              "word": "court",
              "weight": 1.9735694660137398e-08
            },
            {
              "word": "carrey",
              "weight": 5.839877927411316e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.0571397112237666,
            "margin": 0.5865530099426539,
            "disagreement_mass": 0.3024185690623479
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "just seeing that (clear OR klare OR care OR their OR claire OR core OR car OR clare OR clearer OR klar OR clair OR kerry OR your OR clary OR court OR carrey) vision is a necessity",
            "retrieved_docs": [
              "Your car is fine and everything.",
              "Seeing their natures as equally void.",
              "This is the vision that we have.",
              "A clear division arose.",
              "It's not clear to me that it is really a problem.",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that"
            ],
            "scores": [
              12.903551905738926,
              12.506788981946382,
              11.53189421397876,
              11.186942801189016,
              10.874132980740665,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 29.11692399993626
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "vision",
          "confusion_candidates": [
            {
              "word": "vision",
              "weight": 0.9987920107973693
            },
            {
              "word": "version",
              "weight": 0.001207274767941558
            },
            {
              "word": "visions",
              "weight": 7.14433689031411e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.00932951945379849,
            "margin": 0.9975847360294278,
            "disagreement_mass": 0.001207989202630655
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "is",
          "confusion_candidates": [
            {
              "word": "is",
              "weight": 0.9999997300628004
            },
            {
              "word": "as",
              "weight": 2.6993619956116126e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 4.3527418314532995e-06,
            "margin": 0.9999994601266008,
            "disagreement_mass": 2.6993719959289564e-07
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 7,
          "span_end": 8,
          "top1_word": "necessity",
          "confusion_candidates": [
            {
              "word": "necessity",
              "weight": 0.9769784330297249
            },
            {
              "word": "disparity",
              "weight": 0.02302156696927491
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.10957629702712936,
            "margin": 0.9539568660604499,
            "disagreement_mass": 0.02302156697027513
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 8,
          "top1_word": "just seeing that clear vision is a necessity",
          "confusion_candidates": [
            {
              "word": "just seeing that clear vision is a necessity",
              "weight": -184.25885772705078
            },
            {
              "word": "just saying that clear vision is a necessity",
              "weight": -184.69155883789062
            },
            {
              "word": "just seeing that klare vision is a necessity",
              "weight": -191.81143188476562
            },
            {
              "word": "just seeing that care vision is a necessity",
              "weight": -190.05131912231445
            },
            {
              "word": "just seeing that their vision is a necessity",
              "weight": -190.03320693969727
            },
            {
              "word": "just saying that klare vision is a necessity",
              "weight": -192.00027084350586
            },
            {
              "word": "just seeing that claire vision is a necessity",
              "weight": -193.34591674804688
            },
            {
              "word": "just saying that care vision is a necessity",
              "weight": -190.07408142089844
            },
            {
              "word": "just seeing that core vision is a necessity",
              "weight": -189.2332763671875
            },
            {
              "word": "just saying that their vision is a necessity",
              "weight": -190.75311279296875
            },
            {
              "word": "just seeing that car vision is a necessity",
              "weight": -188.5037498474121
            },
            {
              "word": "just seeing that clear vision is a disparity",
              "weight": -188.40573120117188
            },
            {
              "word": "just seeing that clare vision is a necessity",
              "weight": -194.02378845214844
            },
            {
              "word": "just seeing that clearer vision is a necessity",
              "weight": -188.93370056152344
            },
            {
              "word": "just saying that claire vision is a necessity",
              "weight": -193.7988395690918
            },
            {
              "word": "just saying that core vision is a necessity",
              "weight": -190.14191055297852
            },
            {
              "word": "just seeing that klar vision is a necessity",
              "weight": -193.70394897460938
            },
            {
              "word": "just seeing that clair vision is a necessity",
              "weight": -194.4154815673828
            },
            {
              "word": "just seeing that car version is a necessity",
              "weight": -192.66351699829102
            },
            {
              "word": "just seeing that core version is a necessity",
              "weight": -194.77303314208984
            },
            {
              "word": "just seeing that claire version is a necessity",
              "weight": -196.4532470703125
            },
            {
              "word": "just saying that clear vision is a disparity",
              "weight": -189.27088165283203
            },
            {
              "word": "just seeing that clear version is a necessity",
              "weight": -191.8962860107422
            },
            {
              "word": "just seeing that klare vision is a disparity",
              "weight": -195.3592300415039
            },
            {
              "word": "just saying that clare vision is a necessity",
              "weight": -194.12859725952148
            },
            {
              "word": "just saying that clearer vision is a necessity",
              "weight": -188.59604263305664
            },
            {
              "word": "just saying that klar vision is a necessity",
              "weight": -193.94377517700195
            },
            {
              "word": "just seeing that care vision is a disparity",
              "weight": -193.91515731811523
            },
            {
              "word": "just seeing that their version is a necessity",
              "weight": -195.03762817382812
            },
            {
              "word": "just saying that clair vision is a necessity",
              "weight": -194.28059005737305
            },
            {
              "word": "just saying that kerry vision is a necessity",
              "weight": -195.89659118652344
            },
            {
              "word": "just seeing that care version is a necessity",
              "weight": -195.30339431762695
            },
            {
              "word": "just seeing that clare version is a necessity",
              "weight": -196.77244567871094
            },
            {
              "word": "just seeing that your vision is a necessity",
              "weight": -193.42584991455078
            },
            {
              "word": "just saying that core version is a necessity",
              "weight": -195.4938087463379
            },
            {
              "word": "just saying that claire version is a necessity",
              "weight": -196.99062728881836
            },
            {
              "word": "just seeing that clear vision as a necessity",
              "weight": -191.4993133544922
            },
            {
              "word": "just saying that clear version is a necessity",
              "weight": -193.21070098876953
            },
            {
              "word": "just saying that your vision is a necessity",
              "weight": -193.82293319702148
            },
            {
              "word": "just seeing that their vision is a disparity",
              "weight": -191.74836349487305
            },
            {
              "word": "just saying that klare vision is a disparity",
              "weight": -195.44971084594727
            },
            {
              "word": "just saying that car vision is a necessity",
              "weight": -189.93061065673828
            },
            {
              "word": "just seeing that clair version is a necessity",
              "weight": -197.4323272705078
            },
            {
              "word": "just seeing that kerry vision is a necessity",
              "weight": -196.6326446533203
            },
            {
              "word": "just sing that clear vision is a necessity",
              "weight": -193.05758666992188
            },
            {
              "word": "just seeing that clary vision is a necessity",
              "weight": -194.25600814819336
            },
            {
              "word": "just saying that their version is a necessity",
              "weight": -196.32127380371094
            },
            {
              "word": "just seeing that claire vision is a disparity",
              "weight": -196.66706085205078
            },
            {
              "word": "just saying that care vision is a disparity",
              "weight": -194.35535430908203
            },
            {
              "word": "just seeing that core vision is a disparity",
              "weight": -193.05437469482422
            },
            {
              "word": "just seeing that court vision is a necessity",
              "weight": -196.30909729003906
            },
            {
              "word": "just seeing that carrey version is a necessity",
              "weight": -199.96974182128906
            },
            {
              "word": "just saying that care version is a necessity",
              "weight": -195.82669067382812
            },
            {
              "word": "just seeing that clear visions is a necessity",
              "weight": -193.26171875
            },
            {
              "word": "just saying that clare version is a necessity",
              "weight": -197.4371452331543
            },
            {
              "word": "just saying that their vision is a disparity",
              "weight": -192.94268035888672
            },
            {
              "word": "just seeing that car vision is a disparity",
              "weight": -192.21844863891602
            },
            {
              "word": "just saying that clear vision as a necessity",
              "weight": -193.81393814086914
            },
            {
              "word": "just seeing that clare vision is a disparity",
              "weight": -197.60184478759766
            },
            {
              "word": "just saying that clair version is a necessity",
              "weight": -197.8643913269043
            },
            {
              "word": "just saying that car version is a necessity",
              "weight": -194.6724624633789
            },
            {
              "word": "just saying that kerry version is a necessity",
              "weight": -198.976806640625
            },
            {
              "word": "just seeing that clearer vision is a disparity",
              "weight": -193.33651733398438
            },
            {
              "word": "just saying that claire vision is a disparity",
              "weight": -196.94971084594727
            },
            {
              "word": "just saying that core vision is a disparity",
              "weight": -193.80097579956055
            },
            {
              "word": "just seeing that klar vision is a disparity",
              "weight": -197.1225357055664
            },
            {
              "word": "just saying that clear visions is a necessity",
              "weight": -193.4816436767578
            },
            {
              "word": "just seeing that clair vision is a disparity",
              "weight": -198.08716583251953
            },
            {
              "word": "just seeing that kerry version is a necessity",
              "weight": -199.10350036621094
            },
            {
              "word": "just seeing that clary version is a necessity",
              "weight": -198.76284408569336
            },
            {
              "word": "just seeing that car version is a disparity",
              "weight": -195.93873977661133
            },
            {
              "word": "just seeing that core version is a disparity",
              "weight": -198.19908142089844
            },
            {
              "word": "just seeing that claire version is a disparity",
              "weight": -199.6961441040039
            },
            {
              "word": "just seeing that clear version is a disparity",
              "weight": -195.64855194091797
            },
            {
              "word": "just saying that clare vision is a disparity",
              "weight": -197.80427932739258
            },
            {
              "word": "just saying that clearer vision is a disparity",
              "weight": -194.12937545776367
            },
            {
              "word": "just saying that klar vision is a disparity",
              "weight": -197.3447151184082
            },
            {
              "word": "just seeing that their version is a disparity",
              "weight": -197.23247528076172
            },
            {
              "word": "just saying that clair vision is a disparity",
              "weight": -197.69710159301758
            },
            {
              "word": "just saying that kerry vision is a disparity",
              "weight": -198.96289825439453
            },
            {
              "word": "just seeing that care version is a disparity",
              "weight": -198.95989608764648
            },
            {
              "word": "just seeing that clare version is a disparity",
              "weight": -200.1298599243164
            },
            {
              "word": "just seeing that your vision is a disparity",
              "weight": -195.1037368774414
            },
            {
              "word": "just saying that core version is a disparity",
              "weight": -199.29912948608398
            },
            {
              "word": "just saying that claire version is a disparity",
              "weight": -200.84216690063477
            },
            {
              "word": "just saying that clear version is a disparity",
              "weight": -197.55264282226562
            },
            {
              "word": "just saying that your vision is a disparity",
              "weight": -195.96120071411133
            },
            {
              "word": "just saying that car vision is a disparity",
              "weight": -193.36810302734375
            },
            {
              "word": "just seeing that clair version is a disparity",
              "weight": -200.7691879272461
            },
            {
              "word": "just seeing that kerry vision is a disparity",
              "weight": -199.88362884521484
            },
            {
              "word": "just sing that clear vision is a disparity",
              "weight": -196.83106994628906
            },
            {
              "word": "just seeing that clary vision is a disparity",
              "weight": -197.93098831176758
            },
            {
              "word": "just saying that their version is a disparity",
              "weight": -199.1145782470703
            },
            {
              "word": "just seeing that court vision is a disparity",
              "weight": -199.9097900390625
            },
            {
              "word": "just seeing that carrey version is a disparity",
              "weight": -203.1292495727539
            },
            {
              "word": "just saying that care version is a disparity",
              "weight": -200.29776763916016
            },
            {
              "word": "just seeing that clear visions is a disparity",
              "weight": -197.32981872558594
            },
            {
              "word": "just saying that clare version is a disparity",
              "weight": -201.53837966918945
            },
            {
              "word": "just saying that clair version is a disparity",
              "weight": -201.8411750793457
            },
            {
              "word": "just saying that car version is a disparity",
              "weight": -198.32876586914062
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "Your car is fine and everything.",
              "Seeing their natures as equally void.",
              "This is the vision that we have.",
              "A clear division arose.",
              "It's not clear to me that it is really a problem.",
              "they told me that this was a topic",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that"
            ],
            "retrieval_time_ms": 29.11692399993626
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "just seeing that clear vision is a necessity",
                "llm_score": -242.45445251464844,
                "old_lm_score": -51.171875,
                "acoustic_score": -74.89138793945312,
                "combined_score": -184.25885772705078
              },
              {
                "candidate": "just saying that clear vision is a necessity",
                "llm_score": -240.53591918945312,
                "old_lm_score": -51.0732421875,
                "acoustic_score": -77.77395629882812,
                "combined_score": -184.69155883789062
              },
              {
                "candidate": "just seeing that klare vision is a necessity",
                "llm_score": -259.5370178222656,
                "old_lm_score": -56.1923828125,
                "acoustic_score": -67.89346313476562,
                "combined_score": -191.81143188476562
              },
              {
                "candidate": "just seeing that care vision is a necessity",
                "llm_score": -253.03759765625,
                "old_lm_score": -54.4609375,
                "acoustic_score": -72.6041030883789,
                "combined_score": -190.05131912231445
              },
              {
                "candidate": "just seeing that their vision is a necessity",
                "llm_score": -241.73550415039062,
                "old_lm_score": -44.5888671875,
                "acoustic_score": -93.7420425415039,
                "combined_score": -190.03320693969727
              },
              {
                "candidate": "just saying that klare vision is a necessity",
                "llm_score": -257.1307678222656,
                "old_lm_score": -56.09375,
                "acoustic_score": -70.7760238647461,
                "combined_score": -192.00027084350586
              },
              {
                "candidate": "just seeing that claire vision is a necessity",
                "llm_score": -260.7612609863281,
                "old_lm_score": -58.037109375,
                "acoustic_score": -67.89346313476562,
                "combined_score": -193.34591674804688
              },
              {
                "candidate": "just saying that care vision is a necessity",
                "llm_score": -250.2991943359375,
                "old_lm_score": -54.3623046875,
                "acoustic_score": -75.48666381835938,
                "combined_score": -190.07408142089844
              },
              {
                "candidate": "just seeing that core vision is a necessity",
                "llm_score": -246.9250946044922,
                "old_lm_score": -52.7314453125,
                "acoustic_score": -78.81001281738281,
                "combined_score": -189.2332763671875
              },
              {
                "candidate": "just saying that their vision is a necessity",
                "llm_score": -240.56716918945312,
                "old_lm_score": -44.314453125,
                "acoustic_score": -96.62460327148438,
                "combined_score": -190.75311279296875
              },
              {
                "candidate": "just seeing that car vision is a necessity",
                "llm_score": -245.40211486816406,
                "old_lm_score": -53.69921875,
                "acoustic_score": -77.90616607666016,
                "combined_score": -188.5037498474121
              },
              {
                "candidate": "just seeing that clear vision is a disparity",
                "llm_score": -247.0001678466797,
                "old_lm_score": -55.9208984375,
                "acoustic_score": -73.89039611816406,
                "combined_score": -188.40573120117188
              },
              {
                "candidate": "just seeing that clare vision is a necessity",
                "llm_score": -261.04083251953125,
                "old_lm_score": -59.11328125,
                "acoustic_score": -67.89346313476562,
                "combined_score": -194.02378845214844
              },
              {
                "candidate": "just seeing that clearer vision is a necessity",
                "llm_score": -244.9301300048828,
                "old_lm_score": -53.4423828125,
                "acoustic_score": -79.49488830566406,
                "combined_score": -188.93370056152344
              },
              {
                "candidate": "just saying that claire vision is a necessity",
                "llm_score": -258.8831787109375,
                "old_lm_score": -57.9384765625,
                "acoustic_score": -70.7760238647461,
                "combined_score": -193.7988395690918
              },
              {
                "candidate": "just saying that core vision is a necessity",
                "llm_score": -245.95843505859375,
                "old_lm_score": -52.6328125,
                "acoustic_score": -81.69257354736328,
                "combined_score": -190.14191055297852
              },
              {
                "candidate": "just seeing that klar vision is a necessity",
                "llm_score": -257.2709655761719,
                "old_lm_score": -56.94140625,
                "acoustic_score": -73.19552612304688,
                "combined_score": -193.70394897460938
              },
              {
                "candidate": "just seeing that clair vision is a necessity",
                "llm_score": -261.123046875,
                "old_lm_score": -59.814453125,
                "acoustic_score": -67.89346313476562,
                "combined_score": -194.4154815673828
              },
              {
                "candidate": "just seeing that car version is a necessity",
                "llm_score": -249.4412841796875,
                "old_lm_score": -52.4501953125,
                "acoustic_score": -83.43555450439453,
                "combined_score": -192.66351699829102
              },
              {
                "candidate": "just seeing that core version is a necessity",
                "llm_score": -253.1842041015625,
                "old_lm_score": -52.0224609375,
                "acoustic_score": -84.33940124511719,
                "combined_score": -194.77303314208984
              },
              {
                "candidate": "just seeing that claire version is a necessity",
                "llm_score": -262.002197265625,
                "old_lm_score": -57.4814453125,
                "acoustic_score": -73.4228515625,
                "combined_score": -196.4532470703125
              },
              {
                "candidate": "just saying that clear vision is a disparity",
                "llm_score": -245.946533203125,
                "old_lm_score": -55.822265625,
                "acoustic_score": -76.77296447753906,
                "combined_score": -189.27088165283203
              },
              {
                "candidate": "just seeing that clear version is a necessity",
                "llm_score": -249.25949096679688,
                "old_lm_score": -54.1123046875,
                "acoustic_score": -80.4207763671875,
                "combined_score": -191.8962860107422
              },
              {
                "candidate": "just seeing that klare vision is a disparity",
                "llm_score": -262.88458251953125,
                "old_lm_score": -60.94140625,
                "acoustic_score": -66.89247131347656,
                "combined_score": -195.3592300415039
              },
              {
                "candidate": "just saying that clare vision is a necessity",
                "llm_score": -258.4665222167969,
                "old_lm_score": -59.0146484375,
                "acoustic_score": -70.7760238647461,
                "combined_score": -194.12859725952148
              },
              {
                "candidate": "just saying that clearer vision is a necessity",
                "llm_score": -241.47088623046875,
                "old_lm_score": -53.34375,
                "acoustic_score": -82.37744903564453,
                "combined_score": -188.59604263305664
              },
              {
                "candidate": "just saying that klar vision is a necessity",
                "llm_score": -254.96669006347656,
                "old_lm_score": -56.8427734375,
                "acoustic_score": -76.07808685302734,
                "combined_score": -193.94377517700195
              },
              {
                "candidate": "just seeing that care vision is a disparity",
                "llm_score": -257.0172424316406,
                "old_lm_score": -59.2099609375,
                "acoustic_score": -71.60311126708984,
                "combined_score": -193.91515731811523
              },
              {
                "candidate": "just seeing that their version is a necessity",
                "llm_score": -245.38096618652344,
                "old_lm_score": -45.4228515625,
                "acoustic_score": -99.27143859863281,
                "combined_score": -195.03762817382812
              },
              {
                "candidate": "just saying that clair vision is a necessity",
                "llm_score": -258.0693359375,
                "old_lm_score": -59.7158203125,
                "acoustic_score": -70.7760238647461,
                "combined_score": -194.28059005737305
              },
              {
                "candidate": "just saying that kerry vision is a necessity",
                "llm_score": -256.5409851074219,
                "old_lm_score": -55.0224609375,
                "acoustic_score": -80.229736328125,
                "combined_score": -195.89659118652344
              },
              {
                "candidate": "just seeing that care version is a necessity",
                "llm_score": -256.2975158691406,
                "old_lm_score": -56.17578125,
                "acoustic_score": -78.13349151611328,
                "combined_score": -195.30339431762695
              },
              {
                "candidate": "just seeing that clare version is a necessity",
                "llm_score": -261.5644226074219,
                "old_lm_score": -58.5576171875,
                "acoustic_score": -73.4228515625,
                "combined_score": -196.77244567871094
              },
              {
                "candidate": "just seeing that your vision is a necessity",
                "llm_score": -240.72642517089844,
                "old_lm_score": -44.8857421875,
                "acoustic_score": -101.23953247070312,
                "combined_score": -193.42584991455078
              },
              {
                "candidate": "just saying that core version is a necessity",
                "llm_score": -251.84182739257812,
                "old_lm_score": -51.923828125,
                "acoustic_score": -87.22196197509766,
                "combined_score": -195.4938087463379
              },
              {
                "candidate": "just saying that claire version is a necessity",
                "llm_score": -260.29302978515625,
                "old_lm_score": -57.3828125,
                "acoustic_score": -76.30541229248047,
                "combined_score": -196.99062728881836
              },
              {
                "candidate": "just seeing that clear vision as a necessity",
                "llm_score": -244.17112731933594,
                "old_lm_score": -52.431640625,
                "acoustic_score": -86.39585876464844,
                "combined_score": -191.4993133544922
              },
              {
                "candidate": "just saying that clear version is a necessity",
                "llm_score": -249.10438537597656,
                "old_lm_score": -54.013671875,
                "acoustic_score": -83.3033447265625,
                "combined_score": -193.21070098876953
              },
              {
                "candidate": "just saying that your vision is a necessity",
                "llm_score": -239.90658569335938,
                "old_lm_score": -43.6171875,
                "acoustic_score": -104.1220932006836,
                "combined_score": -193.82293319702148
              },
              {
                "candidate": "just seeing that their vision is a disparity",
                "llm_score": -241.41778564453125,
                "old_lm_score": -49.337890625,
                "acoustic_score": -92.74105072021484,
                "combined_score": -191.74836349487305
              },
              {
                "candidate": "just saying that klare vision is a disparity",
                "llm_score": -260.2816162109375,
                "old_lm_score": -60.8427734375,
                "acoustic_score": -69.77503204345703,
                "combined_score": -195.44971084594727
              },
              {
                "candidate": "just saying that car vision is a necessity",
                "llm_score": -243.66526794433594,
                "old_lm_score": -55.4072265625,
                "acoustic_score": -80.78872680664062,
                "combined_score": -189.93061065673828
              },
              {
                "candidate": "just seeing that clair version is a necessity",
                "llm_score": -262.1830139160156,
                "old_lm_score": -59.2587890625,
                "acoustic_score": -73.4228515625,
                "combined_score": -197.4323272705078
              },
              {
                "candidate": "just seeing that kerry vision is a necessity",
                "llm_score": -258.5753479003906,
                "old_lm_score": -57.3427734375,
                "acoustic_score": -77.34716796875,
                "combined_score": -196.6326446533203
              },
              {
                "candidate": "just sing that clear vision is a necessity",
                "llm_score": -250.9800567626953,
                "old_lm_score": -57.244140625,
                "acoustic_score": -77.89097595214844,
                "combined_score": -193.05758666992188
              },
              {
                "candidate": "just seeing that clary vision is a necessity",
                "llm_score": -255.99951171875,
                "old_lm_score": -59.8759765625,
                "acoustic_score": -72.63652801513672,
                "combined_score": -194.25600814819336
              },
              {
                "candidate": "just saying that their version is a necessity",
                "llm_score": -245.34011840820312,
                "old_lm_score": -45.1484375,
                "acoustic_score": -102.15399169921875,
                "combined_score": -196.32127380371094
              },
              {
                "candidate": "just seeing that claire vision is a disparity",
                "llm_score": -263.655517578125,
                "old_lm_score": -62.7861328125,
                "acoustic_score": -66.89247131347656,
                "combined_score": -196.66706085205078
              },
              {
                "candidate": "just saying that care vision is a disparity",
                "llm_score": -255.11370849609375,
                "old_lm_score": -59.111328125,
                "acoustic_score": -74.48567199707031,
                "combined_score": -194.35535430908203
              },
              {
                "candidate": "just seeing that core vision is a disparity",
                "llm_score": -250.8192596435547,
                "old_lm_score": -57.48046875,
                "acoustic_score": -77.80902099609375,
                "combined_score": -193.05437469482422
              },
              {
                "candidate": "just seeing that court vision is a necessity",
                "llm_score": -251.21160888671875,
                "old_lm_score": -51.5234375,
                "acoustic_score": -89.88314819335938,
                "combined_score": -196.30909729003906
              },
              {
                "candidate": "just seeing that carrey version is a necessity",
                "llm_score": -261.92034912109375,
                "old_lm_score": -55.142578125,
                "acoustic_score": -82.87655639648438,
                "combined_score": -199.96974182128906
              },
              {
                "candidate": "just saying that care version is a necessity",
                "llm_score": -254.5601806640625,
                "old_lm_score": -56.0771484375,
                "acoustic_score": -81.01605224609375,
                "combined_score": -195.82669067382812
              },
              {
                "candidate": "just seeing that clear visions is a necessity",
                "llm_score": -248.6472930908203,
                "old_lm_score": -55.33984375,
                "acoustic_score": -82.53630065917969,
                "combined_score": -193.26171875
              },
              {
                "candidate": "just saying that clare version is a necessity",
                "llm_score": -260.1098937988281,
                "old_lm_score": -58.458984375,
                "acoustic_score": -76.30541229248047,
                "combined_score": -197.4371452331543
              },
              {
                "candidate": "just saying that their vision is a disparity",
                "llm_score": -241.19827270507812,
                "old_lm_score": -49.0634765625,
                "acoustic_score": -95.62361145019531,
                "combined_score": -192.94268035888672
              },
              {
                "candidate": "just seeing that car vision is a disparity",
                "llm_score": -249.08348083496094,
                "old_lm_score": -58.4482421875,
                "acoustic_score": -76.9051742553711,
                "combined_score": -192.21844863891602
              },
              {
                "candidate": "just saying that clear vision as a necessity",
                "llm_score": -246.01644897460938,
                "old_lm_score": -52.3330078125,
                "acoustic_score": -89.2784194946289,
                "combined_score": -193.81393814086914
              },
              {
                "candidate": "just seeing that clare vision is a disparity",
                "llm_score": -264.44891357421875,
                "old_lm_score": -63.8623046875,
                "acoustic_score": -66.89247131347656,
                "combined_score": -197.60184478759766
              },
              {
                "candidate": "just saying that clair version is a necessity",
                "llm_score": -260.2632141113281,
                "old_lm_score": -59.16015625,
                "acoustic_score": -76.30541229248047,
                "combined_score": -197.8643913269043
              },
              {
                "candidate": "just saying that car version is a necessity",
                "llm_score": -248.8686065673828,
                "old_lm_score": -54.158203125,
                "acoustic_score": -86.318115234375,
                "combined_score": -194.6724624633789
              },
              {
                "candidate": "just saying that kerry version is a necessity",
                "llm_score": -257.7276916503906,
                "old_lm_score": -54.466796875,
                "acoustic_score": -85.75912475585938,
                "combined_score": -198.976806640625
              },
              {
                "candidate": "just seeing that clearer vision is a disparity",
                "llm_score": -249.98773193359375,
                "old_lm_score": -58.19140625,
                "acoustic_score": -78.493896484375,
                "combined_score": -193.33651733398438
              },
              {
                "candidate": "just saying that claire vision is a disparity",
                "llm_score": -261.4368896484375,
                "old_lm_score": -62.6875,
                "acoustic_score": -69.77503204345703,
                "combined_score": -196.94971084594727
              },
              {
                "candidate": "just saying that core vision is a disparity",
                "llm_score": -249.52853393554688,
                "old_lm_score": -57.3818359375,
                "acoustic_score": -80.69158172607422,
                "combined_score": -193.80097579956055
              },
              {
                "candidate": "just seeing that klar vision is a disparity",
                "llm_score": -260.360107421875,
                "old_lm_score": -61.6904296875,
                "acoustic_score": -72.19453430175781,
                "combined_score": -197.1225357055664
              },
              {
                "candidate": "just saying that clear visions is a necessity",
                "llm_score": -246.30320739746094,
                "old_lm_score": -55.2412109375,
                "acoustic_score": -85.41886901855469,
                "combined_score": -193.4816436767578
              },
              {
                "candidate": "just seeing that clair vision is a disparity",
                "llm_score": -264.7183837890625,
                "old_lm_score": -64.5634765625,
                "acoustic_score": -66.89247131347656,
                "combined_score": -198.08716583251953
              },
              {
                "candidate": "just seeing that kerry version is a necessity",
                "llm_score": -258.5433349609375,
                "old_lm_score": -56.787109375,
                "acoustic_score": -82.87655639648438,
                "combined_score": -199.10350036621094
              },
              {
                "candidate": "just seeing that clary version is a necessity",
                "llm_score": -260.0394592285156,
                "old_lm_score": -59.3203125,
                "acoustic_score": -78.1659164428711,
                "combined_score": -198.76284408569336
              },
              {
                "candidate": "just seeing that car version is a disparity",
                "llm_score": -252.2436981201172,
                "old_lm_score": -57.19921875,
                "acoustic_score": -82.43456268310547,
                "combined_score": -195.93873977661133
              },
              {
                "candidate": "just seeing that core version is a disparity",
                "llm_score": -256.28826904296875,
                "old_lm_score": -56.771484375,
                "acoustic_score": -83.33840942382812,
                "combined_score": -198.19908142089844
              },
              {
                "candidate": "just seeing that claire version is a disparity",
                "llm_score": -264.7399597167969,
                "old_lm_score": -62.23046875,
                "acoustic_score": -72.42185974121094,
                "combined_score": -199.6961441040039
              },
              {
                "candidate": "just seeing that clear version is a disparity",
                "llm_score": -253.0159912109375,
                "old_lm_score": -58.861328125,
                "acoustic_score": -79.41978454589844,
                "combined_score": -195.64855194091797
              },
              {
                "candidate": "just saying that clare vision is a disparity",
                "llm_score": -262.0698547363281,
                "old_lm_score": -63.763671875,
                "acoustic_score": -69.77503204345703,
                "combined_score": -197.80427932739258
              },
              {
                "candidate": "just saying that clearer vision is a disparity",
                "llm_score": -248.78952026367188,
                "old_lm_score": -58.0927734375,
                "acoustic_score": -81.37645721435547,
                "combined_score": -194.12937545776367
              },
              {
                "candidate": "just saying that klar vision is a disparity",
                "llm_score": -258.0205383300781,
                "old_lm_score": -61.591796875,
                "acoustic_score": -75.07709503173828,
                "combined_score": -197.3447151184082
              },
              {
                "candidate": "just seeing that their version is a disparity",
                "llm_score": -246.0226287841797,
                "old_lm_score": -50.171875,
                "acoustic_score": -98.27044677734375,
                "combined_score": -197.23247528076172
              },
              {
                "candidate": "just saying that clair vision is a disparity",
                "llm_score": -261.1543273925781,
                "old_lm_score": -64.46484375,
                "acoustic_score": -69.77503204345703,
                "combined_score": -197.69710159301758
              },
              {
                "candidate": "just saying that kerry vision is a disparity",
                "llm_score": -258.9255676269531,
                "old_lm_score": -59.771484375,
                "acoustic_score": -79.22874450683594,
                "combined_score": -198.96289825439453
              },
              {
                "candidate": "just seeing that care version is a disparity",
                "llm_score": -259.86248779296875,
                "old_lm_score": -60.9248046875,
                "acoustic_score": -77.13249969482422,
                "combined_score": -198.95989608764648
              },
              {
                "candidate": "just seeing that clare version is a disparity",
                "llm_score": -264.5312194824219,
                "old_lm_score": -63.306640625,
                "acoustic_score": -72.42185974121094,
                "combined_score": -200.1298599243164
              },
              {
                "candidate": "just seeing that your vision is a disparity",
                "llm_score": -240.33416748046875,
                "old_lm_score": -49.634765625,
                "acoustic_score": -100.23854064941406,
                "combined_score": -195.1037368774414
              },
              {
                "candidate": "just saying that core version is a disparity",
                "llm_score": -255.70443725585938,
                "old_lm_score": -56.6728515625,
                "acoustic_score": -86.2209701538086,
                "combined_score": -199.29912948608398
              },
              {
                "candidate": "just saying that claire version is a disparity",
                "llm_score": -264.2480773925781,
                "old_lm_score": -62.1318359375,
                "acoustic_score": -75.3044204711914,
                "combined_score": -200.84216690063477
              },
              {
                "candidate": "just saying that clear version is a disparity",
                "llm_score": -254.0402374267578,
                "old_lm_score": -58.7626953125,
                "acoustic_score": -82.30235290527344,
                "combined_score": -197.55264282226562
              },
              {
                "candidate": "just saying that your vision is a disparity",
                "llm_score": -240.43508911132812,
                "old_lm_score": -48.3662109375,
                "acoustic_score": -103.12110137939453,
                "combined_score": -195.96120071411133
              },
              {
                "candidate": "just saying that car vision is a disparity",
                "llm_score": -246.79222106933594,
                "old_lm_score": -60.15625,
                "acoustic_score": -79.78773498535156,
                "combined_score": -193.36810302734375
              },
              {
                "candidate": "just seeing that clair version is a disparity",
                "llm_score": -265.10870361328125,
                "old_lm_score": -64.0078125,
                "acoustic_score": -72.42185974121094,
                "combined_score": -200.7691879272461
              },
              {
                "candidate": "just seeing that kerry vision is a disparity",
                "llm_score": -261.32928466796875,
                "old_lm_score": -62.091796875,
                "acoustic_score": -76.34617614746094,
                "combined_score": -199.88362884521484
              },
              {
                "candidate": "just sing that clear vision is a disparity",
                "llm_score": -254.77899169921875,
                "old_lm_score": -61.9931640625,
                "acoustic_score": -76.88998413085938,
                "combined_score": -196.83106994628906
              },
              {
                "candidate": "just seeing that clary vision is a disparity",
                "llm_score": -259.6014404296875,
                "old_lm_score": -64.625,
                "acoustic_score": -71.63553619384766,
                "combined_score": -197.93098831176758
              },
              {
                "candidate": "just saying that their version is a disparity",
                "llm_score": -247.17869567871094,
                "old_lm_score": -49.8974609375,
                "acoustic_score": -101.15299987792969,
                "combined_score": -199.1145782470703
              },
              {
                "candidate": "just seeing that court vision is a disparity",
                "llm_score": -254.6649627685547,
                "old_lm_score": -56.2724609375,
                "acoustic_score": -88.88215637207031,
                "combined_score": -199.9097900390625
              },
              {
                "candidate": "just seeing that carrey version is a disparity",
                "llm_score": -264.4913330078125,
                "old_lm_score": -59.8916015625,
                "acoustic_score": -81.87556457519531,
                "combined_score": -203.1292495727539
              },
              {
                "candidate": "just saying that care version is a disparity",
                "llm_score": -259.7543029785156,
                "old_lm_score": -60.826171875,
                "acoustic_score": -80.01506042480469,
                "combined_score": -200.29776763916016
              },
              {
                "candidate": "just seeing that clear visions is a disparity",
                "llm_score": -253.03546142578125,
                "old_lm_score": -60.0888671875,
                "acoustic_score": -81.53530883789062,
                "combined_score": -197.32981872558594
              },
              {
                "candidate": "just saying that clare version is a disparity",
                "llm_score": -264.5643310546875,
                "old_lm_score": -63.2080078125,
                "acoustic_score": -75.3044204711914,
                "combined_score": -201.53837966918945
              },
              {
                "candidate": "just saying that clair version is a disparity",
                "llm_score": -264.46875,
                "old_lm_score": -63.9091796875,
                "acoustic_score": -75.3044204711914,
                "combined_score": -201.8411750793457
              },
              {
                "candidate": "just saying that car version is a disparity",
                "llm_score": -252.4331817626953,
                "old_lm_score": -58.9072265625,
                "acoustic_score": -85.31712341308594,
                "combined_score": -198.32876586914062
              }
            ],
            "selected": "just seeing that clear vision is a necessity",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 2178.8858190000155
        }
      ],
      "total_time_ms": 2214.955626999995
    },
    {
      "sentence_idx": 34,
      "ground_truth": "factors that affect earnings of an employee",
      "top1_hypothesis": "factors that affect earnings of an employee",
      "final_decoded": "factors that affect earnings of an employee",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 0,
          "span_end": 1,
          "top1_word": "factors",
          "confusion_candidates": [
            {
              "word": "factors",
              "weight": 0.999978416614535
            },
            {
              "word": "factor",
              "weight": 2.1583384464969928e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0002534661144833043,
            "margin": 0.99995683323007,
            "disagreement_mass": 2.158338546498495e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 2,
          "span_end": 3,
          "top1_word": "affect",
          "confusion_candidates": [
            {
              "word": "affect",
              "weight": 0.9949482969970883
            },
            {
              "word": "affects",
              "weight": 0.0001389376331502229
            },
            {
              "word": "effect",
              "weight": 0.004912765368761543
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.03238875341854938,
            "margin": 0.9900355316283268,
            "disagreement_mass": 0.005051703002911689
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "earnings",
          "confusion_candidates": [
            {
              "word": "earnings",
              "weight": 0.5706719116579482
            },
            {
              "word": "learning",
              "weight": 0.2902963346036965
            },
            {
              "word": "joining",
              "weight": 0.09503529030911584
            },
            {
              "word": "running",
              "weight": 0.0006881805727173664
            },
            {
              "word": "journey",
              "weight": 0.0007133650931601588
            },
            {
              "word": "earning",
              "weight": 0.030406853424989184
            },
            {
              "word": "turning",
              "weight": 0.0049992738897450305
            },
            {
              "word": "warning",
              "weight": 5.032088301977899e-05
            },
            {
              "word": "any",
              "weight": 5.018166256860653e-07
            },
            {
              "word": "burning",
              "weight": 5.7403398560015373e-05
            },
            {
              "word": "dawning",
              "weight": 0.0001409911908921655
            },
            {
              "word": "inning",
              "weight": 7.780483272604578e-05
            },
            {
              "word": "cunning",
              "weight": 0.00016462802951034414
            },
            {
              "word": "churning",
              "weight": 0.0006357204777894742
            },
            {
              "word": "awning",
              "weight": 0.0001333930961032031
            },
            {
              "word": "yearning",
              "weight": 0.0005619016345118679
            },
            {
              "word": "ending",
              "weight": 6.566858617936841e-06
            },
            {
              "word": "jennings",
              "weight": 0.00043374039710693116
            },
            {
              "word": "on",
              "weight": 4.391353106977491e-08
            },
            {
              "word": "journeying",
              "weight": 0.0048964733576490225
            },
            {
              "word": "signing",
              "weight": 1.3095720084550966e-06
            },
            {
              "word": "journeys",
              "weight": 1.5911429922798432e-05
            },
            {
              "word": "funding",
              "weight": 1.0457594328376792e-07
            },
            {
              "word": "tuning",
              "weight": 1.131539282616335e-05
            },
            {
              "word": "warnings",
              "weight": 6.595902835256586e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.0900930742730408,
            "margin": 0.28037557705425165,
            "disagreement_mass": 0.42932808834205183
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "factors that affect (earnings OR learning OR joining OR running OR journey OR earning OR turning OR warning OR any OR burning OR dawning OR inning OR cunning OR churning OR awning OR yearning OR ending OR jennings OR on OR journeying OR signing OR journeys OR funding OR tuning OR warnings) of an employee",
            "retrieved_docs": [
              "Without any warning whatsoever.",
              "They're burning that diesel fuel.",
              "I'm kind of learning this.",
              "Employee controller.",
              "Joining mining pool.",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity"
            ],
            "scores": [
              15.83057978852026,
              11.752546983345932,
              10.829961530175169,
              10.399786066351336,
              9.912589744530077,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 38.078300999927706
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 6,
          "span_end": 7,
          "top1_word": "employee",
          "confusion_candidates": [
            {
              "word": "employee",
              "weight": 0.9999897958299631
            },
            {
              "word": "employee's",
              "weight": 1.0204169036814081e-05
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0001274777142820376,
            "margin": 0.9999795916609262,
            "disagreement_mass": 1.0204170036942628e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 7,
          "top1_word": "factors that affect earnings of an employee",
          "confusion_candidates": [
            {
              "word": "factors that affect earnings of an employee",
              "weight": -154.94967460632324
            },
            {
              "word": "factors that affect learning of an employee",
              "weight": -158.0819969177246
            },
            {
              "word": "factors that affect joining of an employee",
              "weight": -160.27666091918945
            },
            {
              "word": "factors that affect running of an employee",
              "weight": -160.92280197143555
            },
            {
              "word": "factors that affect journey of an employee",
              "weight": -161.5102767944336
            },
            {
              "word": "factors that affect earning of an employee",
              "weight": -157.8867473602295
            },
            {
              "word": "factors that affect turning of an employee",
              "weight": -160.93259048461914
            },
            {
              "word": "factors that affect warning of an employee",
              "weight": -164.38940048217773
            },
            {
              "word": "factors that affect any of an employee",
              "weight": -163.21258163452148
            },
            {
              "word": "factors that affect burning of an employee",
              "weight": -162.77665328979492
            },
            {
              "word": "factors that affect dawning of an employee",
              "weight": -166.57959938049316
            },
            {
              "word": "factors that affect inning of an employee",
              "weight": -168.56685638427734
            },
            {
              "word": "factors that affect cunning of an employee",
              "weight": -163.49246788024902
            },
            {
              "word": "factors that affect churning of an employee",
              "weight": -163.62245178222656
            },
            {
              "word": "factors that affect awning of an employee",
              "weight": -166.63648796081543
            },
            {
              "word": "factors that affect yearning of an employee",
              "weight": -163.32959175109863
            },
            {
              "word": "factors that affect ending of an employee",
              "weight": -164.0608367919922
            },
            {
              "word": "factors that affect jennings of an employee",
              "weight": -166.6357593536377
            },
            {
              "word": "factors that affects learning of an employee",
              "weight": -164.21317863464355
            },
            {
              "word": "factors that affect earnings of an employee's",
              "weight": -163.06049728393555
            },
            {
              "word": "factors that affect on of an employee",
              "weight": -166.51520538330078
            },
            {
              "word": "factors that affect journeying of an employee",
              "weight": -163.36674880981445
            },
            {
              "word": "factor that affects learning of an employee",
              "weight": -166.0995330810547
            },
            {
              "word": "factors that affect signing of an employee",
              "weight": -164.8167724609375
            },
            {
              "word": "factors that effect joining of an employee",
              "weight": -162.86766624450684
            },
            {
              "word": "factors that affects earnings of an employee",
              "weight": -161.43650817871094
            },
            {
              "word": "factors that affect learning of an employee's",
              "weight": -164.90819931030273
            },
            {
              "word": "factor that affects earnings of an employee",
              "weight": -163.2372169494629
            },
            {
              "word": "factors that effect turning of an employee",
              "weight": -162.7728042602539
            },
            {
              "word": "factors that affect journeys of an employee",
              "weight": -163.78478622436523
            },
            {
              "word": "factors that affect funding of an employee",
              "weight": -165.72789001464844
            },
            {
              "word": "factors that affect tuning of an employee",
              "weight": -164.57718658447266
            },
            {
              "word": "factors that affect warnings of an employee",
              "weight": -167.14266967773438
            },
            {
              "word": "factors that affect joining of an employee's",
              "weight": -167.85837173461914
            },
            {
              "word": "factors that affect running of an employee's",
              "weight": -168.0208511352539
            },
            {
              "word": "factors that affect journey of an employee's",
              "weight": -169.44904708862305
            },
            {
              "word": "factors that affect earning of an employee's",
              "weight": -165.70377731323242
            },
            {
              "word": "factors that affect turning of an employee's",
              "weight": -167.91218948364258
            },
            {
              "word": "factors that affect warning of an employee's",
              "weight": -171.07081604003906
            },
            {
              "word": "factors that affect any of an employee's",
              "weight": -169.09909057617188
            },
            {
              "word": "factors that affect burning of an employee's",
              "weight": -168.9297866821289
            },
            {
              "word": "factors that affect dawning of an employee's",
              "weight": -173.13471221923828
            },
            {
              "word": "factors that affect inning of an employee's",
              "weight": -175.23952865600586
            },
            {
              "word": "factors that affect cunning of an employee's",
              "weight": -171.40463638305664
            },
            {
              "word": "factors that affect churning of an employee's",
              "weight": -170.51382446289062
            },
            {
              "word": "factors that affect awning of an employee's",
              "weight": -173.6033821105957
            },
            {
              "word": "factors that affect yearning of an employee's",
              "weight": -171.29125213623047
            },
            {
              "word": "factors that affect ending of an employee's",
              "weight": -170.5380973815918
            },
            {
              "word": "factors that affect jennings of an employee's",
              "weight": -173.93873596191406
            },
            {
              "word": "factors that affects learning of an employee's",
              "weight": -171.00009536743164
            },
            {
              "word": "factors that affect on of an employee's",
              "weight": -173.06550979614258
            },
            {
              "word": "factors that affect journeying of an employee's",
              "weight": -171.1382713317871
            },
            {
              "word": "factor that affects learning of an employee's",
              "weight": -172.79018020629883
            },
            {
              "word": "factors that affect signing of an employee's",
              "weight": -171.86640548706055
            },
            {
              "word": "factors that effect joining of an employee's",
              "weight": -170.5310878753662
            },
            {
              "word": "factors that affects earnings of an employee's",
              "weight": -169.57332611083984
            },
            {
              "word": "factor that affects earnings of an employee's",
              "weight": -171.31597900390625
            },
            {
              "word": "factors that effect turning of an employee's",
              "weight": -169.89226531982422
            },
            {
              "word": "factors that affect journeys of an employee's",
              "weight": -171.7308349609375
            },
            {
              "word": "factors that affect funding of an employee's",
              "weight": -172.57272720336914
            },
            {
              "word": "factors that affect tuning of an employee's",
              "weight": -170.89574813842773
            },
            {
              "word": "factors that affect warnings of an employee's",
              "weight": -173.81925582885742
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "Without any warning whatsoever.",
              "They're burning that diesel fuel.",
              "I'm kind of learning this.",
              "Employee controller.",
              "Joining mining pool.",
              "in the red square are weaver said",
              "they did a lot of paper work and stuff",
              "you can gain too much weight",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity"
            ],
            "retrieval_time_ms": 38.078300999927706
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "factors that affect earnings of an employee",
                "llm_score": -205.24874877929688,
                "old_lm_score": -45.140625,
                "acoustic_score": -59.50997543334961,
                "combined_score": -154.94967460632324
              },
              {
                "candidate": "factors that affect learning of an employee",
                "llm_score": -210.8373260498047,
                "old_lm_score": -45.3896484375,
                "acoustic_score": -59.93701934814453,
                "combined_score": -158.0819969177246
              },
              {
                "candidate": "factors that affect joining of an employee",
                "llm_score": -214.0642852783203,
                "old_lm_score": -50.4326171875,
                "acoustic_score": -56.056419372558594,
                "combined_score": -160.27666091918945
              },
              {
                "candidate": "factors that affect running of an employee",
                "llm_score": -210.47459411621094,
                "old_lm_score": -47.0576171875,
                "acoustic_score": -64.31339263916016,
                "combined_score": -160.92280197143555
              },
              {
                "candidate": "factors that affect journey of an employee",
                "llm_score": -211.68548583984375,
                "old_lm_score": -47.169921875,
                "acoustic_score": -64.16514587402344,
                "combined_score": -161.5102767944336
              },
              {
                "candidate": "factors that affect earning of an employee",
                "llm_score": -208.19085693359375,
                "old_lm_score": -51.4404296875,
                "acoustic_score": -56.142208099365234,
                "combined_score": -157.8867473602295
              },
              {
                "candidate": "factors that affect turning of an employee",
                "llm_score": -212.33970642089844,
                "old_lm_score": -50.2841796875,
                "acoustic_score": -59.241294860839844,
                "combined_score": -160.93259048461914
              },
              {
                "candidate": "factors that affect warning of an employee",
                "llm_score": -214.7921600341797,
                "old_lm_score": -46.3642578125,
                "acoustic_score": -67.62238311767578,
                "combined_score": -164.38940048217773
              },
              {
                "candidate": "factors that affect any of an employee",
                "llm_score": -207.83058166503906,
                "old_lm_score": -43.3828125,
                "acoustic_score": -75.2117691040039,
                "combined_score": -163.21258163452148
              },
              {
                "candidate": "factors that affect burning of an employee",
                "llm_score": -211.69834899902344,
                "old_lm_score": -48.1396484375,
                "acoustic_score": -65.7153091430664,
                "combined_score": -162.77665328979492
              },
              {
                "candidate": "factors that affect dawning of an employee",
                "llm_score": -220.2028350830078,
                "old_lm_score": -49.33984375,
                "acoustic_score": -63.616519927978516,
                "combined_score": -166.57959938049316
              },
              {
                "candidate": "factors that affect inning of an employee",
                "llm_score": -223.58285522460938,
                "old_lm_score": -48.81640625,
                "acoustic_score": -64.73445129394531,
                "combined_score": -168.56685638427734
              },
              {
                "candidate": "factors that affect cunning of an employee",
                "llm_score": -214.18356323242188,
                "old_lm_score": -49.775390625,
                "acoustic_score": -63.02598190307617,
                "combined_score": -163.49246788024902
              },
              {
                "candidate": "factors that affect churning of an employee",
                "llm_score": -215.7946014404297,
                "old_lm_score": -51.6572265625,
                "acoustic_score": -59.79307556152344,
                "combined_score": -163.62245178222656
              },
              {
                "candidate": "factors that affect awning of an employee",
                "llm_score": -220.26121520996094,
                "old_lm_score": -50.287109375,
                "acoustic_score": -62.72465133666992,
                "combined_score": -166.63648796081543
              },
              {
                "candidate": "factors that affect yearning of an employee",
                "llm_score": -215.08544921875,
                "old_lm_score": -51.8486328125,
                "acoustic_score": -59.725101470947266,
                "combined_score": -163.32959175109863
              },
              {
                "candidate": "factors that affect ending of an employee",
                "llm_score": -212.09864807128906,
                "old_lm_score": -47.861328125,
                "acoustic_score": -68.16169738769531,
                "combined_score": -164.0608367919922
              },
              {
                "candidate": "factors that affect jennings of an employee",
                "llm_score": -221.43890380859375,
                "old_lm_score": -52.0966796875,
                "acoustic_score": -59.73593521118164,
                "combined_score": -166.6357593536377
              },
              {
                "candidate": "factors that affects learning of an employee",
                "llm_score": -214.6922607421875,
                "old_lm_score": -50.4921875,
                "acoustic_score": -63.24190902709961,
                "combined_score": -164.21317863464355
              },
              {
                "candidate": "factors that affect earnings of an employee's",
                "llm_score": -209.97769165039062,
                "old_lm_score": -48.166015625,
                "acoustic_score": -67.97728729248047,
                "combined_score": -163.06049728393555
              },
              {
                "candidate": "factors that affect on of an employee",
                "llm_score": -211.99981689453125,
                "old_lm_score": -43.3525390625,
                "acoustic_score": -77.67805480957031,
                "combined_score": -166.51520538330078
              },
              {
                "candidate": "factors that affect journeying of an employee",
                "llm_score": -217.32470703125,
                "old_lm_score": -55.0244140625,
                "acoustic_score": -54.384376525878906,
                "combined_score": -163.36674880981445
              },
              {
                "candidate": "factor that affects learning of an employee",
                "llm_score": -216.77169799804688,
                "old_lm_score": -49.0908203125,
                "acoustic_score": -66.3365478515625,
                "combined_score": -166.0995330810547
              },
              {
                "candidate": "factors that affect signing of an employee",
                "llm_score": -211.99818420410156,
                "old_lm_score": -46.9921875,
                "acoustic_score": -70.64317321777344,
                "combined_score": -164.8167724609375
              },
              {
                "candidate": "factors that effect joining of an employee",
                "llm_score": -216.18980407714844,
                "old_lm_score": -55.2666015625,
                "acoustic_score": -54.278926849365234,
                "combined_score": -162.86766624450684
              },
              {
                "candidate": "factors that affects earnings of an employee",
                "llm_score": -208.9302215576172,
                "old_lm_score": -51.1279296875,
                "acoustic_score": -62.81486511230469,
                "combined_score": -161.43650817871094
              },
              {
                "candidate": "factors that affect learning of an employee's",
                "llm_score": -212.9970245361328,
                "old_lm_score": -48.4150390625,
                "acoustic_score": -68.40433502197266,
                "combined_score": -164.90819931030273
              },
              {
                "candidate": "factor that affects earnings of an employee",
                "llm_score": -210.83836364746094,
                "old_lm_score": -49.7265625,
                "acoustic_score": -65.90950775146484,
                "combined_score": -163.2372169494629
              },
              {
                "candidate": "factors that effect turning of an employee",
                "llm_score": -214.10523986816406,
                "old_lm_score": -53.9765625,
                "acoustic_score": -57.46380615234375,
                "combined_score": -162.7728042602539
              },
              {
                "candidate": "factors that affect journeys of an employee",
                "llm_score": -212.43154907226562,
                "old_lm_score": -50.337890625,
                "acoustic_score": -64.80013275146484,
                "combined_score": -163.78478622436523
              },
              {
                "candidate": "factors that affect funding of an employee",
                "llm_score": -211.29287719726562,
                "old_lm_score": -45.3349609375,
                "acoustic_score": -74.82794189453125,
                "combined_score": -165.72789001464844
              },
              {
                "candidate": "factors that affect tuning of an employee",
                "llm_score": -213.67547607421875,
                "old_lm_score": -50.087890625,
                "acoustic_score": -65.39100646972656,
                "combined_score": -164.57718658447266
              },
              {
                "candidate": "factors that affect warnings of an employee",
                "llm_score": -215.96414184570312,
                "old_lm_score": -47.3310546875,
                "acoustic_score": -70.99014282226562,
                "combined_score": -167.14266967773438
              },
              {
                "candidate": "factors that affect joining of an employee's",
                "llm_score": -217.73500061035156,
                "old_lm_score": -53.4580078125,
                "acoustic_score": -64.52373504638672,
                "combined_score": -167.85837173461914
              },
              {
                "candidate": "factors that affect running of an employee's",
                "llm_score": -213.17799377441406,
                "old_lm_score": -50.0830078125,
                "acoustic_score": -72.78070068359375,
                "combined_score": -168.0208511352539
              },
              {
                "candidate": "factors that affect journey of an employee's",
                "llm_score": -216.07032775878906,
                "old_lm_score": -50.1953125,
                "acoustic_score": -72.63245391845703,
                "combined_score": -169.44904708862305
              },
              {
                "candidate": "factors that affect earning of an employee's",
                "llm_score": -212.33221435546875,
                "old_lm_score": -54.4658203125,
                "acoustic_score": -64.6095199584961,
                "combined_score": -165.70377731323242
              },
              {
                "candidate": "factors that affect turning of an employee's",
                "llm_score": -214.8061981201172,
                "old_lm_score": -53.3095703125,
                "acoustic_score": -67.70861053466797,
                "combined_score": -167.91218948364258
              },
              {
                "candidate": "factors that affect warning of an employee's",
                "llm_score": -216.66229248046875,
                "old_lm_score": -49.3896484375,
                "acoustic_score": -76.08969116210938,
                "combined_score": -171.07081604003906
              },
              {
                "candidate": "factors that affect any of an employee's",
                "llm_score": -208.11090087890625,
                "old_lm_score": -46.408203125,
                "acoustic_score": -83.6790771484375,
                "combined_score": -169.09909057617188
              },
              {
                "candidate": "factors that affect burning of an employee's",
                "llm_score": -212.5119171142578,
                "old_lm_score": -51.1650390625,
                "acoustic_score": -74.1826171875,
                "combined_score": -168.9297866821289
              },
              {
                "candidate": "factors that affect dawning of an employee's",
                "llm_score": -221.8203582763672,
                "old_lm_score": -52.365234375,
                "acoustic_score": -72.08383178710938,
                "combined_score": -173.13471221923828
              },
              {
                "candidate": "factors that affect inning of an employee's",
                "llm_score": -225.4355010986328,
                "old_lm_score": -51.841796875,
                "acoustic_score": -73.2017593383789,
                "combined_score": -175.23952865600586
              },
              {
                "candidate": "factors that affect cunning of an employee's",
                "llm_score": -218.51519775390625,
                "old_lm_score": -52.80078125,
                "acoustic_score": -71.49329376220703,
                "combined_score": -171.40463638305664
              },
              {
                "candidate": "factors that affect churning of an employee's",
                "llm_score": -218.0846405029297,
                "old_lm_score": -54.6826171875,
                "acoustic_score": -68.26039123535156,
                "combined_score": -170.51382446289062
              },
              {
                "candidate": "factors that affect awning of an employee's",
                "llm_score": -222.70230102539062,
                "old_lm_score": -53.3125,
                "acoustic_score": -71.19196319580078,
                "combined_score": -173.6033821105957
              },
              {
                "candidate": "factors that affect yearning of an employee's",
                "llm_score": -219.5160675048828,
                "old_lm_score": -54.8740234375,
                "acoustic_score": -68.19241333007812,
                "combined_score": -171.29125213623047
              },
              {
                "candidate": "factors that affect ending of an employee's",
                "llm_score": -213.5604705810547,
                "old_lm_score": -50.88671875,
                "acoustic_score": -76.6290054321289,
                "combined_score": -170.5380973815918
              },
              {
                "candidate": "factors that affect jennings of an employee's",
                "llm_score": -224.55215454101562,
                "old_lm_score": -55.1220703125,
                "acoustic_score": -68.2032470703125,
                "combined_score": -173.93873596191406
              },
              {
                "candidate": "factors that affects learning of an employee's",
                "llm_score": -216.7733917236328,
                "old_lm_score": -53.517578125,
                "acoustic_score": -71.70922088623047,
                "combined_score": -171.00009536743164
              },
              {
                "candidate": "factors that affect on of an employee's",
                "llm_score": -213.60772705078125,
                "old_lm_score": -46.3779296875,
                "acoustic_score": -86.1453628540039,
                "combined_score": -173.06550979614258
              },
              {
                "candidate": "factors that affect journeying of an employee's",
                "llm_score": -221.3750457763672,
                "old_lm_score": -58.0498046875,
                "acoustic_score": -62.85169219970703,
                "combined_score": -171.1382713317871
              },
              {
                "candidate": "factor that affects learning of an employee's",
                "llm_score": -218.66029357910156,
                "old_lm_score": -52.1162109375,
                "acoustic_score": -74.8038558959961,
                "combined_score": -172.79018020629883
              },
              {
                "candidate": "factors that affect signing of an employee's",
                "llm_score": -214.60475158691406,
                "old_lm_score": -50.017578125,
                "acoustic_score": -79.11048126220703,
                "combined_score": -171.86640548706055
              },
              {
                "candidate": "factors that effect joining of an employee's",
                "llm_score": -220.02394104003906,
                "old_lm_score": -58.2919921875,
                "acoustic_score": -62.74624252319336,
                "combined_score": -170.5310878753662
              },
              {
                "candidate": "factors that affects earnings of an employee's",
                "llm_score": -213.71115112304688,
                "old_lm_score": -54.1533203125,
                "acoustic_score": -71.28218078613281,
                "combined_score": -169.57332611083984
              },
              {
                "candidate": "factor that affects earnings of an employee's",
                "llm_score": -215.50318908691406,
                "old_lm_score": -52.751953125,
                "acoustic_score": -74.37681579589844,
                "combined_score": -171.31597900390625
              },
              {
                "candidate": "factors that effect turning of an employee's",
                "llm_score": -216.85145568847656,
                "old_lm_score": -57.001953125,
                "acoustic_score": -65.93112182617188,
                "combined_score": -169.89226531982422
              },
              {
                "candidate": "factors that affect journeys of an employee's",
                "llm_score": -216.83094787597656,
                "old_lm_score": -53.36328125,
                "acoustic_score": -73.26744079589844,
                "combined_score": -171.7308349609375
              },
              {
                "candidate": "factors that affect funding of an employee's",
                "llm_score": -213.48985290527344,
                "old_lm_score": -48.3603515625,
                "acoustic_score": -83.29524993896484,
                "combined_score": -172.57272720336914
              },
              {
                "candidate": "factors that affect tuning of an employee's",
                "llm_score": -214.8199005126953,
                "old_lm_score": -53.11328125,
                "acoustic_score": -73.85831451416016,
                "combined_score": -170.89574813842773
              },
              {
                "candidate": "factors that affect warnings of an employee's",
                "llm_score": -217.82461547851562,
                "old_lm_score": -50.3564453125,
                "acoustic_score": -79.45745086669922,
                "combined_score": -173.81925582885742
              }
            ],
            "selected": "factors that affect earnings of an employee",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 1059.3886599999678
        }
      ],
      "total_time_ms": 1101.1621899999682
    },
    {
      "sentence_idx": 35,
      "ground_truth": "if you drink a lot of caffeine you'll stay awake",
      "top1_hypothesis": "if you drink a lot of caffeine will still work",
      "final_decoded": "if you drink a lot of caffeine will still work",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 2.112447999934375
    },
    {
      "sentence_idx": 36,
      "ground_truth": "that's a nice car",
      "top1_hypothesis": "that's a nice car",
      "final_decoded": "that's a nice car",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.11893799990048137
    },
    {
      "sentence_idx": 37,
      "ground_truth": "visionary leaders",
      "top1_hypothesis": "visionary leaders",
      "final_decoded": "visionary leaders",
      "was_changed": false,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 1,
      "spans": [
        {
          "span_start": 1,
          "span_end": 2,
          "top1_word": "leaders",
          "confusion_candidates": [
            {
              "word": "leaders",
              "weight": 0.7876144861347112
            },
            {
              "word": "letters",
              "weight": 0.21170637651040444
            },
            {
              "word": "leader",
              "weight": 1.24150608416378e-05
            },
            {
              "word": "daughters",
              "weight": 0.0006667222930426883
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.521742101856577,
            "margin": 0.5759081096243067,
            "disagreement_mass": 0.2123855138652888
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "visionary (leaders OR letters OR leader OR daughters)",
            "retrieved_docs": [
              "Letters of applications to universities.",
              "We hold a visionary approach.",
              "Mine's pretty limited.",
              "When do you want the babysitter to come?",
              "So you have your hands full with them?",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity",
              "factors that affect earnings of an employee",
              "if you drink a lot of caffeine will still work",
              "that's a nice car"
            ],
            "scores": [
              9.568650191125684,
              9.568650191125684,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 7.573433999937151
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 2,
          "top1_word": "visionary leaders",
          "confusion_candidates": [
            {
              "word": "visionary leaders",
              "weight": -137.88560485839844
            },
            {
              "word": "visionary letters",
              "weight": -138.50056266784668
            },
            {
              "word": "visionary leader",
              "weight": -142.85029220581055
            },
            {
              "word": "visionary daughters",
              "weight": -142.18331336975098
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "Letters of applications to universities.",
              "We hold a visionary approach.",
              "Mine's pretty limited.",
              "When do you want the babysitter to come?",
              "So you have your hands full with them?",
              "recent legislation",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity",
              "factors that affect earnings of an employee",
              "if you drink a lot of caffeine will still work",
              "that's a nice car"
            ],
            "retrieval_time_ms": 7.573433999937151
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "visionary leaders",
                "llm_score": -224.17340087890625,
                "old_lm_score": -17.775390625,
                "acoustic_score": -33.822418212890625,
                "combined_score": -137.88560485839844
              },
              {
                "candidate": "visionary letters",
                "llm_score": -224.08950805664062,
                "old_lm_score": -29.595703125,
                "acoustic_score": -23.315914154052734,
                "combined_score": -138.50056266784668
              },
              {
                "candidate": "visionary leader",
                "llm_score": -223.044921875,
                "old_lm_score": -22.0009765625,
                "acoustic_score": -40.654685974121094,
                "combined_score": -142.85029220581055
              },
              {
                "candidate": "visionary daughters",
                "llm_score": -225.69442749023438,
                "old_lm_score": -26.0498046875,
                "acoustic_score": -32.62239456176758,
                "combined_score": -142.18331336975098
              }
            ],
            "selected": "visionary leaders",
            "selected_index": 0,
            "changed_from_top1": false,
            "change_was_correct": false
          },
          "time_ms": 102.77764699992531
        }
      ],
      "total_time_ms": 110.64506800005347
    },
    {
      "sentence_idx": 38,
      "ground_truth": "the only other place i've ever vacationed",
      "top1_hypothesis": "the only other place i've ever taken",
      "final_decoded": "the only other place i've ever vacation",
      "was_changed": true,
      "decision_mode": "nbest_rescore",
      "n_uncertain_spans": 2,
      "spans": [
        {
          "span_start": 3,
          "span_end": 4,
          "top1_word": "place",
          "confusion_candidates": [
            {
              "word": "place",
              "weight": 0.9999476513477318
            },
            {
              "word": "piece",
              "weight": 5.2141995224134895e-05
            },
            {
              "word": "face",
              "weight": 2.0665604386752706e-07
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.0005697285377980625,
            "margin": 0.9998955093525076,
            "disagreement_mass": 5.2348652268219276e-05
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 4,
          "span_end": 5,
          "top1_word": "i've",
          "confusion_candidates": [
            {
              "word": "i've",
              "weight": 0.9964692596000371
            },
            {
              "word": "of",
              "weight": 0.003527268711706813
            },
            {
              "word": "i",
              "weight": 3.471687255969825e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.023487444891672943,
            "margin": 0.9929419908883302,
            "disagreement_mass": 0.0035307403999629283
          },
          "gate_result": "confident",
          "gate_threshold_used": 0.0,
          "retrieval": null,
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 5,
          "span_end": 6,
          "top1_word": "ever",
          "confusion_candidates": [
            {
              "word": "ever",
              "weight": 0.7286194375941939
            },
            {
              "word": "every",
              "weight": 0.27138056240480607
            }
          ],
          "uncertainty_metrics": {
            "entropy": 0.5846271488494619,
            "margin": 0.45723887518938783,
            "disagreement_mass": 0.2713805624058061
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "the only other place i've (ever OR every) taken",
            "retrieved_docs": [
              "The other place is called the Vienna Inn.",
              "I've got a place in the country.",
              "I've taken some classes and I've made a few friends.",
              "I've been in school ever since.",
              "I've seen his other movies.",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity",
              "factors that affect earnings of an employee",
              "if you drink a lot of caffeine will still work",
              "that's a nice car",
              "visionary leaders"
            ],
            "scores": [
              11.524533064721787,
              11.245755440740364,
              10.431926230158775,
              10.091074300931345,
              10.057503242957381,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 18.242434000057983
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 6,
          "span_end": 7,
          "top1_word": "taken",
          "confusion_candidates": [
            {
              "word": "taken",
              "weight": 8.33887021902031e-05
            },
            {
              "word": "action",
              "weight": 0.231773063121699
            },
            {
              "word": "actions",
              "weight": 0.11313551879683514
            },
            {
              "word": "occasion",
              "weight": 0.4321945438777745
            },
            {
              "word": "vacation",
              "weight": 0.15133904668144127
            },
            {
              "word": "vacations",
              "weight": 0.03850787203820329
            },
            {
              "word": "vacationed",
              "weight": 0.03203173890096506
            },
            {
              "word": "caution",
              "weight": 0.000305346843006901
            },
            {
              "word": "kitchen",
              "weight": 0.0001196613277316379
            },
            {
              "word": "creation",
              "weight": 8.035336554933688e-05
            },
            {
              "word": "auctioned",
              "weight": 3.879545606454237e-06
            },
            {
              "word": "nation",
              "weight": 9.89166176341418e-06
            },
            {
              "word": "occasions",
              "weight": 4.4015569053523634e-05
            },
            {
              "word": "factions",
              "weight": 9.287364241764178e-05
            },
            {
              "word": "taxation",
              "weight": 9.445862261574093e-05
            },
            {
              "word": "nations",
              "weight": 6.515630991436325e-06
            },
            {
              "word": "asian",
              "weight": 1.2178653545726186e-05
            },
            {
              "word": "faction",
              "weight": 5.441213373899936e-05
            },
            {
              "word": "reaction",
              "weight": 7.541617359790346e-06
            },
            {
              "word": "reactions",
              "weight": 8.46672741583357e-06
            },
            {
              "word": "auction",
              "weight": 2.142161673813036e-06
            },
            {
              "word": "equation",
              "weight": 8.037693044906351e-06
            },
            {
              "word": "creations",
              "weight": 2.0686578842232306e-05
            },
            {
              "word": "caption",
              "weight": 1.3576826659440208e-07
            },
            {
              "word": "section",
              "weight": 1.1122379569159913e-06
            },
            {
              "word": "traction",
              "weight": 8.946331390338833e-06
            },
            {
              "word": "cautioned",
              "weight": 3.506925376654887e-05
            },
            {
              "word": "fiction",
              "weight": 1.5637394474615497e-06
            },
            {
              "word": "kitchens",
              "weight": 1.528011615726007e-05
            },
            {
              "word": "correction",
              "weight": 2.2586585488245676e-06
            }
          ],
          "uncertainty_metrics": {
            "entropy": 1.4787718176395455,
            "margin": 0.2004214807560755,
            "disagreement_mass": 0.5678054561222254
          },
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "only other place i've ever (taken OR action OR actions OR occasion OR vacation OR vacations OR vacationed OR caution OR kitchen OR creation OR auctioned OR nation OR occasions OR factions OR taxation OR nations OR asian OR faction OR reaction OR reactions OR auction OR equation OR creations OR caption OR section OR traction OR cautioned OR fiction OR kitchens OR correction)",
            "retrieved_docs": [
              "I've taken some classes and I've made a few friends.",
              "I've been in school ever since.",
              "I've seen his other movies.",
              "I've got a place in the country.",
              "Several Asian countries.",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity",
              "factors that affect earnings of an employee",
              "if you drink a lot of caffeine will still work",
              "that's a nice car",
              "visionary leaders"
            ],
            "scores": [
              10.431926230158775,
              10.091074300931345,
              10.057503242957381,
              10.027384939890176,
              9.912589744530077,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0
            ],
            "retrieval_time_ms": 63.80810400003156
          },
          "llm_decision": null,
          "time_ms": 0.0
        },
        {
          "span_start": 0,
          "span_end": 7,
          "top1_word": "the only other place i've ever taken",
          "confusion_candidates": [
            {
              "word": "the only other place i've ever taken",
              "weight": -164.02902221679688
            },
            {
              "word": "the only other place i've ever action",
              "weight": -166.1809310913086
            },
            {
              "word": "the only other place i've ever actions",
              "weight": -168.23796463012695
            },
            {
              "word": "the only other place i've every occasion",
              "weight": -168.15927696228027
            },
            {
              "word": "the only other place i've ever occasion",
              "weight": -165.86001586914062
            },
            {
              "word": "the only other place i've ever vacation",
              "weight": -163.69898414611816
            },
            {
              "word": "the only other place of every occasion",
              "weight": -166.73265075683594
            },
            {
              "word": "the only other place i've every action",
              "weight": -170.55855178833008
            },
            {
              "word": "the only other piece of every occasion",
              "weight": -170.92919921875
            },
            {
              "word": "the only other place i've ever vacations",
              "weight": -166.77780723571777
            },
            {
              "word": "the only other place i've ever vacationed",
              "weight": -164.4830722808838
            },
            {
              "word": "the only other place of every action",
              "weight": -167.93856048583984
            },
            {
              "word": "the only other piece of every action",
              "weight": -170.09967803955078
            },
            {
              "word": "the only other place i've ever caution",
              "weight": -170.29681777954102
            },
            {
              "word": "the only other place i've ever kitchen",
              "weight": -170.57625198364258
            },
            {
              "word": "the only other place i've ever creation",
              "weight": -173.0861053466797
            },
            {
              "word": "the only other place i've ever auctioned",
              "weight": -171.8429718017578
            },
            {
              "word": "the only other place i've ever nation",
              "weight": -171.85347747802734
            },
            {
              "word": "the only other place i've ever occasions",
              "weight": -172.3479881286621
            },
            {
              "word": "the only other place i've ever factions",
              "weight": -173.06227111816406
            },
            {
              "word": "the only other place i've ever take action",
              "weight": -171.06513595581055
            },
            {
              "word": "the only other place i've ever taxation",
              "weight": -173.62865447998047
            },
            {
              "word": "the only other place i've ever nations",
              "weight": -173.3110008239746
            },
            {
              "word": "the only other place i ever action",
              "weight": -171.74241638183594
            },
            {
              "word": "the only other place i've ever asian",
              "weight": -170.9247055053711
            },
            {
              "word": "the only other place i've ever faction",
              "weight": -172.77261352539062
            },
            {
              "word": "the only other place i've ever reaction",
              "weight": -172.6804656982422
            },
            {
              "word": "the only other place i've ever reactions",
              "weight": -173.9449462890625
            },
            {
              "word": "the only other face of every occasion",
              "weight": -174.38275909423828
            },
            {
              "word": "the only other place i've ever auction",
              "weight": -172.11597442626953
            },
            {
              "word": "the only other place i've ever equation",
              "weight": -173.84146118164062
            },
            {
              "word": "the only other place i've ever creations",
              "weight": -174.6862564086914
            },
            {
              "word": "the only other place i've ever caption",
              "weight": -173.25457763671875
            },
            {
              "word": "the only other place i've ever section",
              "weight": -172.4997329711914
            },
            {
              "word": "the only other place i've ever traction",
              "weight": -173.51190185546875
            },
            {
              "word": "the only other place i ever actions",
              "weight": -174.3827781677246
            },
            {
              "word": "the only other place i've ever cautioned",
              "weight": -169.88296127319336
            },
            {
              "word": "the only other place i've ever fiction",
              "weight": -172.89628219604492
            },
            {
              "word": "the only other place i've ever kitchens",
              "weight": -173.1227798461914
            },
            {
              "word": "the only other place i ever occasion",
              "weight": -172.57193756103516
            },
            {
              "word": "the only other place i've ever correction",
              "weight": -175.62929153442383
            },
            {
              "word": "the only other face of every action",
              "weight": -174.18370819091797
            }
          ],
          "uncertainty_metrics": {},
          "gate_result": "uncertain",
          "gate_threshold_used": 0.0,
          "retrieval": {
            "query": "(merged evidence for n-best rescoring)",
            "retrieved_docs": [
              "The other place is called the Vienna Inn.",
              "I've got a place in the country.",
              "I've taken some classes and I've made a few friends.",
              "I've been in school ever since.",
              "I've seen his other movies.",
              "i'm a car buff to",
              "two fans from a grateful heart",
              "still in over will never allow all to see",
              "no cause cause air pollution",
              "and then you people the case on top of that",
              "just seeing that clear vision is a necessity",
              "factors that affect earnings of an employee",
              "if you drink a lot of caffeine will still work",
              "that's a nice car",
              "visionary leaders",
              "Several Asian countries."
            ],
            "retrieval_time_ms": 82.05053800008955
          },
          "llm_decision": {
            "mode": "nbest_rescore",
            "candidate_scores": [
              {
                "candidate": "the only other place i've ever taken",
                "llm_score": -214.92588806152344,
                "old_lm_score": -30.4013671875,
                "acoustic_score": -82.73078918457031,
                "combined_score": -164.02902221679688
              },
              {
                "candidate": "the only other place i've ever action",
                "llm_score": -227.08364868164062,
                "old_lm_score": -39.8017578125,
                "acoustic_score": -65.47645568847656,
                "combined_score": -166.1809310913086
              },
              {
                "candidate": "the only other place i've ever actions",
                "llm_score": -230.5565948486328,
                "old_lm_score": -40.6923828125,
                "acoustic_score": -65.2269515991211,
                "combined_score": -168.23796463012695
              },
              {
                "candidate": "the only other place i've every occasion",
                "llm_score": -231.1966094970703,
                "old_lm_score": -41.9208984375,
                "acoustic_score": -63.201045989990234,
                "combined_score": -168.15927696228027
              },
              {
                "candidate": "the only other place i've ever occasion",
                "llm_score": -226.25253295898438,
                "old_lm_score": -42.1552734375,
                "acoustic_score": -63.312225341796875,
                "combined_score": -165.86001586914062
              },
              {
                "candidate": "the only other place i've ever vacation",
                "llm_score": -221.7695770263672,
                "old_lm_score": -42.5439453125,
                "acoustic_score": -63.08444595336914,
                "combined_score": -163.69898414611816
              },
              {
                "candidate": "the only other place of every occasion",
                "llm_score": -223.9984893798828,
                "old_lm_score": -39.0126953125,
                "acoustic_score": -70.45411682128906,
                "combined_score": -166.73265075683594
              },
              {
                "candidate": "the only other place i've every action",
                "llm_score": -233.2860107421875,
                "old_lm_score": -42.4658203125,
                "acoustic_score": -65.36527252197266,
                "combined_score": -170.55855178833008
              },
              {
                "candidate": "the only other piece of every occasion",
                "llm_score": -228.19223022460938,
                "old_lm_score": -36.6728515625,
                "acoustic_score": -76.99331665039062,
                "combined_score": -170.92919921875
              },
              {
                "candidate": "the only other place i've ever vacations",
                "llm_score": -226.55856323242188,
                "old_lm_score": -44.162109375,
                "acoustic_score": -62.83494186401367,
                "combined_score": -166.77780723571777
              },
              {
                "candidate": "the only other place i've ever vacationed",
                "llm_score": -221.7849578857422,
                "old_lm_score": -44.0302734375,
                "acoustic_score": -63.15091323852539,
                "combined_score": -164.4830722808838
              },
              {
                "candidate": "the only other place of every action",
                "llm_score": -223.70115661621094,
                "old_lm_score": -39.5576171875,
                "acoustic_score": -72.61834716796875,
                "combined_score": -167.93856048583984
              },
              {
                "candidate": "the only other piece of every action",
                "llm_score": -223.82403564453125,
                "old_lm_score": -37.2177734375,
                "acoustic_score": -79.15754699707031,
                "combined_score": -170.09967803955078
              },
              {
                "candidate": "the only other place i've ever caution",
                "llm_score": -228.75941467285156,
                "old_lm_score": -42.556640625,
                "acoustic_score": -69.27758026123047,
                "combined_score": -170.29681777954102
              },
              {
                "candidate": "the only other place i've ever kitchen",
                "llm_score": -228.38150024414062,
                "old_lm_score": -41.91796875,
                "acoustic_score": -70.85303497314453,
                "combined_score": -170.57625198364258
              },
              {
                "candidate": "the only other place i've ever creation",
                "llm_score": -233.0029754638672,
                "old_lm_score": -41.7236328125,
                "acoustic_score": -71.44560241699219,
                "combined_score": -173.0861053466797
              },
              {
                "candidate": "the only other place i've ever auctioned",
                "llm_score": -227.48599243164062,
                "old_lm_score": -39.0,
                "acoustic_score": -77.199951171875,
                "combined_score": -171.8429718017578
              },
              {
                "candidate": "the only other place i've ever nation",
                "llm_score": -228.44297790527344,
                "old_lm_score": -40.3974609375,
                "acoustic_score": -74.86651611328125,
                "combined_score": -171.85347747802734
              },
              {
                "candidate": "the only other place i've ever occasions",
                "llm_score": -230.9248504638672,
                "old_lm_score": -42.064453125,
                "acoustic_score": -71.70667266845703,
                "combined_score": -172.3479881286621
              },
              {
                "candidate": "the only other place i've ever factions",
                "llm_score": -233.10011291503906,
                "old_lm_score": -43.18359375,
                "acoustic_score": -69.84083557128906,
                "combined_score": -173.06227111816406
              },
              {
                "candidate": "the only other place i've ever take action",
                "llm_score": -227.95042419433594,
                "old_lm_score": -42.0751953125,
                "acoustic_score": -72.10465240478516,
                "combined_score": -171.06513595581055
              },
              {
                "candidate": "the only other place i've ever taxation",
                "llm_score": -234.2498016357422,
                "old_lm_score": -43.298828125,
                "acoustic_score": -69.70867919921875,
                "combined_score": -173.62865447998047
              },
              {
                "candidate": "the only other place i've ever nations",
                "llm_score": -230.94053649902344,
                "old_lm_score": -41.064453125,
                "acoustic_score": -74.61701202392578,
                "combined_score": -173.3110008239746
              },
              {
                "candidate": "the only other place i ever action",
                "llm_score": -226.3175811767578,
                "old_lm_score": -39.734375,
                "acoustic_score": -77.43287658691406,
                "combined_score": -171.74241638183594
              },
              {
                "candidate": "the only other place i've ever asian",
                "llm_score": -226.79342651367188,
                "old_lm_score": -41.892578125,
                "acoustic_score": -73.16340637207031,
                "combined_score": -170.9247055053711
              },
              {
                "candidate": "the only other place i've ever faction",
                "llm_score": -231.98614501953125,
                "old_lm_score": -43.46875,
                "acoustic_score": -70.09033203125,
                "combined_score": -172.77261352539062
              },
              {
                "candidate": "the only other place i've ever reaction",
                "llm_score": -229.82569885253906,
                "old_lm_score": -41.7685546875,
                "acoustic_score": -73.76667785644531,
                "combined_score": -172.6804656982422
              },
              {
                "candidate": "the only other place i've ever reactions",
                "llm_score": -232.47036743164062,
                "old_lm_score": -41.90234375,
                "acoustic_score": -73.51718139648438,
                "combined_score": -173.9449462890625
              },
              {
                "candidate": "the only other face of every occasion",
                "llm_score": -229.5686798095703,
                "old_lm_score": -38.419921875,
                "acoustic_score": -80.77691650390625,
                "combined_score": -174.38275909423828
              },
              {
                "candidate": "the only other place i've ever auction",
                "llm_score": -227.43809509277344,
                "old_lm_score": -40.828125,
                "acoustic_score": -75.96572875976562,
                "combined_score": -172.11597442626953
              },
              {
                "candidate": "the only other place i've ever equation",
                "llm_score": -232.21139526367188,
                "old_lm_score": -42.3828125,
                "acoustic_score": -73.08871459960938,
                "combined_score": -173.84146118164062
              },
              {
                "candidate": "the only other place i've ever creations",
                "llm_score": -234.84632873535156,
                "old_lm_score": -43.330078125,
                "acoustic_score": -71.19610595703125,
                "combined_score": -174.6862564086914
              },
              {
                "candidate": "the only other place i've ever caption",
                "llm_score": -226.95668029785156,
                "old_lm_score": -38.5439453125,
                "acoustic_score": -81.00852966308594,
                "combined_score": -173.25457763671875
              },
              {
                "candidate": "the only other place i've ever section",
                "llm_score": -227.5501708984375,
                "old_lm_score": -40.693359375,
                "acoustic_score": -76.75593566894531,
                "combined_score": -172.4997329711914
              },
              {
                "candidate": "the only other place i've ever traction",
                "llm_score": -231.6593780517578,
                "old_lm_score": -43.0341796875,
                "acoustic_score": -72.33024597167969,
                "combined_score": -173.51190185546875
              },
              {
                "candidate": "the only other place i ever actions",
                "llm_score": -230.95718383789062,
                "old_lm_score": -40.625,
                "acoustic_score": -77.1833724975586,
                "combined_score": -174.3827781677246
              },
              {
                "candidate": "the only other place i've ever cautioned",
                "llm_score": -225.767578125,
                "old_lm_score": -44.654296875,
                "acoustic_score": -69.34404754638672,
                "combined_score": -169.88296127319336
              },
              {
                "candidate": "the only other place i've ever fiction",
                "llm_score": -228.68397521972656,
                "old_lm_score": -41.76953125,
                "acoustic_score": -75.33905792236328,
                "combined_score": -172.89628219604492
              },
              {
                "candidate": "the only other place i've ever kitchens",
                "llm_score": -231.41644287109375,
                "old_lm_score": -44.2255859375,
                "acoustic_score": -70.60353088378906,
                "combined_score": -173.1227798461914
              },
              {
                "candidate": "the only other place i ever occasion",
                "llm_score": -227.78733825683594,
                "old_lm_score": -42.087890625,
                "acoustic_score": -75.26864624023438,
                "combined_score": -172.57193756103516
              },
              {
                "candidate": "the only other place i've ever correction",
                "llm_score": -234.51768493652344,
                "old_lm_score": -42.779296875,
                "acoustic_score": -73.96160125732422,
                "combined_score": -175.62929153442383
              },
              {
                "candidate": "the only other face of every action",
                "llm_score": -226.46142578125,
                "old_lm_score": -38.96484375,
                "acoustic_score": -82.94114685058594,
                "combined_score": -174.18370819091797
              }
            ],
            "selected": "the only other place i've ever vacation",
            "selected_index": 5,
            "changed_from_top1": true,
            "change_was_correct": false
          },
          "time_ms": 970.9833820000995
        }
      ],
      "total_time_ms": 1057.831988000089
    },
    {
      "sentence_idx": 39,
      "ground_truth": "i just kind of went through",
      "top1_hypothesis": "i just kind of went through",
      "final_decoded": "i just kind of went through",
      "was_changed": false,
      "decision_mode": "kept_top1",
      "n_uncertain_spans": 0,
      "spans": [],
      "total_time_ms": 0.27000699992640875
    }
  ]
}